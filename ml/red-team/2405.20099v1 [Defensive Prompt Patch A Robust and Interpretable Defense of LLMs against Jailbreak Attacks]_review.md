#Tags
[[Research/Research Papers/2405.20099v1.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0054/LLMJailbreak
#AMLT0043/CraftAdversarialData

**Title:** Defensive Prompt Patch: A Robust and Interpretable Defense of LLMs against Jailbreak Attacks
**Authors:** Chen Xiong, Xiangyu Qi, Pin-Yu Chen, Tsung-Yi Ho
**Affiliations:** 
- The Chinese University of Hong Kong
- Princeton University  
- IBM Research
**Publication Date:** May 30, 2024

Summary:
This paper introduces Defensive Prompt Patch (DPP), a novel prompt-based defense mechanism designed to protect large language models (LLMs) against sophisticated jailbreak attacks. DPP aims to minimize the Attack Success Rate (ASR) while maintaining high model utility. The method uses strategically designed interpretable suffix prompts to thwart various jailbreak techniques. Empirical results on LLAMA-2-7B-Chat and Mistral-7B-Instruct-v0.2 models demonstrate significant ASR reductions with minimal utility impact.

Key Contributions:
- Introduction of Defensive Prompt Patch (DPP) for LLM defense
- Balanced approach to minimize ASR while preserving utility
- Empirical evaluation on multiple LLM models and jailbreak techniques
- Demonstration of DPP's robustness and adaptability

Problem Statement:
LLMs are susceptible to jailbreak attacks that circumvent safety guardrails and security mechanisms, potentially leading to harmful or unintended outputs. Existing defense approaches often compromise model utility for safety.

Methodology:
1. DPP Algorithm:
   - Uses a Hierarchical Genetic Algorithm (HGA) to optimize defensive prompts
   - Iteratively refines prompts based on refusal and helpful scores
   - Incorporates sentence-level word substitution and paragraph-level sentence swap/mutations

2. Evaluation:
   - Models: LLAMA-2-7B-Chat and Mistral-7B-Instruct-v0.2
   - Jailbreak Attacks: GCG, Base64, AutoDAN, PAIR, TAP, ICA, Catastrophic
   - Metrics: Attack Success Rate (ASR), Win-Rate (utility)
   - Comparison with baseline defenses: Self-Reminder, RPO, Goal Prioritization, System Prompt

Main Results:
1. LLAMA-2-7B-Chat:
   - DPP achieved lowest Average ASR of 3.80% 
   - Highest Win-Rate of 82.98%
   - Outperformed baselines in both non-adaptive and adaptive attack scenarios

2. Mistral-7B-Instruct-v0.2:
   - DPP achieved lowest Average ASR of 2.0%
   - Win-Rate of 75.06% (lower than some baselines but with significantly better defense)

3. Generalization:
   - Effective against unforeseen jailbreak queries (JailbreakBench Chat dataset)
   - Adaptable to less-aligned models

Qualitative Analysis:
- DPP demonstrates a balance between maintaining high utility and providing robust defense
- The method is interpretable, with generated prompts being fluent and relevant to alignment
- DPP shows adaptability to different LLM models, including less-aligned ones

Limitations:
- Prototype selection impacts DPP performance
- Computationally intensive training process
- High cost associated with using GPT-4 for prompt revision during training

Conclusion and Future Work:
- DPP presents a scalable and practical approach to improving LLM safeguards
- Achieves optimal balance between utility and robust defense
- Future work may focus on relaxing prototype selection constraints and optimizing computational efficiency

Tools Introduced:
- Defensive Prompt Patch (DPP) algorithm
- GitHub repository: https://anonymous.4open.science/r/DPP-23FF/README.md