#Tags
[[Research/Research Papers/2409.07353v1.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0018/BackdoorMLModel
#AMLT0043/CraftAdversarialData
#AMLT0054/LLMJailbreak

**Title:** Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks
**Authors:** Md Zarif Hossain, Ahmed Imteaj
**Affiliations:** School of Computing, Southern Illinois University, Carbondale, IL, USA; Security, Privacy and Intelligence for Edge Devices Laboratory (SPEED Lab)
**Publication Date:** September 11, 2024

Key Contributions:
- Introduces Sim-CLIP+, a novel defense mechanism for Large Vision-Language Models (LVLMs) against jailbreak and adversarial attacks
- Proposes an unsupervised adversarial fine-tuning scheme for the CLIP vision encoder
- Demonstrates effectiveness against gradient-based adversarial attacks and various jailbreak techniques
- Maintains high clean accuracy while improving robustness
- Offers a plug-and-play solution for existing LVLM architectures

Problem Statement:
LVLMs are vulnerable to jailbreak attacks that bypass safety protocols, causing the generation of harmful or misleading content. This vulnerability stems from both inherent susceptibilities of Large Language Models (LLMs) and the expanded attack surface introduced by the visual modality.

Methodology:
1. Adversarial fine-tuning of CLIP vision encoder using a Siamese architecture
2. Maximization of cosine similarity between perturbed and clean samples
3. Implementation of a stop-gradient mechanism to prevent loss function collapse
4. Evaluation against three jailbreak attack strategies: ImgJP, VisualAdv, and HADES
5. Clean evaluations using COCO for image captioning and OKVQA for visual question answering
6. Comparison with state-of-the-art defense methods like JailGuard and CIDER

Main Results:
1. Sim-CLIP+ significantly reduces Attack Success Rate (ASR) for jailbreak attacks:
   - ImgJP attack: ASR reduced from 28.0% to 15.0% for LLaVA (Llama-2-13B)
   - VisualAdv attack: Average toxicity reduced from 30.4% to 14.2% at Îµ=128/255
2. Maintains competitive clean accuracy on downstream tasks:
   - COCO image captioning: CIDEr score of 122.3 (vs. 121.9 for original CLIP)
   - OKVQA: Accuracy of 60.3% (vs. 57.3% for original CLIP)
3. Outperforms existing defense methods like JailGuard and CIDER in most scenarios

Qualitative Analysis:
- Sim-CLIP+ demonstrates a balance between robustness and clean performance, addressing a common trade-off in adversarial training
- The plug-and-play nature of Sim-CLIP+ allows for easy integration into existing LVLM architectures without structural modifications
- The approach shows effectiveness against both optimization-based and generation-based jailbreak attacks, indicating its versatility

Limitations:
- Performance against generation-based attacks (e.g., HADES) is comparable to external defenses but not significantly better
- The study focuses on specific LVLM architectures (LLaVA variants), and generalization to other architectures needs further investigation

Conclusion and Future Work:
- Sim-CLIP+ offers a robust defense mechanism for LVLMs against jailbreak and adversarial attacks
- The approach maintains high clean accuracy while significantly improving robustness
- Future work may include:
  1. Extending the evaluation to a broader range of LVLM architectures
  2. Investigating the combination of Sim-CLIP+ with other defense strategies for enhanced protection
  3. Exploring the applicability of the approach to other modalities beyond vision-language models

Relevant Figures:
- Figure 1: Illustration of jailbreak attack on LVLM
- Figure 2: Workflow and overview of proposed Sim-CLIP+

New Tools:
- Sim-CLIP+: A robust vision encoder for LVLMs
- GitHub repository: https://github.com/speedlab-git/Robust-Encoder-against-Jailbreak-attack.git

## Repository Token Information
Total tokens in repository: 200000

Tokens per file:
- CLIP_benchmark/clip_benchmark/datasets/builder.py: 19893 tokens
- VisualAdv/lavis/models/blip2_models/modeling_t5.py: 18109 tokens
- vlm_eval/run_evaluation_of.py: 15634 tokens
- vlm_eval/run_evaluation_of copy.py: 15615 tokens
- vlm_eval/run_evaluation.py: 15582 tokens
- VisualAdv/lavis/models/med.py: 10925 tokens
- VisualAdv/lavis/models/clip_models/model.py: 10263 tokens
- VisualAdv/lavis/models/blip2_models/modeling_opt.py: 10158 tokens
- ImgJP/minigpt4/models/Qformer.py: 9583 tokens
- VisualAdv/lavis/models/blip2_models/Qformer.py: 9583 tokens
- VisualAdv/minigpt4/models/Qformer.py: 9583 tokens
- HADES/white_box/llava/model/language_model/mpt/flash_attn_triton.py: 8896 tokens
- HADES/black_box/llava/model/language_model/mpt/flash_attn_triton.py: 8896 tokens
- HADES/eval/evaluate/inference/llava/model/language_model/mpt/flash_attn_triton.py: 8896 tokens
- llava/model/language_model/mpt/flash_attn_triton.py: 8896 tokens
- VisualAdv/llava_llama_2/model/language_model/mpt/flash_attn_triton.py: 8896 tokens
- ImgJP/torchattacks/attacks/_differential_evolution.py: 8822 tokens
- VisualAdv/lavis/models/blip2_models/modeling_llama.py: 1770 tokens
