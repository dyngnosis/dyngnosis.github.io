#Tags
[[Research/Research Papers/2310.04451v2.pdf]]

#AMLT0054/LLMJailbreak
#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0017/DevelopCapabilities

**Title:** AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models
**Authors:** Xiaogeng Liu, Nan Xu, Muhao Chen, Chaowei Xiao
**Publication Date:** March 20, 2024 (last updated)

Summary:
This paper introduces AutoDAN, a novel method for automatically generating stealthy jailbreak prompts to attack aligned large language models (LLMs). The approach uses a hierarchical genetic algorithm to create semantically meaningful prompts that can evade detection while successfully causing LLMs to produce undesired outputs.

Key Contributions:
- AutoDAN: A new method for automatically generating stealthy jailbreak prompts
- Hierarchical genetic algorithm tailored for structured discrete data like prompt text
- Demonstration of superior attack strength, cross-model transferability, and cross-sample universality compared to baselines
- Ability to bypass perplexity-based defense methods

Problem Statement:
Existing jailbreak techniques for LLMs suffer from scalability issues (manual crafting) or lack of stealthiness (token-based algorithms producing meaningless prompts). The research aims to develop an approach that can automatically generate stealthy jailbreak prompts.

Methodology:
1. Population Initialization: Use LLMs to revise prototype handcrafted jailbreak prompts
2. Fitness Evaluation: Calculate log-likelihood of desired output given input prompt
3. Genetic Policies:
   - Paragraph-level: Selection, crossover, and mutation of prompts
   - Sentence-level: Momentum word scoring for fine-grained optimization
4. Termination Criteria: Max iterations or absence of refusal signals in LLM response

Main Results:
1. AutoDAN achieves higher attack success rates compared to baselines (e.g., 8% improvement in average ASRs)
2. Superior cross-model transferability (e.g., 70.58% ASR when transferring from Vicuna-7B to Guanaco-7b)
3. Better cross-sample universality (e.g., 80.96% ASR on Vicuna-7b)
4. Effective against perplexity-based defenses (maintaining high ASRs while baseline methods fail)

Qualitative Analysis:
- AutoDAN generates semantically meaningful jailbreak prompts, making them more resistant to detection and potentially more transferable across models and samples
- The hierarchical approach allows for better exploration of the solution space, leading to more effective jailbreak prompts
- LLM-based diversification in the initialization and mutation steps contributes to the generation of fluent and contextually appropriate prompts

Limitations:
- Computational cost: Although more efficient than some baselines, still requires significant time to generate prompts
- Performance on robust models: Struggles with models like Llama2 with robust system prompts

Conclusion and Future Work:
AutoDAN demonstrates the ability to automatically generate stealthy jailbreak prompts that are effective across multiple LLMs and resistant to certain defense mechanisms. Future work may focus on improving efficiency, addressing limitations with robust models, and exploring more advanced mutation policies.

New Tools:
- AutoDAN: A hierarchical genetic algorithm for generating stealthy jailbreak prompts
- GitHub repository: https://github.com/SheltonLiu-N/AutoDAN

## Repository Token Information
Total tokens in repository: 13760

Tokens per file:
- check_asr.py: 419 tokens
- get_responses.py: 1461 tokens
- autodan_hga_eval.py: 2381 tokens
- requirements.txt: 88 tokens
- autodan_ga_eval.py: 2286 tokens
- README.md: 1151 tokens
- assets/autodan_initial_prompt.txt: 63 tokens
- utils/string_utils.py: 1180 tokens
- utils/opt_utils.py: 4581 tokens
- models/download_models.py: 150 tokens


## Tutorial and Enhancement Suggestions

# AutoDAN: Stealthy Jailbreak Prompts for Large Language Models

## Tutorial

### 1. Project Overview

AutoDAN is a novel approach to automatically generate stealthy jailbreak prompts for attacking aligned large language models (LLMs). The project implements a hierarchical genetic algorithm to create semantically meaningful prompts that can evade detection while successfully causing LLMs to produce undesired outputs.

#### Project Structure

```
AutoDAN/
│
├── autodan_ga_eval.py
├── autodan_hga_eval.py
├── check_asr.py
├── get_responses.py
├── README.md
├── requirements.txt
│
├── assets/
│   └── autodan_initial_prompt.txt
│
├── models/
│   └── download_models.py
│
└── utils/
    ├── opt_utils.py
    └── string_utils.py
```

### 2. Key Components and Functionality

#### 2.1 Genetic Algorithm Implementation (autodan_ga_eval.py)

This file implements the basic genetic algorithm for generating jailbreak prompts. Key functions include:

- `autodan_sample_control`: Performs selection, crossover, and mutation operations on the population of prompts.
- `roulette_wheel_selection`: Implements the selection process based on fitness scores.
- `apply_crossover_and_mutation`: Applies genetic operations to create new offspring prompts.
- `crossover`: Implements the crossover operation between two parent prompts.
- `gpt_mutate`: Uses GPT-4 to mutate prompts, adding diversity to the population.

#### 2.2 Hierarchical Genetic Algorithm (autodan_hga_eval.py)

This file extends the basic genetic algorithm with a hierarchical approach, incorporating sentence-level optimization. Key additions include:

- `autodan_sample_control_hga`: Implements the hierarchical genetic algorithm.
- `construct_momentum_word_dict`: Builds a dictionary of words with associated scores based on their effectiveness in jailbreak prompts.
- `replace_with_best_synonym`: Replaces words in prompts with synonyms based on the word dictionary scores.

#### 2.3 Utility Functions (utils/opt_utils.py and utils/string_utils.py)

These files contain various utility functions for working with LLMs, tokenizers, and text processing. Notable functions include:

- `load_model_and_tokenizer`: Loads the target LLM and its tokenizer.
- `get_score_autodan`: Evaluates the fitness of prompts by calculating the log-likelihood of desired outputs.
- `autodan_SuffixManager`: Manages the structure of prompts and their tokenization.

#### 2.4 Evaluation and Analysis (check_asr.py and get_responses.py)

These files are used to evaluate the effectiveness of generated jailbreak prompts and analyze the responses from the target LLM.

### 3. Relation to Research Concepts

The code implements the key concepts discussed in the research paper:

1. **Population Initialization**: The `autodan_initial_prompt.txt` file contains prototype handcrafted jailbreak prompts, which are then revised using LLMs (implemented in `gpt_mutate`).

2. **Fitness Evaluation**: The `get_score_autodan` function calculates the log-likelihood of desired outputs given input prompts, as described in the paper's methodology.

3. **Genetic Policies**: 
   - Paragraph-level operations are implemented in `autodan_sample_control` (GA) and `autodan_sample_control_hga` (HGA).
   - Sentence-level optimization is achieved through the momentum word scoring in `construct_momentum_word_dict` and `replace_with_best_synonym`.

4. **Termination Criteria**: The main evaluation loops in `autodan_ga_eval.py` and `autodan_hga_eval.py` implement the termination criteria based on maximum iterations or successful jailbreaks.

### 4. Notable Algorithms and Techniques

1. **Hierarchical Genetic Algorithm**: The combination of paragraph-level and sentence-level genetic operations allows for more fine-grained optimization of prompts.

2. **Momentum Word Scoring**: This technique, implemented in `construct_momentum_word_dict`, keeps track of word effectiveness across generations, guiding the optimization process.

3. **GPT-4 Assisted Mutation**: The `gpt_mutate` function uses GPT-4 to create meaningful mutations in prompts, maintaining semantic coherence and fluency.

4. **Roulette Wheel Selection**: This selection method, implemented in `roulette_wheel_selection`, allows for a balance between exploration and exploitation in the genetic algorithm.

## Potential Enhancements

1. **Adaptive Mutation Rates**
   - Implement dynamic mutation rates that adapt based on the population's diversity and fitness improvement rate.
   - This could help balance exploration and exploitation more effectively, potentially leading to faster convergence or discovery of better jailbreak prompts.

2. **Multi-Objective Optimization**
   - Extend the fitness function to consider multiple objectives, such as jailbreak success, stealth (e.g., perplexity scores), and transferability across models.
   - Implement Pareto-based selection methods to find prompts that balance these potentially conflicting objectives.

3. **Ensemble Learning for Prompt Generation**
   - Develop an ensemble of different genetic algorithm variants (e.g., GA, HGA, and other evolutionary algorithms) to generate prompts.
   - Implement a meta-learner that combines the strengths of different algorithms based on their performance on different types of jailbreak tasks.

4. **Adversarial Training Integration**
   - Incorporate the generated jailbreak prompts into an adversarial training pipeline for LLMs.
   - Develop methods to automatically fine-tune LLMs to become more robust against the generated jailbreak attempts.

5. **Prompt Distillation and Compression**
   - Implement techniques to distill the essence of successful jailbreak prompts into shorter, more efficient versions.
   - Explore methods like prompt compression or knowledge distillation to create a set of compact, highly transferable jailbreak patterns.