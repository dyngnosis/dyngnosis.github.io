#Tags
[[Research/Research Papers/2405.19668v1.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0054/LLMJailbreak
#AMLT0051/LLMPromptInjection

**Title:** AutoBreach: Universal and Adaptive Jailbreaking with Efficient Wordplay-Guided Optimization
**Authors:** Jiawei Chen, Xiao Yang, Zhengwei Fang, Yu Tian, Yinpeng Dong, Zhaoxia Yin, Hang Su
**Affiliations:** Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University; Dept. of Comp. Sci. and Tech., Institute for AI, Tsinghua University; RealAI
**Publication Date:** May 30, 2024

Key Contributions:
- Introduces AutoBreach, a novel method for jailbreaking LLMs using only black-box access
- Proposes wordplay-guided mapping rule sampling for generating universal mapping rules
- Implements sentence compression and chain-of-thought-based mapping rules to improve jailbreak success rates
- Develops a two-stage mapping rule optimization strategy for enhanced efficiency

Problem Statement:
The paper addresses the limitations of existing jailbreak research, including limited universality, suboptimal efficiency, and reliance on manual crafting. It aims to develop a more effective and efficient method for jailbreaking LLMs while maintaining universality and adaptability.

Methodology:
1. Wordplay-Guided Mapping Rule Sampling (WMFS):
   - Injects validated wordplay rules into the system prompt of an Attacker LLM
   - Leverages inductive reasoning to generate novel and diverse mapping rules

2. Sentence Compression (SC):
   - Condenses jailbreak goals into concise tokens while preserving semantic consistency

3. Chain-of-Thought (CoT) based Mapping Rules:
   - Augments the Attacker LLM to generate mapping rules with thought chains

4. Two-stage Mapping Rule Optimization (TMFO):
   - Stage 1: Optimizes mapping rules before querying target LLMs
   - Stage 2: Iteratively refines mapping rules through target LLM queries

5. Experimental Setup:
   - Evaluates AutoBreach on various LLMs, including Claude-3, GPT-3.5, GPT-4 Turbo, Bingchat, and GPT-4 Web
   - Uses the AdvBench subset containing 50 prompts across 32 categories

Main Results:
1. Jailbreak Success Rate (JSR):
   - Achieves an average JSR of over 80% across diverse models
   - Outperforms baseline methods on most target LLMs

2. Efficiency:
   - Requires fewer than 10 queries on average to successfully jailbreak target LLMs

3. Universality:
   - Demonstrates effectiveness across different LLM interfaces (API and web)
   - Shows high transferability of mapping rules across different models

4. Robustness:
   - Maintains effectiveness against multi-modal LLMs (MLLMs) when presented with irrelevant images

Qualitative Analysis:
- The success of AutoBreach can be attributed to its ability to generate diverse and adaptive mapping rules using wordplay techniques
- The two-stage optimization process significantly reduces the number of queries required, improving efficiency
- The use of sentence compression and CoT-based mapping rules helps overcome challenges related to long sentences and misinterpretations by target LLMs

Limitations:
- The method relies on access to advanced LLMs (e.g., GPT-4 Turbo) for optimal performance, which may incur higher economic costs
- The approach may not be as effective when using simpler LLMs (e.g., Vicuna) for generating mapping rules

Conclusion and Future Work:
- AutoBreach demonstrates the potential for efficient, universal, and adaptive jailbreaking of LLMs
- The method provides a valuable tool for assessing and improving the security of large language models
- Future work could focus on optimizing AutoBreach to work effectively with simpler, open-source LLMs to reduce economic costs

Relevant Figures:
- Figure 1: Overview of AutoBreach, illustrating the two-stage optimization process and the roles of different LLM components (Attacker, Supervisor, Mapper, and Evaluator)
- Table 2: Comparison of jailbreak attacks on the AdvBench subset, showing AutoBreach's performance against baseline methods

New Tools:
- AutoBreach: A novel method for jailbreaking LLMs using wordplay-guided optimization (No GitHub repository mentioned in the paper)