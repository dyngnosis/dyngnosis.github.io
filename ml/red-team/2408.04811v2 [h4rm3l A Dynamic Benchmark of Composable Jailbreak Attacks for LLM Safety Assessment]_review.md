#Tags
[[Research/Research Papers/2408.04811v2.pdf]]

#AMLT0054/LLMJailbreak
#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0017/DevelopCapabilities
#AMLT0042/VerifyAttack

**Title:** h4rm3l: A Dynamic Benchmark of Composable Jailbreak Attacks for LLM Safety Assessment

**Authors:** Moussa Koulako Bala Doumbouya, Ananjan Nandi, Gabriel Poesia, Davide Ghilardi, Anna Goldie, Federico Bianchi, Dan Jurafsky, Christopher D. Manning

**Affiliation:** Department of Computer Science, Stanford University

**Publication Date:** September 13, 2024 (last updated)

Summary:
The paper introduces h4rm3l, a novel dynamic benchmark for evaluating the safety of Large Language Models (LLMs) against jailbreak attacks. It addresses the limitations of static benchmarks by providing a composable and extensible framework for generating and testing jailbreak attacks.

Key Contributions:
- A domain-specific language (DSL) for formally expressing jailbreak attacks as compositions of parameterized prompt transformation primitives
- Bandit-based few-shot program synthesis algorithms for generating novel jailbreak attacks
- Open-source automated red-teaming software using the DSL and synthesis algorithms
- A dataset of 2,656 successful novel jailbreak attacks targeting 6 state-of-the-art LLMs
- Benchmark results showing high attack success rates (ASR) on closed-source models like claude-3-haiku and GPT-4o

Problem Statement:
The lack of comprehensive benchmarks for systematically evaluating LLMs' robustness to a large and diverse set of jailbreak attacks, which hinders the development of effective safety measures.

Methodology:
1. Development of h4rm3l DSL for representing jailbreak attacks
2. Implementation of bandit-based few-shot program synthesis algorithms
3. Creation of a zero-shot harmful LLM behavior classifier
4. Generation and evaluation of jailbreak attacks on 6 SOTA LLMs
5. Qualitative analysis of synthesized attacks

Main Results:
- Synthesized attacks achieved high ASRs: 94% for GPT-4o, 82% for claude-3-haiku
- Synthesized attacks outperformed state-of-the-art jailbreak attacks by significant margins
- The composition of individual attacks resulted in higher attack success rates
- Targeted attack synthesis is necessary for effective LLM safety benchmarking

Qualitative Analysis:
- Synthesized attacks showed high diversity and specificity to targeted LLMs
- The ASR of synthesized attacks increased with the number of primitives they compose
- Different LLMs showed vulnerabilities to different distributions of attack primitives

Limitations:
- The definition of harm is nuanced and may require human discernment for accurate classification
- The automated classifier, while effective, may not capture all nuances of harmful content
- Some results for Claude-3 models may not be directly comparable due to additional safety filters applied during the study

Conclusion and Future Work:
The h4rm3l framework provides a powerful tool for assessing LLM vulnerabilities and developing robust defenses. Future work could focus on:
- Expanding the range of attack primitives and target models
- Developing more sophisticated program synthesis algorithms
- Improving the accuracy and nuance of harm classification
- Investigating defense mechanisms against synthesized attacks

Tools Introduced:
- h4rm3l: A domain-specific language and framework for composable jailbreak attacks
- GitHub repository: https://mdoumbouya.github.io/h4rm3l/

Figures and Tables:
- Figure 1: Example of a synthesized jailbreak attack and its effect on Claude3-Haiku
- Figure 2: Comparison of attack synthesis methods
- Figure 3: Attack success rates for different LLMs over synthesis iterations
- Figure 4: Heatmap of attack success rates for synthesized and SOTA attacks on 6 LLMs
- Figure 5: t-SNE projection of attack embeddings
- Figure 6: Analysis of attack primitives in synthesized attacks