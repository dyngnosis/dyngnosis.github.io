#Tags
[[Research/Research Papers/2408.09093v1.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0018/BackdoorMLModel
#AMLT0043/CraftAdversarialData
#AMLT0054/LLMJailbreak

**Title:** BaThe: Defense against the Jailbreak Attack in Multimodal Large Language Models by Treating Harmful Instruction as Backdoor Trigger

**Authors:** Yulin Chen, Haoran Li, Zihao Zheng, Yangqiu Song

Affiliations:
- National University of Singapore
- Hong Kong University of Science and Technology
- Harbin Institute of Technology, Shenzhen

**Publication Date:** August 17, 2024

Summary:
This paper introduces BaThe (Backdoor Trigger Shield), a novel defense mechanism against jailbreak attacks on Multimodal Large Language Models (MLLMs). The authors propose treating harmful instructions as backdoor triggers and using rejection responses as the triggered output to defend against such attacks.

Key Contributions:
- Novel perspective on jailbreak defense for MLLMs
- Development of a "wedge" containing a virtual rejection prompt
- Effective mitigation of various jailbreak attacks, including unseen ones
- Minimal impact on MLLMs' performance on benign tasks

Problem Statement:
MLLMs are vulnerable to jailbreak attacks, especially through the image modality, which can bypass existing safety mechanisms. Current defense methods either require extensive resources or face issues like prompt injection attacks and over-defense.

Methodology:
1. Collect harmful instruction-image pairs and corresponding rejection responses
2. Create a "wedge" by embedding a virtual rejection prompt into soft text embeddings
3. Train the wedge using harmful instructions, crafted rejection responses, and general multimodal QA dataset
4. Integrate the wedge into MLLMs to map harmful instructions to rejection responses

Datasets:
- JailBreakV-28K for harmful instruction-image pairs
- LLaVA-Instruct-150K for general QA samples
- MM-SafetyBench, FigStep, and HADES for evaluation
- MMBench for utility performance assessment

Models:
- LLaVA-1.5-7b
- LLaVA-1.6-vicuna-7b
- LLaVA-1.6-mistral-7b

Main Results:
1. BaThe significantly reduces Attack Success Rate (ASR) across various attacks
2. Effective against unseen attacks (e.g., HADES)
3. Minimal impact on MLLMs' performance on benign tasks
4. Outperforms baseline methods like system prompts and response filtering

Qualitative Analysis:
- BaThe successfully identifies and rejects harmful instructions, even when they are not explicitly stated
- The method avoids over-defense issues seen in other approaches
- Contextually appropriate rejection responses maintain the model's coherence

Limitations:
1. Wedge transferability between different MLLMs is poor
2. Using image noise as a wedge is ineffective for defense

Conclusion and Future Work:
BaThe offers a promising approach to defending MLLMs against jailbreak attacks while maintaining utility. Future work could focus on improving wedge transferability and exploring alternative wedge implementations.

Relevant Figures:
Figure 1: Illustration of the intuition behind BaThe, comparing jailbreak backdoor attack and the proposed defense mechanism.

Figure 2: Training process for the wedge, showing how the soft text embeddings are integrated with image and text inputs.

New Tool:
BaThe (Backdoor Trigger Shield) - A defense mechanism for MLLMs against jailbreak attacks. No GitHub repository mentioned.