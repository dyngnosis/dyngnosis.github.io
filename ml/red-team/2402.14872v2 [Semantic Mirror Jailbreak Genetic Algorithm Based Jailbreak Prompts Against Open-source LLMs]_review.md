#Tags
[[Research/Research Papers/2402.14872v2.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0051/LLMPromptInjection
#AMLT0054/LLMJailbreak

**Title:** Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs
**Authors:** Xiaoxia Li, Siyuan Liang, Jiyi Zhang, Han Fang, Aishan Liu, Ee-Chien Chang
**Publication Date:** February 21, 2024

Summary:
This paper introduces Semantic Mirror Jailbreak (SMJ), a novel approach to generate jailbreak prompts for Large Language Models (LLMs) that are semantically similar to the original harmful questions while bypassing safety measures. The method uses genetic algorithms to optimize both semantic similarity and attack success rate.

Key Contributions:
- Proposes a new jailbreak attack method that generates prompts satisfying both semantic similarity and attack effectiveness
- Models the attack as a multi-objective optimization problem
- Develops a genetic algorithm-based scheme for automatic prompt generation
- Demonstrates SMJ's resistance to simple defenses and its ability to bypass more advanced defenses like ONION

Problem Statement:
Existing jailbreak attacks on LLMs often use prompts that are semantically different from the original questions, making them vulnerable to defenses based on semantic metrics. The challenge is to create jailbreak prompts that are both effective and semantically similar to the original harmful questions.

Methodology:
1. Population Initialization: Generate paraphrased questions based on the original harmful question
2. Fitness Evaluation: Assess semantic similarity and attack validity
3. Selection: Use roulette wheel selection based on semantic similarity
4. Crossover: Apply syntactic form paraphrasing to generate offspring
5. Termination Criteria: Based on generations, similarity stagnation, or lack of new individuals

Main Results:
- SMJ achieves up to 35.4% higher Attack Success Rate (ASR) compared to AutoDAN-GA without ONION defense
- With ONION defense, SMJ's ASR is up to 85.2% higher than AutoDAN-GA
- SMJ outperforms AutoDAN-GA in semantic meaningfulness metrics: Jailbreak Prompt, Similarity, and Outlier
- SMJ demonstrates better transferability in black-box scenarios for most cases

Qualitative Analysis:
- SMJ addresses the limitations of existing jailbreak attacks by generating prompts that are semantically similar to original questions
- The method's success in bypassing defenses like ONION suggests it could pose significant challenges for current LLM safety measures
- The approach of using genetic algorithms for multi-objective optimization in this context is novel and effective

Limitations:
- The study focuses on open-source LLMs; effectiveness on closed-source models is not explored
- Ethical concerns arise from improving methods to generate harmful content from LLMs

Conclusion and Future Work:
SMJ demonstrates the ability to generate effective jailbreak prompts while maintaining semantic similarity to original questions. This approach poses new challenges for LLM safety and highlights the need for more robust defense mechanisms. Future work may involve exploring countermeasures and extending the method to other types of LLMs.

Relevant Figures:
- Figure 1: Illustration of jailbreak prompt comparison between normal, existing, and SMJ methods
- Figure 2: Overview of the Semantic Mirror Jailbreak (SMJ) process

Tools Introduced:
- Semantic Mirror Jailbreak (SMJ): A genetic algorithm-based tool for generating jailbreak prompts against open-source LLMs
- No specific GitHub repository mentioned in the paper