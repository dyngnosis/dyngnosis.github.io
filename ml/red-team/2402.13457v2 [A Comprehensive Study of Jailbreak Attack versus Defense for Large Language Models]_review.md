#Tags
[[Research/Research Papers/2402.13457v2.pdf]]

#AMLT0054/LLMJailbreak
#AMLT0015/EvadeMLModel
#AMLT0051/LLMPromptInjection
#AMLT0042/VerifyAttack
#AMLT0043/CraftAdversarialData

**Title:** A Comprehensive Study of Jailbreak Attack versus Defense for Large Language Models
**Authors:** Zihao Xu, Yi Liu, Gelei Deng, Yuekang Li, Stjepan Picek
**Affiliations:** University of New South Wales, Australia; Delft University of Technology, The Netherlands; Nanyang Technological University, Singapore
**Publication Date:** February 21, 2024 (updated May 17, 2024)

Summary:
This study conducts a comprehensive analysis of jailbreak attacks and defense techniques for Large Language Models (LLMs). The research investigates nine attack techniques and seven defense techniques across three LLMs: Vicuna, LLama, and GPT-3.5 Turbo.

Key Contributions:
- First systematic evaluation of jailbreak attacks versus defenses on various open/closed-source LLMs
- Identification of previously unknown insights for enhancing attack and defense strategies
- Development and release of a comprehensive benchmark for attack and defense techniques

Problem Statement:
The study addresses the challenge of jailbreak attacks on LLMs, where carefully crafted prompts bypass safety measures and elicit harmful content from models.

Methodology:
1. Baseline Selection: Nine attack techniques and seven defense techniques were chosen based on popularity and source code accessibility.
2. LLMs Tested: Llama-2-7b, Vicuna-v1.5-7b, and GPT-3.5-Turbo-1106
3. Experimental Configuration: Used two NVIDIA RTX 6000 Ada GPUs with 48 GB RAM
4. Benchmark Construction: Expanded dataset to 60 malicious queries across various categories
5. Result Labeling: Employed both automated and manual labeling strategies
6. Evaluation Metrics: 
   - For attacks: Attack Success Rate (ASR) and Efficiency
   - For defenses: Defense Passing Rate (DPR), Benign Success Rate (BSR), and Generated Response Quality (GRQ)

Main Results and Findings:
1. Template-based methods demonstrated superior effectiveness in jailbreak attacks
2. White-box attacks (e.g., AutoDan, GCG) underperformed compared to universal, template-based methods
3. LLaMA model showed more resilience against jailbreak attempts, particularly for white-box attacks
4. Special tokens (e.g., '[/INST]') significantly influenced the success rates of jailbreak attacks
5. Most current defense strategies were found to be inadequate, with the Bergeron method showing the best performance

Qualitative Analysis:
- The study highlights the importance of comprehensive safety training during LLM development
- The effectiveness of template-based attacks suggests a need for more robust defense mechanisms
- The impact of special tokens on attack success rates indicates a potential area for improving model security

Limitations:
- The study did not extend to larger models (13B, 33B parameters) or commercial models like GPT-4, Gemini, and Palm2
- Recent updates to some attack techniques (e.g., autoDan) were not included in the evaluation

Conclusion and Future Work:
The research emphasizes the need for continued focus on LLM security, particularly in developing more effective defense strategies. Future work should include:
1. Incorporating evolving attacks and defenses into the benchmark framework
2. Investigating the influence of special tokens on LLM behavior in security contexts
3. Developing more advanced evaluation frameworks for defense strategies

Tools Introduced:
The authors developed and released a comprehensive benchmark platform for testing attack and defense techniques. The dataset and testing framework are available on the companion website: https://sites.google.com/view/llmcomprehensive/home