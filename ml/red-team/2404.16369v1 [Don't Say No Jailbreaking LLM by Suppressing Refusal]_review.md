#Tags
[[Research/Research Papers/2404.16369v1.pdf]]

#AMLT0054/LLMJailbreak
#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0051/LLMPromptInjection

**Title:** Don't Say No: Jailbreaking LLM by Suppressing Refusal
**Authors:** Yukai Zhou, Wenjie Wang
**Affiliations:** Shanghaitech University
**Publication Date:** April 25, 2024

Summary:
This paper introduces a novel jailbreaking attack called DSN (Don't Say No) that aims to elicit affirmative responses from Large Language Models (LLMs) while suppressing refusals. The authors also propose an ensemble evaluation pipeline to assess the effectiveness of jailbreaking attacks more accurately.

Key Contributions:
- Introduction of the DSN attack, which incorporates a novel objective to suppress refusal responses
- Application of Unlikelihood loss to stabilize the convergence of opposing loss objectives
- Proposal of an ensemble evaluation pipeline incorporating NLI contradiction assessment and external LLM evaluators
- Extensive experiments demonstrating the effectiveness of DSN and the ensemble evaluation method

Problem Statement:
Existing jailbreaking attacks, such as GCG, have limited success rates in eliciting harmful content from LLMs. Additionally, current evaluation methods for jailbreaking attacks, like refusal keyword matching, are prone to false positives and negatives.

Methodology:
1. DSN Attack:
   - Incorporates two main objectives: eliciting affirmative responses and suppressing refusals
   - Uses Unlikelihood loss to stabilize the convergence of opposing loss objectives
   - Employs Greedy Coordinate Gradient-based search for optimization

2. Ensemble Evaluation Pipeline:
   - Incorporates Natural Language Inference (NLI) contradiction assessment
   - Utilizes two external LLM evaluators: GPT-4 and HarmBench
   - Aggregates results using majority voting

3. Experiments:
   - Conducted on Llama-2-Chat-7B and Vicuna-7b-v1.3 models
   - Compared DSN with GCG baseline
   - Evaluated using both refusal matching and the proposed ensemble method

Main Results:
1. DSN outperforms GCG in terms of Attack Success Rate (ASR) on both Llama-2 and Vicuna models
2. The ensemble evaluation method shows higher accuracy and AUROC scores compared to refusal matching
3. DSN demonstrates good transferability to black-box models like GPT-3.5-turbo

Qualitative Analysis:
- The DSN attack's success is attributed to its dual objective of eliciting affirmative responses and suppressing refusals
- The ensemble evaluation method provides a more nuanced and accurate assessment of jailbreaking attacks compared to simple refusal matching
- The transferability of DSN to black-box models suggests its potential effectiveness against a wide range of LLMs

Limitations:
- The gibberish nature of optimized suffixes may trigger perplexity-based defending filters
- The ensemble evaluation method treats all components with equal weight, which may not accurately reflect the reliability of each element

Conclusion and Future Work:
The paper demonstrates the effectiveness of the DSN attack and the ensemble evaluation method in jailbreaking LLMs and assessing attack success. Future work may focus on improving the readability of adversarial suffixes and refining the weighting mechanism in the ensemble evaluation pipeline.

Relevant Figures:
- Figure 2: Detailed illustration of DSN attack and ensemble evaluation pipeline
- Figure 4: ASR over steps on Llama2 and Vicuna
- Figure 5: Ablation study of ASR vs. α by refusal matching evaluation
- Figure 7: Ablation study of ASR vs. α by ensemble evaluation

New Tools:
- DSN (Don't Say No) attack: A novel jailbreaking method for LLMs
- Ensemble evaluation pipeline: A more accurate method for assessing jailbreaking attacks