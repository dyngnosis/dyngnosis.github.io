#Tags
[[Research/Research Papers/2406.11757v3.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0040/MLModelInferenceAPIAccess
#AMLT0042/VerifyAttack

**Title:** STAR: SocioTechnical Approach to Red Teaming Language Models
**Authors:** Laura Weidinger, John Mellor, Bernat Guill√©n Pegueroles, Nahema Marchal, Ravin Kumar, Kristian Lum, Canfer Akbulut, Mark Diaz, Stevie Bergman, Mikel Rodriguez, Verena Rieser, William Isaac
**Affiliations:** Google DeepMind, Google, Google Labs
**Publication date:** August 6, 2024

Summary:
STAR is a sociotechnical framework for improving red teaming of large language models. It enhances steerability through parameterized instructions and improves signal quality by matching demographics and using arbitration to leverage diverse viewpoints.

Key Contributions:
- Introduces STAR, a novel framework for red teaming language models
- Enhances steerability with parameterized instructions for comprehensive risk surface coverage
- Improves signal quality through demographic matching and arbitration
- Demonstrates the effectiveness of STAR compared to current best practices

Problem Statement:
Current red teaming practices for AI systems lack consensus on best practices, making it difficult to compare results and establish standards. This hinders progress in AI safety research and public assessment of AI safety.

Methodology:
1. Procedurally generated instructions with multiple parameters for red teamers
2. Demographic matching of annotators to targeted groups
3. Two-step annotation process with arbitration for disagreements
4. Comparison with other red teaming approaches using UMAP embedding
5. Quantitative and qualitative analysis of in-group vs. out-group annotations

Main Results:
1. STAR achieves broader coverage and less clustering of attacks compared to other red teaming approaches
2. In-group annotators flagged hate speech and discriminatory stereotype dialogues as rule-breaking more often (45%) than out-group annotators (30%)
3. Arbitration process leverages diverse viewpoints and improves label reliability
4. STAR enables more nuanced findings about model failure modes at no additional cost

Qualitative Analysis:
- Annotator disagreements often stemmed from different interpretations of key terms like "promoting" hate or stereotypes
- Arbitrators demonstrated thoughtful engagement with annotators' reasoning, weighing different arguments
- Demographic matching revealed different sensitivity profiles between in-group and out-group annotators

Limitations:
- Study limited to English language attacks and specific demographic labels (gender, race)
- Cognitive load limits the number of parameters that can be used in instructions
- Some clustering of dialogues may not mirror real-world innocuous use

Conclusion:
STAR offers a novel approach to red teaming that improves steerability and signal quality. It provides a more comprehensive and nuanced understanding of model failures while leveraging diverse perspectives.

Future Work:
- Extend STAR to other languages, modalities, and user applications
- Adapt STAR for hybridized approaches incorporating automated tools
- Explore additional parameters for instructions to further improve coverage

Tools Introduced:
STAR (SocioTechnical Approach to Red teaming) - A framework for improving red teaming of large language models