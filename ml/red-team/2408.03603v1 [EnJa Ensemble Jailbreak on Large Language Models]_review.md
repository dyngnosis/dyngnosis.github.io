#Tags
[[Research/Research Papers/2408.03603v1.pdf]]

#AMLT0054/LLMJailbreak
#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0051/LLMPromptInjection

**Title:** EnJa: Ensemble Jailbreak on Large Language Models
**Authors:** Jiahao Zhang, Zilong Wang, Ruofan Wang, Xingjun Ma, Yu-Gang Jiang
**Affiliation:** School of Computer Science, Fudan University, China
**Publication Date:** August 7, 2024 (preprint)

Summary:
This paper introduces Ensemble Jailbreak (EnJa), a novel attack method that combines prompt-level and token-level jailbreak techniques to create more effective and efficient attacks on Large Language Models (LLMs). The authors demonstrate that EnJa outperforms existing jailbreak attacks in terms of attack success rate and efficiency.

Key Contributions:
- Introduction of the Ensemble Jailbreak (EnJa) concept
- Development of a novel EnJa attack method combining template-optimized and gradient-based attacks
- Proposal of an effective integration technique called the ensemble connector
- Introduction of strategies to improve both attack types, including off-topic checking and regret prevention
- Empirical evaluation of EnJa on open-source and commercial LLMs

Problem Statement:
Despite alignment methods to protect LLMs from jailbreaks, carefully crafted malicious prompts can still bypass safety mechanisms, producing content that violates policy regulations. Existing jailbreak attacks have limitations in either effectiveness or efficiency.

Methodology:
1. Malicious Prompt Concealment:
   - Use LLM to transform malicious queries into concealed attack prompts
   - Employ off-topic checking to ensure prompts stay on-topic

2. Connector Template Design:
   - Create a transitional template to combine prompt-level and token-level attacks
   - Incorporate the beginning of the answer into the template

3. Adversarial Suffix Generation:
   - Improve GCG attack with regret prevention loss and multi-branch strategy
   - Optimize adversarial suffixes to boost attack success rate

4. Evaluation:
   - Test on open-source models: Vicuna-7B, Vicuna-13B, LLaMA-2-7B, LLaMA-2-13B
   - Test on closed-source models: GPT-3.5-turbo and GPT-4
   - Compare with baseline methods: GCG, PAIR, and GPTFuzzer

Main Results:
- EnJa achieves state-of-the-art attack success rates on both open-source and closed-source LLMs
- On Llama-2-7B, EnJa achieves a 94% attack success rate, compared to 64% for GCG and 31% for GPTFuzzer
- EnJa demonstrates high transferability to black-box models, achieving a 96% success rate on GPT-3.5-turbo and 56% on GPT-4

Qualitative Analysis:
- The ensemble approach of combining prompt-level and token-level attacks proves more effective than individual jailbreak methods
- The connector template plays a crucial role in integrating different attack types and maintaining attack coherence
- The regret prevention loss and multi-branch strategy significantly improve the efficiency of adversarial suffix generation

Limitations:
- The study focuses on jailbreaking LLMs and may raise ethical concerns about potential misuse
- The effectiveness of the attack on future, more robustly aligned LLMs is not addressed

Conclusion and Future Work:
The authors conclude that EnJa represents a significant advancement in jailbreak attacks on LLMs, highlighting the need for improved defense mechanisms. Future work may include:
- Developing more robust alignment techniques to counter ensemble attacks
- Exploring the generalization of EnJa to other types of language models
- Investigating ethical implications and potential countermeasures for such attacks

Relevant Figures:
Figure 1: Illustration of the proposed Ensemble Jailbreak (EnJa) framework on LLMs
Figure 2: Ablation study results on Llama-2-7B, showing the impact of different components on attack success rate and efficiency

Tools Introduced:
- EnJa: A novel ensemble jailbreak attack framework for LLMs (no GitHub repository mentioned)