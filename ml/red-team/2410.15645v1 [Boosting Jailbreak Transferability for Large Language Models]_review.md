#Tags
[[Research/Research Papers/2410.15645v1.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0054/LLMJailbreak

**Title:** Boosting Jailbreak Transferability for Large Language Models
**Authors:** Hanqing Liu, Lifeng Zhou, Huanqian Yan
**Affiliations:** 
- Hangzhou Innovation Institute, Beihang University (Liu)
- School of Computer Science and Technology, Anhui University (Zhou)
- Qiyuan laboratory (Yan)
**Publication Date:** October 21, 2024

Summary:
This paper presents a novel approach called SI-GCG to enhance jailbreak attacks on large language models (LLMs), focusing on improving transferability and attack success rates. The method combines scenario induction templates, optimized suffix selection, and re-suffix attack mechanisms to overcome limitations in existing techniques like GCG.

Key Contributions:
- Introduction of a scenario induction template considering both malicious question contexts and target templates
- Development of an automatic optimal suffix selection strategy
- Integration of a re-suffix attack mechanism to reduce inconsistent outputs
- Achievement of nearly 100% attack success rates and improved transferability across different LLMs

Problem Statement:
Existing jailbreak methods like GCG perform well in single-model attacks but lack transferability and efficiency in generating harmful content consistently.

Methodology:
1. Scenario Induction Template:
   - Fixed harmful template for malicious questions
   - Optimized response template incorporating harmful information
2. Automatic Optimal Suffix Selection:
   - Evaluation of top five suffixes with smallest losses at each optimization step
   - Selection based on both loss and harmfulness of generated content
3. Re-suffix Attack Mechanism:
   - Two-stage optimization process to ensure consistent harmful outputs
4. Experiments:
   - Dataset: 50 malicious questions provided by AI Singapore
   - Victim Models: LLAMA2-7B-CHAT and VICUNA-7B-1.5
   - Baselines: GCG and I-GCG

Main Results:
1. Track 1a (white-box setting):
   - SI-GCG achieved 96% and 98% attack success rates on LLAMA2-7B-CHAT and VICUNA-7B-1.5, respectively
   - Significantly outperformed GCG (46%, 24%) and I-GCG (54%, 80%)
2. Track 1b (black-box setting):
   - SI-GCG achieved 91.43% attack success rate on LLAMA2-7B-CHAT with initialization
3. Ablation Study:
   - Harmful templates greatly enhanced attack success rate and transferability
   - Combination of all proposed techniques achieved the best performance with minimal steps

Qualitative Analysis:
- The proposed method demonstrates superior performance in both attack execution and transferability compared to existing techniques
- The scenario induction template and optimal suffix selection strategy contribute significantly to the improved attack success rates
- The re-suffix attack mechanism helps maintain consistency in generating harmful content

Limitations:
- Computational resource constraints in the competition setting limited some experiments
- The study focused on specific LLMs, and broader applicability to other models needs further investigation

Conclusion and Future Work:
The SI-GCG method provides a powerful strategy for jailbreaking LLMs, achieving near-perfect success rates across various models. Its compatibility with other optimization methods enhances its versatility. Future work may involve exploring the method's effectiveness on a broader range of LLMs and developing robust defense mechanisms against such attacks.

Relevant Figures:
Figure 1: Illustration of how the fixed harmful template and optimized suffix guide an LLM to generate harmful responses
Figure 2: Illustration of the proposed automatic optimal suffix selection strategy

New Tools:
No specific new tools or GitHub repositories were mentioned in the paper.