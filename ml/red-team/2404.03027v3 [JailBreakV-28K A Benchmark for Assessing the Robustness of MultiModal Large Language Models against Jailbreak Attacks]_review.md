#Tags
[[Research/Research Papers/2404.03027v3.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0051/LLMPromptInjection
#AMLT0054/LLMJailbreak

**Title:** JailBreakV-28K: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks
**Authors:** Weidi Luo, Siyuan Ma, Xiaogeng Liu, Xiaoyu Guo, Chaowei Xiao
**Publication Date:** April 3, 2024

Summary:
This paper introduces JailBreakV-28K, a comprehensive benchmark for evaluating the robustness of Multimodal Large Language Models (MLLMs) against jailbreak attacks. The study investigates whether techniques used to jailbreak Large Language Models (LLMs) can be effectively transferred to MLLMs. The benchmark includes 28,000 test cases, combining text-based and image-based jailbreak attacks.

Key Contributions:
- Introduction of JailBreakV-28K benchmark for assessing MLLM robustness
- Creation of RedTeam-2K dataset with 2,000 malicious queries
- Generation of 20,000 text-based and 8,000 image-based jailbreak inputs
- Evaluation of 10 open-source MLLMs using the benchmark
- Analysis of the transferability of LLM jailbreak techniques to MLLMs

Problem Statement:
The study addresses the critical challenge of securing MLLMs against malicious inputs while aligning them with human values. It specifically investigates whether jailbreak techniques effective against LLMs can be transferred to MLLMs.

Methodology:
1. Creation of RedTeam-2K dataset:
   - Curated 2,000 harmful queries across 16 safety policies
   - Utilized various sources and generation methods
   
2. Development of JailBreakV-28K benchmark:
   - Generated 20,000 text-based jailbreak prompts using LLM jailbreak techniques
   - Created 8,000 image-based jailbreak inputs using recent MLLM jailbreak attacks
   
3. Evaluation of MLLMs:
   - Tested 10 open-source MLLMs using the JailBreakV-28K benchmark
   - Measured Attack Success Rate (ASR) for different types of attacks

Main Results:
1. High transferability of LLM jailbreak attacks to MLLMs
2. Text-based jailbreak attacks more effective than image-based attacks
3. MLLMs vulnerable regardless of image input in text-based attacks
4. Highest vulnerability in "Economic Harm" and "Malware" safety policies

Qualitative Analysis:
- The study reveals a critical vulnerability in MLLMs stemming from their text-processing capabilities
- Findings suggest that MLLMs inherit vulnerabilities from their LLM counterparts
- Results highlight the need for robust defense mechanisms that can adapt to evolving LLM transfer attacks in MLLMs

Limitations:
- Focus on open-source MLLMs only
- Potential bias in the generation of malicious queries and jailbreak prompts

Conclusion and Future Work:
- JailBreakV-28K provides a comprehensive benchmark for assessing MLLM robustness
- Urgent need for future research to address alignment vulnerabilities in MLLMs from both textual and visual inputs
- Calls for development of tailored defenses against jailbreak attacks in MLLMs

Tools Introduced:
- JailBreakV-28K benchmark (no GitHub repository mentioned)
- RedTeam-2K dataset (no GitHub repository mentioned)