#Tags
[[Research/Research Papers/2407.21659v2.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0031/ErodeMLModelIntegrity

**Title:** Defending Jailbreak Attack in VLMs via Cross-modality Information Detector
**Authors:** Yue Xu, Xiuyuan Qi, Zhan Qin, Wenjie Wang
**Affiliations:** 
- School of Information Science and Technology, ShanghaiTech University
- College of Computer Science and Technology, Zhejiang University
**Publication Date:** July 31, 2024

Summary:
This paper proposes CIDER (Cross-modality Information DEtectoR), a plug-and-play jailbreaking detector for Vision Language Models (VLMs). CIDER identifies maliciously perturbed image inputs by utilizing cross-modal similarity between harmful queries and adversarial images.

Key Contributions:
- Introduces CIDER, an effective and efficient pre-detection module for VLMs
- Demonstrates the effectiveness of using cross-modality information for defense
- Shows strong transferability across both white-box and black-box VLMs and attack methods

Problem Statement:
VLMs are susceptible to jailbreak attacks, where malicious users can break the safety alignment of the model and generate harmful answers. Existing defense methods either require model modifications or significant computational resources.

Methodology:
1. Utilize a diffusion-based denoiser to preprocess image inputs
2. Compare semantic similarity between text and image before and after denoising
3. Set a threshold based on the change in similarity to detect adversarially perturbed images
4. Implement CIDER as a plug-and-play module independent of target VLMs

Main Results:
1. CIDER achieves higher detection success rates compared to baseline methods
2. Significantly reduces attack success rates across multiple VLMs
3. Minimal computational overhead compared to existing defense methods
4. Strong transferability to both white-box and black-box VLMs and attack methods

Qualitative Analysis:
- Cross-modality information acts as a double-edged sword, increasing attack risks but also providing additional data for defense
- CIDER's effectiveness stems from exploiting the semantic relationship between harmful queries and adversarially perturbed images
- The approach is model-agnostic, making it widely applicable to various VLMs

Limitations:
- Some impact on VLM performance for normal tasks, particularly in recognition, knowledge, and language generation capabilities
- Primarily focused on optimization-based jailbreak attacks

Conclusion and Future Work:
CIDER demonstrates the potential of leveraging cross-modality information for defending VLMs against jailbreak attacks. Future work could focus on:
1. Improving CIDER's impact on normal VLM tasks
2. Extending the approach to other types of jailbreak attacks
3. Implementing multi-level thresholds for different types of content to balance safety and utility

Figures:
- Figure 1: Illustration of a typical VLM architecture
- Figure 2: Workflow of safeguarding VLM against jailbreak attacks via CIDER
- Figures 3-9: Various experimental results and ablation studies

New Tool:
CIDER (Cross-modality Information DEtectoR) - A plug-and-play jailbreaking detector for Vision Language Models
GitHub repository: Not provided in the paper