#Tags
[[Research/Research Papers/2410.16155v1.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0018/BackdoorMLModel
#AMLT0020/PoisonTrainingData
#AMLT0031/ErodeMLModelIntegrity
#AMLT0043/CraftAdversarialData

**Title:** A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns
**Authors:** Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao
**Affiliations:** 
- The Key Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China
- School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China
**Publication Date:** October 21, 2024

Summary:
This paper introduces the Troublemaker Makes Chaos in Honest Towns (TMCHT) task, a framework for evaluating multi-agent, multi-topology text-based attacks on language model agents. The authors propose a novel Adversarial Replication Contagious Jailbreak (ARCJ) method to address challenges in attacking multi-agent systems with independent memory.

Key Contributions:
1. Introduction of the TMCHT task for evaluating security in multi-agent LLM systems
2. Identification of the "toxicity disappearing" phenomenon in multi-agent attacks
3. Development of the ARCJ method to enhance attack effectiveness in multi-agent scenarios
4. Demonstration of improved attack performance across various topologies and scales

Problem Statement:
Existing research on jailbreak attacks for language models focuses primarily on single-agent scenarios or shared memory in multi-agent systems. However, real-world applications often involve multiple agents with independent memory, creating new challenges for attackers.

Methodology:
1. TMCHT Task:
   - Defines a multi-agent environment with various topologies (graph, line, star)
   - Includes one attacker agent attempting to mislead multiple clean agents
   - Evaluates attack success across different agent densities and interaction rounds

2. ARCJ Method:
   - Stage 1: Optimize retrieval suffix to improve poisoned sample retrieval
   - Stage 2: Optimize replication suffix to enhance contagious capabilities of poisoned samples

3. Evaluation:
   - Compared ARCJ against baseline methods (Clean, GCG) across different topologies and scales
   - Measured Attack Success Rate (ASR) and attack speed

Main Results:
1. ARCJ outperformed baselines across all tested scenarios:
   - Line topology: 44.20% ASR (23.51% improvement)
   - Star topology: 38.94% ASR (18.95% improvement)
   - 100-agent setting: 85.18% ASR (52.93% improvement)

2. ARCJ demonstrated faster attack speeds and higher ASR in large-scale systems

Qualitative Analysis:
- The authors attribute the success of ARCJ to its ability to mitigate the "toxicity disappearing" phenomenon
- ARCJ's two-stage optimization process allows for both improved retrieval and enhanced propagation of poisoned information
- The method shows particular effectiveness in non-complete graph structures and large-scale systems, addressing key challenges in real-world scenarios

Limitations:
- The study is limited to a maximum of 100 agents due to computational constraints
- The effectiveness of the method in even larger-scale systems (thousands of agents) remains untested
- The paper does not extensively discuss potential defensive measures against the proposed attack

Conclusion and Future Work:
- The paper demonstrates the vulnerability of multi-agent LLM systems to contagious jailbreak attacks
- The authors encourage the research community to focus on the security of multi-agent architectures
- Future work may include scaling the simulations to thousands of agents and developing defensive strategies

Relevant Figures:
- Figure 1: Illustration of attack memory, multi-agent attack, and toxicity disappearing phenomenon
- Figure 5: Overview of the ARCJ method architecture

New Tools:
- TMCHT: A large-scale, multi-agent, multi-topology text-based attack evaluation framework
- ARCJ: Adversarial Replication Contagious Jailbreak method for enhancing attack effectiveness in multi-agent systems