#Tags
[[Research/Research Papers/2406.09324v2.pdf]]

#AMLT0054/LLMJailbreak
#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0051/LLMPromptInjection

**Title:** Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs
**Authors:** Zhao Xu, Fan Liu, Hao Liu
**Affiliations:** AI Thrust, The Hong Kong University of Science and Technology (Guangzhou)
**Publication Date:** October 4, 2024 (last updated)

Summary:
This paper provides a comprehensive evaluation of jailbreak attacks on Large Language Models (LLMs), focusing on key factors affecting attack performance and benchmarking various attack methods against different defense strategies. The study aims to standardize the evaluation of jailbreak attacks and highlight the need for robust defense mechanisms.

Key Contributions:
- Evaluation of 8 key factors influencing jailbreak attacks on LLMs
- Comprehensive benchmarking of 7 jailbreak attacks against 6 defense methods
- Analysis of the impact of various attack settings on LLM performance
- Proposal for a standardized evaluation framework for jailbreak attacks

Problem Statement:
The paper addresses the lack of comprehensive understanding of LLM vulnerabilities to jailbreak attacks, particularly the impact of various implementation details and the effectiveness of defense methods.

Methodology:
- Evaluation of key factors: model size, fine-tuning alignment, safety system prompt, template type, attacker ability, adversarial suffix length, attack budget, and attack intention
- Implementation of 7 jailbreak attacks: GCG, AutoDAN, AmpleGCG, AdvPrompter, PAIR, TAP, and GPTFuzz
- Testing of 6 defense methods: Self-Reminder, RPO, SmoothLLM, Adversarial Training, Unlearning, and Safety Training
- Experiments conducted on two datasets: AdvBench and MaliciousInstruct
- Use of various LLM models, including Llama-2 and Vicuna series

Main Results:
1. Model robustness does not strictly correlate with model size
2. Fine-tuning can significantly affect the original LLM's safety alignment
3. Safe system prompts can substantially enhance LLM robustness
4. Unsuitable chat templates may impact LLM vulnerability
5. Attacker ability significantly influences attack performance
6. Longer adversarial suffixes increase the likelihood of successful attacks up to a certain point
7. Attack budget has varying effects on token-level and prompt-level attacks
8. Different attack intentions result in varying attack success rates

Qualitative Analysis:
- The study highlights the complexity of factors influencing LLM vulnerability to jailbreak attacks
- Results emphasize the need for a standardized approach to evaluating and comparing jailbreak attacks
- Findings suggest that current defense methods may negatively impact model utility to varying degrees

Limitations:
- Experiments limited by computational resources and API costs
- Focus on specific LLM models and datasets may not fully represent real-world application scenarios

Conclusion and Future Work:
The paper concludes that standardized benchmarking is crucial for understanding and mitigating jailbreak attack risks on LLMs. It emphasizes the need for continuous benchmarking and the development of standardized evaluation frameworks to ensure the reliability and safety of LLMs.

New Tools:
The authors have released their code for reproducing the experiments and benchmarks at:
https://github.com/usail-hkust/Bag_of_Tricks_for_LLM_Jailbreaking

## Repository Token Information
Total tokens in repository: 200000

Tokens per file:
- FastChat/fastchat/model/model_adapter.py: 20757 tokens
- FastChat/fastchat/conversation.py: 17696 tokens
- baseline/GCG/base/attack_manager.py: 13262 tokens
- defenses/LLaMA-Factory/src/llmtuner/extras/constants.py: 12494 tokens
- defenses/LLaMA-Factory/src/llmtuner/webui/locales.py: 11005 tokens
- baseline/DrAttack/drattack/ga/ga_attack.py: 8429 tokens
- FastChat/fastchat/serve/gradio_web_server.py: 8158 tokens
- defenses/LLaMA-Factory/src/llmtuner/data/template.py: 7956 tokens
- FastChat/fastchat/serve/monitor/monitor.py: 7757 tokens
- FastChat/fastchat/serve/api_provider.py: 7254 tokens
- FastChat/fastchat/model/model_registry.py: 6864 tokens
- FastChat/fastchat/serve/openai_api_server.py: 6802 tokens
- baseline/GPTFuzz/example/finetune_roberta.py: 6105 tokens
- FastChat/fastchat/serve/gradio_block_arena_anony.py: 5598 tokens
- FastChat/fastchat/llm_judge/common.py: 5595 tokens
- FastChat/fastchat/serve/monitor/elo_analysis.py: 5221 tokens
- baseline/AutoDAN/utils/opt_utils.py: 5051 tokens
- FastChat/fastchat/serve/gradio_block_arena_vision_anony.py: 4620 tokens
- defenses/LLaMA-Factory/src/llmtuner/train/ppo/trainer.py: 4292 tokens
- baseline/TAP/conversers.py: 4285 tokens
- FastChat/fastchat/serve/inference.py: 3936 tokens
- main.py: 3769 tokens
- utils/test_utils.py: 3725 tokens
- FastChat/fastchat/serve/gradio_block_arena_named.py: 3719 tokens
- FastChat/fastchat/train/train_yuan2.py: 3685 tokens
- FastChat/fastchat/serve/lightllm_worker.py: 3677 tokens
- defenses/LLaMA-Factory/src/llmtuner/train/utils.py: 3661 tokens
- defenses/Unlearning/utils.py: 3574 tokens
- defenses/LLaMA-Factory/src/llmtuner/webui/runner.py: 1053 tokens
