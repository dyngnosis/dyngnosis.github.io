#Tags
[[Research/Research Papers/2406.19845v2.pdf]]

#AMLT0054/LLMJailbreak
#AMLT0051/LLMPromptInjection
#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData

**Title:** Virtual Context: Enhancing Jailbreak Attacks with Special Token Injection
**Authors:** Yuqi Zhou, Lin Lu, Hanchi Sun, Pan Zhou, Lichao Sun
**Affiliations:** Huazhong University of Science and Technology, Lehigh University
**Publication Date:** July 11, 2024 (last updated)

Key Contributions:
- Introduces Virtual Context, a novel jailbreak attack method using special tokens
- Significantly improves success rates of existing jailbreak methods by ~40%
- Requires minimal background knowledge about target models
- Effective in black-box settings without additional overhead
- Demonstrates effectiveness across various LLMs and generation configurations

Problem Statement:
Current jailbreak attacks on Large Language Models (LLMs) face challenges of low success rates due to defensive measures and high resource requirements for crafting specific prompts.

Methodology:
1. Leverages special tokens (e.g., <SEP>) to create a Virtual Context
2. Injects affirmative responses using special tokens into user inputs
3. Deceives LLM into perceiving user inputs as self-generated content
4. Evaluated on multiple LLMs: Mixtral-7x8B, Vicuna-13B, LLaMa-2-70B, GPT-3.5, GPT-4
5. Compared with baseline jailbreak methods: GCG, AutoDAN, DeepInception, PAIR
6. Used datasets: AdvBench and MaliciousInstruct
7. Metrics: Response Prefix Matching (Matching), Attack Success Rate (ASR), Harm Score (HS)

Main Results:
1. Virtual Context improved success rates of existing jailbreak methods by ~40% across various LLMs
2. Achieved high jailbreak success rates (>30%) even when applied directly to original malicious behaviors
3. Demonstrated strong generalizability across different generation configurations (Top-p, Temperature, Top-k)
4. Reduced resource consumption compared to traditional optimization techniques
5. Improved readability of jailbreak prompts, potentially bypassing defenses based on semantic consistency

Qualitative Analysis:
- Virtual Context exploits LLMs' interpretation of special tokens, creating a perceived affirmative context
- The method's effectiveness highlights a potential security vulnerability in the use of special tokens during LLM inference
- The approach's simplicity and generalizability make it a significant threat to LLM security

Limitations:
- Focus on <SEP> token, overlooking potential vulnerabilities in other special tokens
- Lack of comprehensive defensive testing against the proposed method
- Potential ethical concerns regarding the development and publication of jailbreak techniques

Conclusion and Future Work:
- Virtual Context significantly enhances jailbreak attacks on LLMs
- Recommends including this threat in red-teaming testing to improve LLM security
- Suggests further investigation into the role of special tokens in LLM security
- Proposes the development of defensive measures against special token manipulation

Relevant Figures:
Figure 1: Comparison of traditional jailbreak methods with Virtual Context assisted jailbreak
Figure 2: Attack success rates (ASR) for different decoding configurations
Figure 3: Log-PPL for different attack methods

New Tool:
Virtual Context: A method for enhancing jailbreak attacks using special token injection. No specific GitHub repository mentioned.