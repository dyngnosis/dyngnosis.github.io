#Tags
[[Research/Research Papers/2407.08956v1.pdf]]

#AMLT0018/BackdoorMLModel
#AMLT0020/PoisonTrainingData
#AMLT0031/ErodeMLModelIntegrity
#AMLT0043/CraftAdversarialData

**Title:** DeCE: Deceptive Cross-Entropy Loss Designed for Defending Backdoor Attacks
**Authors:** Guang Yang, Yu Zhou, Xiang Chen, Xiangyu Zhang, Terry Yue Zhuo, David Lo, Taolue Chen
**Publication Date:** July 12, 2024

Key Contributions:
- Confirmation of the "early learning" phenomenon in Code Language Models (CLMs)
- Analysis of cross-entropy loss function's role in backdoor attack vulnerability
- Introduction of DeCE (Deceptive Cross-Entropy) loss function for defending against backdoor attacks
- Comprehensive evaluation of DeCE across multiple datasets, models, and poisoning ratios

Problem Statement:
Existing defense methods against backdoor attacks in CLMs lack effectiveness and generality, failing to consistently mitigate these attacks across different models and scenarios.

Methodology:
1. Empirical study to reproduce the "early learning" phenomenon in CLMs
2. Analysis of cross-entropy loss function's impact on backdoor attack vulnerability
3. Development of DeCE loss function using deceptive distributions and label smoothing
4. Evaluation of DeCE on code synthesis tasks using various datasets, models, and poisoning ratios

Main Results:
1. DeCE outperforms existing active defense methods in countering backdoor attacks while preserving CLM performance on clean datasets
2. DeCE achieves a balance between maintaining BLEU scores and reducing Attack Success Rate (ASR)
3. DeCE demonstrates effectiveness across different models (CodeBERT, GraphCodeBERT, CodeGen, CodeT5, CodeT5p) and datasets (Lyra, Pisces, Bugs2Fix)

Qualitative Analysis:
- DeCE addresses the limitations of existing defense methods by providing a more balanced approach to security and performance
- The "early learning" phenomenon in CLMs is similar to observations in NLP and Computer Vision, suggesting a common vulnerability across different domains
- The effectiveness of DeCE highlights the importance of considering the loss function in designing defense mechanisms against backdoor attacks

Limitations:
- The study focuses primarily on code synthesis tasks, and the effectiveness of DeCE in other code intelligence domains needs further investigation
- The optimal selection of hyperparameters (α and ε) for DeCE may require fine-tuning for different scenarios

Conclusion and Future Work:
- DeCE provides a promising defense mechanism against backdoor attacks in CLMs
- Future work should focus on optimizing DeCE's hyperparameters and exploring its applicability to other areas of code intelligence beyond code synthesis

Relevant Figures:
- Figure 3: Performance of CLMs on the validation set over training epochs when trained on the poisoned Lyra dataset
- Figure 4: Hyperparameter sensitivity analysis of DeCE on the Lyra dataset with a 5% poisoning ratio under BadPre

New Tool:
DeCE (Deceptive Cross-Entropy) loss function for defending against backdoor attacks in Code Language Models. No GitHub repository is mentioned in the paper.