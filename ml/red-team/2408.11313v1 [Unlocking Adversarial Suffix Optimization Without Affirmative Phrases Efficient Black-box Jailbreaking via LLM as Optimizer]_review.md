#Tags
[[Research/Research Papers/2408.11313v1.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0054/LLMJailbreak
#AMLT0017/DevelopCapabilities

**Title:** Unlocking Adversarial Suffix Optimization Without Affirmative Phrases: Efficient Black-box Jailbreaking via LLM as Optimizer
**Authors:** Weipeng Jiang, Zhenting Wang, Juan Zhai, Shiqing Ma, Zhengyu Zhao, Chao Shen
**Publication Date:** August 21, 2024 (preprint)

Key Contributions:
- Introduces ECLIPSE, a novel black-box jailbreaking method using optimizable suffixes
- Leverages LLMs as both generators and optimizers for jailbreaking
- Achieves high attack success rates (ASR) while reducing attack overhead

Problem Statement:
Existing jailbreaking methods for LLMs have limitations:
- Template-based methods require significant manual effort and domain knowledge
- Optimization-based methods (e.g., GCG) need white-box access and pre-constructed affirmative phrases

Methodology:
1. Task Prompting:
   - Translates jailbreaking goals into natural language instructions
   - Guides LLM to generate adversarial suffixes for malicious queries

2. Harmfulness Scorer:
   - Provides continuous feedback on generated suffixes
   - Enables LLM self-reflection and iterative optimization

3. Reference Selection:
   - Maintains a history of generated suffixes and their efficacy scores
   - Uses hybrid sampling strategy for exploration and exploitation

4. Algorithm:
   - Iterative optimization framework with up to K rounds
   - Generates and evaluates multiple candidate suffixes in batches

Main Results:
1. Attack Success Rate (ASR):
   - ECLIPSE: 0.92 average ASR across three open-source LLMs and GPT-3.5-Turbo
   - Outperforms GCG by 2.4 times

2. Efficiency:
   - Reduces average attack overhead by 83% compared to template-based methods
   - Decreases query numbers by 45%

3. Model Performance:
   - LLaMA2-7B-Chat: 0.75 ASR
   - Vicuna-7B: 0.99 ASR
   - Falcon-7B-Instruct: 0.98 ASR
   - GPT-3.5-Turbo: 0.97 ASR

Qualitative Analysis:
- ECLIPSE demonstrates the potential of using LLMs as optimizers for jailbreaking
- The method's success highlights vulnerabilities in current LLM safety measures
- The approach balances exploration and exploitation in suffix generation

Limitations:
- Relies on instruction-following capabilities of LLMs
- Potential ethical concerns regarding the generation of harmful content

Conclusion and Future Work:
- ECLIPSE provides an efficient black-box jailbreaking method without affirmative phrases
- Future work may focus on improving robustness against this type of attack and developing more sophisticated defense mechanisms

Tools Introduced:
- ECLIPSE: A novel black-box jailbreaking method
  GitHub: https://github.com/lenijwp/ECLIPSE

## Repository Token Information
Total tokens in repository: 6079

Tokens per file:
- Eclipse.py: 3102 tokens
- Eclipse-gpt.py: 2977 tokens


## Tutorial and Enhancement Suggestions

# ECLIPSE Tutorial

## Project Overview

ECLIPSE (Efficient CLassifier-guided Iterative Prompt Suffix Exploration) is a novel black-box jailbreaking method for large language models (LLMs). The project aims to generate adversarial suffixes that can bypass LLM safety measures without relying on pre-constructed affirmative phrases.

The repository contains two main Python scripts:
1. `Eclipse.py`: Implements the ECLIPSE method for open-source LLMs
2. `Eclipse-gpt.py`: Adapts the method for use with GPT-3.5-Turbo

## Key Components and Functionality

### 1. Command-Line Arguments

Both scripts use `argparse` to handle various configuration options, including:
- Target model selection
- Attacker model selection (for `Eclipse.py`)
- Optimization parameters (batch size, rounds, temperature)
- Scorer selection
- Dataset choice

### 2. Model Loading

For open-source models (`Eclipse.py`):
```python
target_model = AutoModelForCausalLM.from_pretrained(MODEL_PATH[target_name], ...)
target_tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH[target_name], ...)
```

For GPT-3.5-Turbo (`Eclipse-gpt.py`):
```python
client = openai.OpenAI()
```

### 3. Judger (Harmfulness Scorer)

The `Judger` function evaluates the harmfulness of generated responses:

```python
def Judger(gen_texts, cl_model, cl_tokenizer, initial_sentence, device):
    # ... (implementation details)
    return scores
```

It uses a pre-trained classifier (e.g., GPTFuzz) to assign scores to generated texts.

### 4. Suffix Generation and Optimization

The core of ECLIPSE is an iterative process that generates and optimizes adversarial suffixes:

```python
for meta_input in behaviors:
    for itr in range(K_round):
        # Generate suffixes
        # Evaluate suffixes
        # Update results
```

Key steps include:
- Constructing prompts with historical references
- Generating candidate suffixes
- Evaluating suffix effectiveness
- Updating the pool of successful suffixes

### 5. Results Logging and Storage

The scripts use Python's `logging` module and JSON file storage to track and save results:

```python
logging.basicConfig(filename=f'./result/log/...', level=logging.DEBUG, ...)
with open(JSON_path, "w") as json_file:
    json.dump(possible_jbk_prompts, json_file, indent=4)
```

## Relation to Research Concepts

1. **Task Prompting**: Implemented through the `query_prompt_base` variable, which instructs the LLM to generate adversarial suffixes.

2. **Harmfulness Scorer**: Realized in the `Judger` function, providing continuous feedback on generated suffixes.

3. **Reference Selection**: Implemented in the main loop, where historical results are sampled and included in prompts.

4. **Iterative Optimization**: The nested loop structure in both scripts corresponds to the K-round optimization framework described in the paper.

## Notable Algorithms and Techniques

1. **Suffix Extraction**: Uses regex to extract generated suffixes from LLM outputs.

2. **Hybrid Sampling**: Combines top-performing suffixes with randomly sampled ones for reference selection.

3. **Batch Processing**: Generates and evaluates multiple suffixes in parallel to improve efficiency.

4. **Score Thresholding**: Uses score thresholds (e.g., 0.3 and 0.5) to filter and prioritize successful suffixes.

# Potential Enhancements

1. **Dynamic Optimization Parameters**
   - Implement adaptive batch sizes and temperatures based on optimization progress
   - This could improve efficiency by adjusting exploration-exploitation balance dynamically

2. **Multi-Model Ensemble**
   - Extend the framework to use multiple LLMs for suffix generation and optimization
   - Combine insights from different models to create more robust adversarial suffixes

3. **Advanced Scorer Integration**
   - Incorporate more sophisticated harmfulness scorers (Llama Guard)
   - This could provide more nuanced feedback and potentially improve jailbreaking success rates

4. **Prompt Engineering Techniques**
   - Integrate advanced prompt engineering methods (e.g., chain-of-thought, few-shot learning) into the suffix generation process
   - This might lead to more diverse and effective adversarial suffixes

5. **Defensive Capabilities**
   - Extend the project to include a module for testing LLM robustness against generated suffixes
   - Develop and evaluate potential defense mechanisms, contributing to safer LLM deployment

These enhancements address efficiency, functionality extension, and the application of recent advancements in the field of LLM security and optimization.