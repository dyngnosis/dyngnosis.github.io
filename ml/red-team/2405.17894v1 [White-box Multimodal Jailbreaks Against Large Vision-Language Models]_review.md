#Tags
[[Research/Research Papers/2405.17894v1.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0044/FullMLModelAccess
#AMLT0054/LLMJailbreak

**Title:** White-box Multimodal Jailbreaks Against Large Vision-Language Models
**Authors:** Ruofan Wang, Xingjun Ma, Hanxu Zhou, Chuanjun Ji, Guangnan Ye, Yu-Gang Jiang
**Publication Date:** May 28, 2024

Summary:
This paper introduces a novel multimodal attack strategy against Large Vision-Language Models (VLMs), exploiting vulnerabilities in both text and image modalities. The proposed method, called Universal Master Key (UMK), uses dual optimization objectives to generate affirmative responses with high toxicity, effectively jailbreaking VLMs.

Key Contributions:
- First to introduce text-image multimodal adversarial attacks against VLMs
- Proposal of a dual optimization objective strategy for crafting adversarial examples
- Development of the Universal Master Key (UMK) concept for jailbreaking VLMs
- Demonstration of high attack success rates against MiniGPT-4

Problem Statement:
The paper addresses the lack of comprehensive adversarial robustness assessment for VLMs, particularly in multimodal attack scenarios. It challenges the assumption that VLMs are inherently resilient against text-based attacks.

Methodology:
1. Initialization of adversarial image prefix with random noise
2. Optimization of image prefix to generate harmful responses without text input
3. Introduction of adversarial text suffix
4. Joint optimization of image prefix and text suffix to maximize affirmative response probability
5. Integration of UMK into malicious queries to bypass VLM defenses

Main Results:
- 96% attack success rate on MiniGPT-4 using the proposed UMK method
- Outperformance of existing unimodal attack methods across various evaluation metrics
- Demonstration of UMK's effectiveness in generating objectionable content and bypassing alignment defenses

Qualitative Analysis:
- The multimodal attack strategy exploits a broader range of vulnerabilities in VLMs compared to unimodal approaches
- The dual optimization objective addresses issues of insufficient toxicity and poor instruction adherence in generated responses
- The success of UMK highlights the urgent need for new alignment strategies in VLMs

Limitations:
- Constrained transferability of the attack across different VLM architectures
- Potential ethical concerns regarding the generation and use of toxic content

Conclusion and Future Work:
The paper demonstrates the vulnerability of VLMs to multimodal attacks and emphasizes the need for improved robustness and alignment strategies. Future work may focus on enhancing the transferability of the attack across different VLM architectures and developing more effective defense mechanisms.

Relevant Figures:
Figure 1: Example of Jailbreak Attack on MiniGPT-4
Figure 2: Overview of the multimodal attack strategy

New Tools:
Universal Master Key (UMK): A multimodal adversarial example comprising an adversarial image prefix and text suffix, designed to jailbreak VLMs.