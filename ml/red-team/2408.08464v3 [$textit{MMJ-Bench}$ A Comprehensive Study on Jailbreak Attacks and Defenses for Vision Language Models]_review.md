#Tags
[[Research/Research Papers/2408.08464v3.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0054/LLMJailbreak
#AMLT0031/ErodeMLModelIntegrity

**Title:** MMJ-Bench: A Comprehensive Study on Jailbreak Attacks and Defenses for Multimodal Large Language Models
**Authors:** Fenghua Weng, Yue Xu, Chengyan Fu, Wenjie Wang
**Affiliation:** ShanghaiTech University, China
**Publication Date:** 21 Oct 2024

Key Contributions:
- Introduced MMJ-Bench, a unified pipeline for evaluating jailbreak attacks and defense techniques for MLLMs
- Conducted extensive experiments assessing various attack methods against state-of-the-art MLLMs
- Evaluated the impact of defense mechanisms on both defense effectiveness and model utility for normal tasks
- Developed and publicly released the first comprehensive benchmark for MLLM jailbreak research

Problem Statement:
The paper addresses the lack of unified and comprehensive evaluations of jailbreak attacks and defenses for Multimodal Large Language Models (MLLMs). Current methods use different datasets, target models, and evaluation metrics, making it difficult to assess their effectiveness comprehensively.

Methodology:
1. Data Collection: Used HarmBench dataset for harmful queries and MM-Vet dataset for normal tasks evaluation
2. Jailbreak Cases Generation: Implemented six attack methods (3 generation-based, 3 optimization-based)
3. Response Generation: Evaluated four defense techniques on six MLLMs from four model families
4. Evaluation: Used GPT-4 and a binary classifier to determine harmful content, calculated Attack Success Rate (ASR) and Detection Success Rate (DSR)

Main Results and Findings:
1. The effectiveness of each attack varies among MLLMs
2. Generation-based attacks are more effective according to the GPT-4 evaluator, while optimization-based techniques perform better according to the HarmBench classifier
3. No MLLM is uniformly robust to all jailbreak attacks
4. The selection of evaluators matters as different evaluators yield different ASR
5. Lower ASR doesn't necessarily indicate stronger safety guardrail

Qualitative Analysis:
- The study highlights the complexity of evaluating MLLM security, as different attack methods and evaluation criteria can lead to varying results
- The findings emphasize the need for comprehensive and standardized evaluation methods for MLLM security
- The trade-off between model utility and defense effectiveness is a crucial consideration in developing robust MLLMs

Limitations:
- The study focuses on a limited set of attack and defense methods
- The evaluation is based on specific datasets and may not cover all possible real-world scenarios
- The reliance on GPT-4 as an evaluator may introduce biases or limitations in assessing harmfulness

Conclusion and Future Work:
- MMJ-Bench provides a systematic and unified pipeline for evaluating jailbreak attacks and defenses in MLLMs
- The study reveals important insights into the effectiveness of various attack and defense methods
- Future work should focus on continuously updating MMJ-Bench with new attacks and defenses to advance the development of safer and more secure MLLMs

Tools Introduced:
MMJ-Bench: A comprehensive benchmark for MLLM jailbreak research
GitHub Repository: https://github.com/thunxxx/MLLM-Jailbreak-evaluation-MMJ-bench

## Repository Token Information
Total tokens in repository: 200000

Tokens per file:
- multimodalmodels/qwen/modeling_qwen.py: 9830 tokens
- multimodalmodels/minigpt4/minigpt4/models/Qformer.py: 9583 tokens
- attacks/xidian/utils/minigpt4/models/Qformer.py: 9583 tokens
- attacks/xidian/utils/torchattacks/attacks/_differential_evolution.py: 8822 tokens
- attacks/xidian/utils/torchattacks/attacks/fab.py: 8271 tokens
- multimodalmodels/qwen/tokenization_qwen.py: 5139 tokens
- attacks/xidian/utils/minigpt4/models/eva_vit.py: 5045 tokens
- attacks/xidian/utils/minigpt4/models/.ipynb_checkpoints/eva_vit-checkpoint.py: 5041 tokens
- multimodalmodels/minigpt4/minigpt4/models/eva_vit.py: 5032 tokens
- attacks/xidian/utils/torchattacks/attacks/square.py: 4668 tokens
- multimodalmodels/minigpt4/minigpt4/runners/runner_base.py: 4646 tokens
- attacks/xidian/utils/minigpt4/runners/runner_base.py: 4622 tokens
- attacks/xidian/utils/torchattacks/attack_noise.py: 4417 tokens
- attacks/xidian/utils/torchattacks/attack.py: 4379 tokens
- attacks/xidian/xidian.py: 4088 tokens
- multimodalmodels/qwen/openai_api.py: 4002 tokens
- multimodalmodels/minigpt4/minigpt4/datasets/builders/image_text_pair_builder.py: 3874 tokens
- multimodalmodels/minigpt4/minigpt4/models/minigpt_base.py: 3821 tokens
- attacks/xidian/utils/minigpt4/models/minigpt_base.py: 3803 tokens
- multimodalmodels/qwen/visual.py: 3791 tokens
- attacks/xidian/utils/minigpt4/models/.ipynb_checkpoints/minigpt_base-checkpoint.py: 3791 tokens
- attacks/xidian/utils/minigpt4/common/config_1.py: 3686 tokens
- eval_utils.py: 3680 tokens
- attacks/xidian/utils/minigpt4/datasets/builders/image_text_pair_builder.py: 3639 tokens
- attacks/xidian/utils/torchattacks/attacks/apgd.py: 3548 tokens
- multimodalmodels/minigpt4/minigpt4/datasets/datasets/coco_dataset.py: 3487 tokens
- attacks/xidian/utils/minigpt4/datasets/datasets/coco_dataset.py: 3481 tokens
- attacks/xidian/utils/torchattacks/attacks/apgdt.py: 3457 tokens
- multimodalmodels/qwen/qwen_generation_utils.py: 3333 tokens
- multimodalmodels/minigpt4/minigpt4/processors/randaugment.py: 3297 tokens
- attacks/xidian/utils/minigpt4/processors/randaugment.py: 3297 tokens
- attacks/xidian/utils/minigpt4/common/config.py: 3294 tokens
- multimodalmodels/minigpt4/minigpt4/common/config.py: 3288 tokens
- multimodalmodels/minigpt4/minigpt4/common/utils.py: 3169 tokens
- attacks/xidian/utils/minigpt4/common/utils.py: 3166 tokens
- attacks/xidian/utils/torchattacks/attacks/pixle.py: 3140 tokens
- attacks/baseline.py: 3052 tokens
- multimodalmodels/qwen/finetune.py: 2957 tokens
- multimodalmodels/minigpt4/minigpt4/common/vqa_tools/vqa_eval.py: 2912 tokens
- attacks/xidian/utils/minigpt4/common/vqa_tools/vqa_eval.py: 2912 tokens
- multimodalmodels/minigpt4/minigpt4/common/vqa_tools/VQA/PythonEvaluationTools/vqaEvaluation/vqaEval.py: 2834 tokens
- attacks/xidian/utils/minigpt4/common/vqa_tools/VQA/PythonEvaluationTools/vqaEvaluation/vqaEval.py: 2834 tokens
- attacks/hades/utils.py: 2403 tokens
- multimodalmodels/minigpt4/minigpt_utils/text_attacker.py: 2389 tokens
- multimodalmodels/qwen/web_demo_mm.py: 2382 tokens
- attacks/xidian/utils/torchattacks/attacks/eaden.py: 2290 tokens
- multimodalmodels/minigpt4/minigpt_utils/visual_attacker.py: 2288 tokens
- attacks/xidian/utils/torchattacks/attacks/eadl1.py: 2283 tokens
- attacks/xidian/utils/torchattacks/wrappers/lgv.py: 1254 tokens
