#Tags
[[Research/Research Papers/2406.09324v1.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0054/LLMJailbreak

**Title:** Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs
**Authors:** Zhao XU, Fan LIU, Hao LIU
**Affiliations:** AI Thrust, The Hong Kong University of Science and Technology (Guangzhou)
**Publication Date:** June 13, 2024 (preprint)

Summary:
This paper provides a comprehensive benchmarking of jailbreak attacks on Large Language Models (LLMs), evaluating the impact of various attack settings and defense methods. The authors conduct extensive experiments to analyze key factors affecting jailbreak attacks from both target model and attacker perspectives.

Key Contributions:
- Evaluation of eight key factors influencing jailbreak attacks on LLMs
- Comprehensive benchmarking of seven representative jailbreak attacks against six defense methods
- Analysis of the impact of various attack settings on LLM performance
- Baseline benchmark for jailbreak attacks on two widely used datasets

Problem Statement:
The paper addresses the lack of standardized evaluation frameworks for jailbreak attacks on LLMs, particularly for defense-enhanced models. It aims to provide a comprehensive understanding of the vulnerabilities in LLMs and the effectiveness of various defense methods.

Methodology:
- Evaluation of key factors: model size, fine-tuning alignment, safety system prompt, template type, attacker ability, adversarial suffix length, attack budget, and attack intention
- Implementation of seven jailbreak attacks: GCG, AutoDAN, AmpleGCG, AdvPrompter, PAIR, TAP, and GPTFuzz
- Testing of six defense methods: Self-Reminder, RPO, SmoothLLM, Adversarial Training, Unlearning, and Safety Training
- Experiments conducted on two datasets: AdvBench and MaliciousInstruct
- Use of various LLM models, including Llama-2 and Vicuna series

Main Results:
1. Model robustness does not strictly correlate with model size
2. Fine-tuning can substantially affect the original LLM's safety alignment
3. Safe system prompts significantly enhance LLM robustness
4. Unsuitable chat templates may impact LLM vulnerability
5. Attacker's skill level significantly influences attack performance
6. Longer adversarial suffixes increase the likelihood of generating jailbroken responses up to a certain point
7. For token-level jailbreaks, the Attack Success Rate (ASR) increases significantly with the attack budget, while for prompt-level jailbreaks, the impact is minimal

Qualitative Analysis:
- The paper highlights the importance of considering multiple factors when evaluating LLM vulnerabilities and defenses
- Results suggest that improper attack settings can significantly degrade attack performance
- The study emphasizes the need for standardized benchmarking to evaluate jailbreak attacks on defense-enhanced LLMs

Limitations:
- Experiments were limited by computational resources and API costs, preventing expansion to more target models and larger datasets
- The experimental setup may not fully replicate real-world application scenarios

Conclusion and Future Work:
The paper provides valuable insights into the key factors affecting jailbreak attacks on LLMs and emphasizes the need for standardized evaluation frameworks. Future work should focus on developing more robust defense methods and exploring cost-effective attack techniques that do not rely on closed-source LLMs.

Relevant Figures/Tables:
- Table 1: Hyperparameter settings and tricks employed to implement various jailbreaks on LLMs
- Figure 1: Overview of benchmarking jailbreak attacks on LLMs
- Tables 3 and 4: Jailbreak attack experiments on datasets AdvBench and MaliciousInstruct

Tools Introduced:
The authors mention that their code is available at https://github.com/usail-hkust/Bag_of_Tricks_for_LLM_Jailbreaking, which likely includes implementations of the jailbreak attacks and defense methods discussed in the paper.

## Repository Token Information
Total tokens in repository: 378844

Tokens per file:
- initialize_args.py: 2591 tokens
- defense.py: 1891 tokens
- main.py: 3199 tokens
- requirements.txt: 3592 tokens
- README.md: 2575 tokens
- FastChat/README.md: 5332 tokens
- FastChat/docs/gptq.md: 832 tokens
- FastChat/docs/server_arch.md: 16 tokens
- FastChat/docs/training.md: 1235 tokens
- FastChat/docs/vicuna_weights_version.md: 1675 tokens
- FastChat/docs/model_support.md: 3142 tokens
- FastChat/docs/third_party_ui.md: 528 tokens
- FastChat/docs/xFasterTransformer.md: 999 tokens
- FastChat/docs/mlx_integration.md: 211 tokens
- FastChat/docs/openai_api.md: 1280 tokens
- FastChat/docs/vllm_integration.md: 295 tokens
- FastChat/docs/arena.md: 834 tokens
- FastChat/docs/exllama_v2.md: 1059 tokens
- FastChat/docs/dataset_release.md: 113 tokens
- FastChat/docs/langchain_integration.md: 796 tokens
- FastChat/docs/awq.md: 982 tokens
- FastChat/docs/lightllm_integration.md: 405 tokens
- FastChat/docs/commands/conv_release.md: 154 tokens
- FastChat/docs/commands/local_cluster.md: 1264 tokens
- FastChat/docs/commands/leaderboard.md: 274 tokens
- FastChat/docs/commands/pypi.md: 45 tokens
- FastChat/docs/commands/webserver.md: 798 tokens
- FastChat/docs/commands/data_cleaning.md: 158 tokens
- FastChat/playground/deepspeed_config_s3.json: 258 tokens
- FastChat/playground/deepspeed_config_s2.json: 87 tokens
- FastChat/playground/test_embedding/test_semantic_search.py: 783 tokens
- FastChat/playground/test_embedding/test_classification.py: 715 tokens
- FastChat/playground/test_embedding/test_sentence_similarity.py: 451 tokens
- FastChat/playground/test_embedding/README.md: 169 tokens
- FastChat/docker/docker-compose.yml: 383 tokens
- FastChat/fastchat/conversation.py: 17696 tokens
- FastChat/fastchat/__init__.py: 11 tokens
- FastChat/fastchat/utils.py: 3398 tokens
- FastChat/fastchat/constants.py: 679 tokens
- FastChat/fastchat/modules/xfastertransformer.py: 342 tokens
- FastChat/fastchat/modules/awq.py: 653 tokens
- FastChat/fastchat/modules/gptq.py: 573 tokens
- FastChat/fastchat/modules/__init__.py: 0 tokens
- FastChat/fastchat/modules/exllama.py: 432 tokens
- FastChat/fastchat/train/train_flant5.py: 3279 tokens
- FastChat/fastchat/train/train_baichuan.py: 2563 tokens
- FastChat/fastchat/train/train.py: 2298 tokens
- FastChat/fastchat/train/llama2_flash_attn_monkey_patch.py: 2109 tokens
- FastChat/fastchat/train/llama_xformers_attn_monkey_patch.py: 1186 tokens
- FastChat/fastchat/train/llama_flash_attn_monkey_patch.py: 1056 tokens
- FastChat/fastchat/train/train_lora_t5.py: 1845 tokens
- FastChat/fastchat/train/train_lora.py: 1898 tokens
- FastChat/fastchat/train/train_mem.py: 85 tokens
- FastChat/fastchat/train/train_with_template.py: 3023 tokens
- FastChat/fastchat/train/train_yuan2.py: 3685 tokens
- FastChat/fastchat/train/train_xformers.py: 91 tokens
- FastChat/fastchat/llm_judge/download_mt_bench_pregenerated.py: 761 tokens
- FastChat/fastchat/llm_judge/common.py: 5595 tokens
- FastChat/fastchat/llm_judge/gen_api_answer.py: 1018 tokens
- FastChat/fastchat/llm_judge/qa_browser.py: 3084 tokens
- FastChat/fastchat/llm_judge/gen_judgment.py: 2172 tokens
- FastChat/fastchat/llm_judge/clean_judgment.py: 699 tokens
- FastChat/fastchat/llm_judge/gen_model_answer.py: 1969 tokens
- FastChat/fastchat/llm_judge/show_result.py: 1232 tokens
- FastChat/fastchat/llm_judge/compute_agreement.py: 1181 tokens
- FastChat/fastchat/llm_judge/README.md: 1896 tokens
- FastChat/fastchat/serve/mlx_worker.py: 1871 tokens
- FastChat/fastchat/serve/gradio_web_server.py: 8158 tokens
- FastChat/fastchat/serve/remote_logger.py: 338 tokens
- FastChat/fastchat/serve/inference.py: 3936 tokens
- FastChat/fastchat/serve/model_worker.py: 3164 tokens
- FastChat/fastchat/serve/controller.py: 2491 tokens
- FastChat/fastchat/serve/gradio_block_arena_vision_named.py: 3432 tokens
- FastChat/fastchat/serve/huggingface_api_worker.py: 2776 tokens
- FastChat/fastchat/serve/gradio_block_arena_vision.py: 2971 tokens
- FastChat/fastchat/serve/gradio_block_arena_anony.py: 5598 tokens
- FastChat/fastchat/serve/vllm_worker.py: 2152 tokens
- FastChat/fastchat/serve/sglang_worker.py: 2152 tokens
- FastChat/fastchat/serve/gradio_web_server_multi.py: 2311 tokens
- FastChat/fastchat/serve/shutdown_serve.py: 192 tokens
- FastChat/fastchat/serve/test_message.py: 545 tokens
- FastChat/fastchat/serve/base_model_worker.py: 1407 tokens
- FastChat/fastchat/serve/multi_model_worker.py: 2182 tokens
- FastChat/fastchat/serve/gradio_block_arena_vision_anony.py: 4620 tokens
- FastChat/fastchat/serve/register_worker.py: 193 tokens
- FastChat/fastchat/serve/launch_all_serve.py: 2119 tokens
- FastChat/fastchat/serve/__init__.py: 0 tokens
- FastChat/fastchat/serve/api_provider.py: 7254 tokens
- FastChat/fastchat/serve/gradio_block_arena_named.py: 3719 tokens
- FastChat/fastchat/serve/huggingface_api.py: 555 tokens
- FastChat/fastchat/serve/test_throughput.py: 930 tokens
- FastChat/fastchat/serve/call_monitor.py: 1799 tokens
- FastChat/fastchat/serve/cli.py: 2416 tokens
- FastChat/fastchat/serve/lightllm_worker.py: 3677 tokens
- FastChat/fastchat/serve/openai_api_server.py: 6802 tokens
- FastChat/fastchat/serve/monitor/clean_chat_data.py: 1193 tokens
- FastChat/fastchat/serve/monitor/elo_analysis.py: 5221 tokens
- FastChat/fastchat/serve/monitor/deduplication.py: 625 tokens
- FastChat/fastchat/serve/monitor/topic_clustering.py: 2304 tokens
- FastChat/fastchat/serve/monitor/leaderboard_csv_to_html.py: 311 tokens
- FastChat/fastchat/serve/monitor/monitor.py: 7757 tokens
- FastChat/fastchat/serve/monitor/inspect_conv.py: 652 tokens
- FastChat/fastchat/serve/monitor/intersect_conv_file.py: 212 tokens
- FastChat/fastchat/serve/monitor/basic_stats.py: 1908 tokens
- FastChat/fastchat/serve/monitor/summarize_cluster.py: 705 tokens
- FastChat/fastchat/serve/monitor/criteria_labeling.py: 1805 tokens
- FastChat/fastchat/serve/monitor/tag_openai_moderation.py: 393 tokens
- FastChat/fastchat/serve/monitor/clean_battle_data.py: 3050 tokens
- FastChat/fastchat/serve/monitor/vote_time_stats/analyze_data.py: 872 tokens
- FastChat/fastchat/serve/monitor/vote_time_stats/plot.py: 524 tokens
- FastChat/fastchat/serve/monitor/vote_time_stats/README.md: 41 tokens
- FastChat/fastchat/serve/monitor/dataset_release_scripts/lmsys_chat_1m/approve_all.py: 128 tokens
- FastChat/fastchat/serve/monitor/dataset_release_scripts/lmsys_chat_1m/filter_bad_conv.py: 1066 tokens
- FastChat/fastchat/serve/monitor/dataset_release_scripts/lmsys_chat_1m/upload_hf_dataset.py: 112 tokens
- FastChat/fastchat/serve/monitor/dataset_release_scripts/lmsys_chat_1m/final_post_processing.py: 178 tokens
- FastChat/fastchat/serve/monitor/dataset_release_scripts/lmsys_chat_1m/compute_stats.py: 824 tokens
- FastChat/fastchat/serve/monitor/dataset_release_scripts/lmsys_chat_1m/instructions.md: 175 tokens
- FastChat/fastchat/serve/monitor/dataset_release_scripts/lmsys_chat_1m/merge_oai_tag.py: 376 tokens
- FastChat/fastchat/serve/monitor/dataset_release_scripts/lmsys_chat_1m/sample.py: 203 tokens
- FastChat/fastchat/serve/monitor/dataset_release_scripts/arena_33k/merge_field.py: 175 tokens
- FastChat/fastchat/serve/monitor/dataset_release_scripts/arena_33k/filter_bad_conv.py: 1145 tokens
- FastChat/fastchat/serve/monitor/dataset_release_scripts/arena_33k/upload_hf_dataset.py: 74 tokens
- FastChat/fastchat/serve/monitor/dataset_release_scripts/arena_33k/count_unique_users.py: 165 tokens
- FastChat/fastchat/serve/monitor/dataset_release_scripts/arena_33k/sample.py: 203 tokens
- FastChat/fastchat/serve/vision/create_vqa_examples_dir.py: 820 tokens
- FastChat/fastchat/serve/gateway/README.md: 396 tokens
- FastChat/fastchat/data/convert_alpaca.py: 272 tokens
- FastChat/fastchat/data/split_long_conversation.py: 883 tokens
- FastChat/fastchat/data/pretty_json.py: 121 tokens
- FastChat/fastchat/data/hardcoded_questions.py: 1441 tokens
- FastChat/fastchat/data/filter_wrong_format.py: 274 tokens
- FastChat/fastchat/data/merge.py: 158 tokens
- FastChat/fastchat/data/prepare_all.py: 482 tokens
- FastChat/fastchat/data/optional_replace.py: 550 tokens
- FastChat/fastchat/data/clean_sharegpt.py: 1690 tokens
- FastChat/fastchat/data/inspect_data.py: 226 tokens
- FastChat/fastchat/data/__init__.py: 0 tokens
- FastChat/fastchat/data/split_train_test.py: 281 tokens
- FastChat/fastchat/data/optional_clean.py: 647 tokens
- FastChat/fastchat/data/extract_gpt4_only.py: 244 tokens
- FastChat/fastchat/data/get_stats.py: 632 tokens
- FastChat/fastchat/data/extract_single_round.py: 215 tokens
- FastChat/fastchat/data/sample.py: 289 tokens
- FastChat/fastchat/protocol/api_protocol.py: 1207 tokens
- FastChat/fastchat/protocol/openai_api_protocol.py: 1398 tokens
- FastChat/fastchat/model/apply_lora.py: 396 tokens
- FastChat/fastchat/model/model_adapter.py: 20757 tokens
- FastChat/fastchat/model/upload_hub.py: 352 tokens
- FastChat/fastchat/model/compression.py: 2292 tokens
- FastChat/fastchat/model/model_falcon.py: 920 tokens
- FastChat/fastchat/model/model_registry.py: 6864 tokens
- FastChat/fastchat/model/llama_condense_monkey_patch.py: 675 tokens
- FastChat/fastchat/model/convert_fp16.py: 186 tokens
- FastChat/fastchat/model/model_exllama.py: 503 tokens
- FastChat/fastchat/model/make_delta.py: 438 tokens
- FastChat/fastchat/model/__init__.py: 30 tokens
- FastChat/fastchat/model/model_xfastertransformer.py: 543 tokens
- FastChat/fastchat/model/model_cllm.py: 1467 tokens
- FastChat/fastchat/model/model_chatglm.py: 1029 tokens
- FastChat/fastchat/model/rwkv_model.py: 578 tokens
- FastChat/fastchat/model/monkey_patch_non_inplace.py: 1121 tokens
- FastChat/fastchat/model/model_codet5p.py: 737 tokens
- FastChat/fastchat/model/model_yuan2.py: 914 tokens
- FastChat/fastchat/model/apply_delta.py: 1303 tokens
- FastChat/tests/test_openai_api.py: 932 tokens
- FastChat/tests/test_cli.py: 619 tokens
- FastChat/tests/test_openai_vision_api.py: 971 tokens
- FastChat/tests/test_openai_langchain.py: 357 tokens
- FastChat/tests/launch_openai_api_test_server.py: 386 tokens
- FastChat/tests/README.md: 672 tokens
- analysis/report_trick.py: 1875 tokens
- baseline/__init__.py: 0 tokens
- baseline/PAIR/judges.py: 581 tokens
- baseline/PAIR/common.py: 481 tokens
- baseline/PAIR/PAIR_single_main.py: 1285 tokens
- baseline/PAIR/conversers.py: 1917 tokens
- baseline/PAIR/config.py: 70 tokens
- baseline/PAIR/__init__.py: 0 tokens
- baseline/PAIR/loggers.py: 1379 tokens
- baseline/PAIR/system_prompts.py: 1479 tokens
- baseline/PAIR/language_models.py: 2492 tokens
- baseline/PAIR/conversers_pair.py: 2346 tokens
- baseline/PAIR/README.md: 1140 tokens
- baseline/PAIR/judges_pair.py: 585 tokens
- baseline/TAP/conversers_tap.py: 2358 tokens
- baseline/TAP/conversers.py: 4285 tokens
- baseline/TAP/config.py: 138 tokens
- baseline/TAP/common_tap.py: 515 tokens
- baseline/TAP/__init__.py: 17 tokens
- baseline/TAP/evaluators.py: 988 tokens
- baseline/TAP/loggers.py: 1231 tokens
- baseline/TAP/TAP_single_main.py: 2794 tokens
- baseline/TAP/system_prompts.py: 1672 tokens
- baseline/TAP/language_models.py: 2830 tokens
- baseline/GPTFuzz/GPTFuzz_single_main.py: 880 tokens
- baseline/GPTFuzz/__init__.py: 0 tokens
- baseline/GPTFuzz/gptfuzz.py: 943 tokens
- baseline/GPTFuzz/README.md: 1460 tokens
- baseline/GPTFuzz/gptfuzzer/__init__.py: 0 tokens
- baseline/GPTFuzz/gptfuzzer/fuzzer/mutator.py: 2360 tokens
- baseline/GPTFuzz/gptfuzzer/fuzzer/core.py: 1723 tokens
- baseline/GPTFuzz/gptfuzzer/fuzzer/__init__.py: 12 tokens
- baseline/GPTFuzz/gptfuzzer/fuzzer/selection.py: 1484 tokens
- baseline/GPTFuzz/gptfuzzer/llm/llm.py: 3003 tokens
- baseline/GPTFuzz/gptfuzzer/llm/__init__.py: 31 tokens
- baseline/GPTFuzz/gptfuzzer/utils/predict.py: 219 tokens
- baseline/GPTFuzz/gptfuzzer/utils/template.py: 42 tokens
- baseline/GPTFuzz/gptfuzzer/utils/__init__.py: 0 tokens
- baseline/GPTFuzz/gptfuzzer/utils/openai.py: 151 tokens
- baseline/GPTFuzz/example/finetune_roberta.py: 6105 tokens
- baseline/GPTFuzz/datasets/prompts/README.md: 86 tokens
- baseline/AdvPrompter/llm.py: 563 tokens
- baseline/AdvPrompter/utils.py: 94 tokens
- baseline/AdvPrompter/AdvPrompter_single_main.py: 428 tokens
- baseline/GCG/GCG_single_main.py: 1399 tokens
- baseline/GCG/__init__.py: 78 tokens
- baseline/GCG/utils.py: 330 tokens
- baseline/GCG/README.md: 3 tokens
- baseline/GCG/base/__init__.py: 0 tokens
- baseline/GCG/base/attack_manager.py: 13262 tokens
- baseline/GCG/minimal_gcg/string_utils.py: 1280 tokens
- baseline/GCG/minimal_gcg/opt_utils.py: 2181 tokens
- baseline/GCG/minimal_gcg/__init__.py: 0 tokens
- baseline/GCG/gcg/__init__.py: 62 tokens
- baseline/GCG/gcg/gcg_attack.py: 1628 tokens
- baseline/AutoDAN/check_asr.py: 196 tokens
- baseline/AutoDAN/AutoDAN_single_main.py: 1857 tokens
- baseline/AutoDAN/get_responses.py: 1461 tokens
- baseline/AutoDAN/autodan_hga_eval.py: 2381 tokens
- baseline/AutoDAN/__init__.py: 14 tokens
- baseline/AutoDAN/autodan_ga_eval.py: 2286 tokens
- baseline/AutoDAN/README.md: 1075 tokens
- baseline/AutoDAN/assets/autodan_initial_prompt.txt: 63 tokens
- baseline/AutoDAN/utils/string_utils.py: 1737 tokens
- baseline/AutoDAN/utils/opt_utils.py: 5051 tokens
- baseline/AmpleGCG/AmpleGCG_single_main.py: 363 tokens
- baseline/AmpleGCG/llm.py: 918 tokens
- baseline/AmpleGCG/utils.py: 96 tokens
- llm_smooth/model_configs.py: 22 tokens
- llm_smooth/perturbations.py: 450 tokens
- llm_smooth/__init__.py: 0 tokens
- llm_smooth/attacks.py: 835 tokens
- llm_smooth/smoothLLM.py: 519 tokens
- llm_smooth/defenses.py: 629 tokens
- llm_smooth/language_models.py: 443 tokens
- utils/test_utils.py: 3181 tokens
- utils/string_utils.py: 397 tokens
- utils/__init__.py: 0 tokens
- utils/utils.py: 885 tokens
- GPTEvaluatorAgent/judges.py: 1113 tokens
- GPTEvaluatorAgent/common.py: 708 tokens
- GPTEvaluatorAgent/agent_eval.py: 882 tokens
- GPTEvaluatorAgent/config.py: 30 tokens
- GPTEvaluatorAgent/__init__.py: 0 tokens
- GPTEvaluatorAgent/main.py: 389 tokens
- GPTEvaluatorAgent/system_prompts.py: 1027 tokens
- GPTEvaluatorAgent/language_models.py: 2516 tokens
