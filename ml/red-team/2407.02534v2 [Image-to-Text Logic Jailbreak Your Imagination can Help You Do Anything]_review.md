#Tags
[[Research/Research Papers/2407.02534v2.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0054/LLMJailbreak
#AMLT0043/CraftAdversarialData
#AMLT0031/ErodeMLModelIntegrity

**Title:** Image-to-Text Logic Jailbreak: Your Imagination can Help You Do Anything
**Authors:** Xiaotian Zou, Ke Li, Yongkang Chen
**Publication Date:** July 1, 2024 (last updated August 26, 2024)

Summary:
This paper introduces a novel approach to evaluating the vulnerability of Visual Language Models (VLMs) to jailbreak attacks using logic-based flowcharts. The authors present a new dataset, Flow-JD, and conduct extensive evaluations on various VLMs, including GPT-4o and GPT-4V, revealing significant vulnerabilities in these models.

Key Contributions:
- Introduction of Flow-JD, a dataset for evaluating logic-based flowchart jailbreak capabilities of VLMs
- Comprehensive evaluation of state-of-the-art VLMs, including GPT-4o, GPT-4V, and 5 open-source models
- Demonstration of high jailbreak success rates (up to 92.8%) using logic-based flowchart attacks
- Analysis of the relationship between image understanding capabilities and jailbreak vulnerability

Problem Statement:
The research addresses the gap in evaluating VLMs' vulnerability to jailbreak attacks using logic-based flowcharts, which exploit the models' logical reasoning and imaginative capabilities.

Methodology:
1. Creation of Flow-JD dataset:
   - Flow-HJD: 70 hand-made logic jailbreak flowcharts
   - Flow-SJD: 520 AI-generated flowcharts using SDXL
2. Evaluation of VLMs:
   - Models tested: GPT-4o, GPT-4V, Qwen-Chat-VL, MiniCPM-Llama3-V2.5, LLAVA-V1.6-7B, LLAVA-V1.5-7B, MiniCPM-V2
   - Metric: Attack Success Rate (ASR)
3. Correlation analysis between VLM responses and harmful behaviors

Main Results:
1. High jailbreak success rates:
   - GPT-4o: 92.8% on Flow-HJD
   - GPT-4V: 70% on Flow-HJD
2. Significantly higher jailbreak rates on Flow-HJD compared to Flow-SJD
3. Positive correlation between image understanding capabilities and jailbreak vulnerability

Qualitative Analysis:
- The study reveals that VLMs with superior image understanding capabilities are more susceptible to logic-based jailbreak attacks
- The imaginative abilities of VLMs contribute to their vulnerability, as they tend to add details related to jailbreaking processes when providing detailed descriptions

Limitations:
- Limited size of the Flow-HJD dataset (70 images)
- Focus on basic jailbreak methods without exploring more advanced strategies
- Evaluation limited to English prompts

Conclusion and Future Work:
The paper highlights significant vulnerabilities in current VLMs to image-to-text jailbreak attacks using logic-based flowcharts. Future work suggestions include:
1. Expanding the Flow-HJD dataset
2. Exploring few-shot flowchart jailbreak techniques
3. Investigating multi-language jailbreak attempts
4. Evaluating VLMs' ability to understand logical flowcharts
5. Exploring multi-round jailbreak scenarios

Relevant Figures:
- Figure 1: Example of logic flowchart jailbreak in GPT-4o
- Figure 2: Correlation score between VLM responses and harmful behaviors
- Figure 3: Similarity of jailbreak flowcharts with corresponding text

New Tools:
- Flow-JD dataset (GitHub repository not provided in the paper)