#Tags
[[Research/Research Papers/2405.01229v1.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0054/LLMJailbreak

**Title:** Boosting Jailbreak Attack with Momentum
**Authors:** Yihao Zhang, Zeming Wei
**Affiliation:** Peking University
**Publication Date:** May 2, 2024 (arXiv preprint)

Summary:
This paper introduces the Momentum Accelerated GCG (MAC) attack, an enhanced version of the Greedy Coordinate Gradient (GCG) attack for jailbreaking Large Language Models (LLMs). The MAC attack incorporates a momentum term into the gradient heuristic to improve efficiency and effectiveness in generating adversarial prompts.

Key Contributions:
- Introduction of the MAC attack, which enhances the GCG attack with a momentum term
- Demonstration of improved efficiency and effectiveness in jailbreaking aligned language models
- Experimental results showing higher attack success rates and fewer optimization steps

Problem Statement:
The paper addresses the efficiency bottleneck in the GCG attack, which is a gradient-based method for jailbreaking LLMs. The authors aim to improve the attack's performance by rethinking the optimization process used to generate adversarial prompts.

Methodology:
1. Reframing the GCG attack as a stochastic gradient descent (SGD) optimization problem
2. Incorporating a momentum term into the gradient heuristic
3. Developing algorithms for both individual and multiple prompt attacks
4. Evaluating the MAC attack on the vicuna-7b model using the AdvBench dataset
5. Comparing performance metrics such as Attack Success Rate (ASR) and optimization steps

Main Results:
1. Individual prompt attacks:
   - MAC with μ=0.2 achieved 76.6% ASR (1.6% improvement over GCG)
   - Reduced average attack steps from 12.62 to 12.37
2. Multiple prompt attacks:
   - MAC with μ=0.6 achieved 48.6% ASR (10.5% improvement over GCG)
   - Increased maximum ASR from 72.7% to 86.1%
   - Reduced standard deviation of maximum ASR from 15.36 to 9.00

Qualitative Analysis:
- The introduction of momentum helps stabilize the optimization process across different prompts
- Higher momentum values (μ=0.6) show the best balance between effectiveness and consistency
- The MAC attack demonstrates improved generalization ability in multiple prompt scenarios

Limitations:
- Experiments focused on a single model (vicuna-7b)
- Only considered batch size of 1 for multiple prompt attacks
- Other optimization methods beyond momentum remain unexplored

Conclusion and Future Work:
The MAC attack successfully improves upon the GCG attack by incorporating momentum, resulting in higher attack success rates and fewer optimization steps. Future work may include:
1. Exploring larger batch sizes for multiple prompt attacks
2. Investigating other optimization methods (e.g., Adam)
3. Evaluating the MAC attack on a broader range of LLMs

New Tool:
Name: Momentum Accelerated GCG (MAC) attack
GitHub: https://github.com/weizeming/momentum-attack-llm