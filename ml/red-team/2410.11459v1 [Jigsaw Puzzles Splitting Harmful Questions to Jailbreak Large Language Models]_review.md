#Tags
[[Research/Research Papers/2410.11459v1.pdf]]

#AMLT0054/LLMJailbreak
#AMLT0051/LLMPromptInjection
#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData

**Title:** Jigsaw Puzzles: Splitting Harmful Questions to Jailbreak Large Language Models
**Authors:** Hao Yang, Lizhen Qu, Ehsan Shareghi, Gholamreza Haffari
**Affiliation:** Department of Data Science & AI, Monash University
**Publication Date:** October 15, 2024

Key Contributions:
- Introduces Jigsaw Puzzles (JSP), a novel multi-turn jailbreak strategy for LLMs
- Demonstrates high attack success rates across multiple advanced LLMs
- Achieves state-of-the-art 92% attack success rate on GPT-4
- Shows strong resistance to existing defense strategies

Problem Statement:
The paper addresses the vulnerability of Large Language Models (LLMs) to jailbreak attacks in multi-turn interactions, which can lead to the generation of harmful responses.

Methodology:
1. JSP Prompt Design:
   - Prohibits LLMs from generating concatenated questions
   - Includes a disclaimer to bypass output-side guardrails

2. JSP Splitting Strategy:
   - Stage 1: Re-write queries into consistent structure
   - Stage 2: Sentence-level splitting to isolate harmful words
   - Stage 3: Word-level splitting of harmful words into benign fractions

3. Experimental Setup:
   - Dataset: 189 harmful questions across 7 categories
   - Models: Gemini-1.5-Pro, GPT-4, GPT-4o, GPT-4o-mini, Llama-3.1-70B
   - Evaluation Metrics: Attack Success Rate by Attempt (ASR-a) and by Question (ASR-q)
   - Automated evaluation using Llama-guard-3

Main Results:
1. JSP achieves an average ASR-q of 93.76% across 5 LLMs
2. Highest vulnerability in Privacy Violation, Fraud, Malware Generation, and Illegal Activity categories
3. JSP outperforms existing jailbreak strategies with 92% ASR-q on GPT-4
4. Maintains 76% ASR-q on GPT-4 even with targeted defense measures

Qualitative Analysis:
- JSP's effectiveness stems from bypassing content-based defenses by splitting harmful content
- Multi-turn interactions exploit LLMs' contextual memory and reasoning abilities
- The strategy's simplicity and effectiveness highlight significant vulnerabilities in current LLM safety measures

Limitations:
- Potential for false positives in automatic evaluation, especially for less capable models
- Increased inference time and costs for multi-turn interactions
- Ethical concerns regarding the development and publication of jailbreak techniques

Conclusion and Future Work:
- JSP reveals critical vulnerabilities in LLM safety mechanisms, especially in multi-turn settings
- Calls for the development of more robust defense tactics against multi-turn jailbreak attempts
- Suggests further research into balancing model capabilities with enhanced safety measures

Relevant Figures:
- Figure 1: Example of JSP jailbreaking process
- Figure 3: Three-stage query processing for JSP
- Figure 4: Heatmap of JSP success rates across harmful categories and LLMs

Tools Introduced:
- Jigsaw Puzzles (JSP) strategy
- GitHub repository: https://github.com/YangHao97/JigSawPuzzles

## Repository Token Information
Total tokens in repository: 0

Tokens per file:


## Tutorial and Enhancement Suggestions

# Tutorial: Jigsaw Puzzles (JSP) for LLM Jailbreaking

## Project Overview

The Jigsaw Puzzles (JSP) project introduces a novel multi-turn jailbreak strategy for Large Language Models (LLMs). This tutorial will explore the implementation of JSP based on the research paper and the provided GitHub repository.

**Note:** The GitHub repository content is not available in the given information. This tutorial will be based on the concepts and methodologies described in the research paper review.

## Key Components

### 1. JSP Prompt Design

The JSP strategy employs a carefully crafted prompt design with two main components:

a) Prohibition of concatenated questions
b) Inclusion of a disclaimer to bypass output-side guardrails

### 2. JSP Splitting Strategy

The core of the JSP method is its three-stage splitting strategy:

1. Query Rewriting
2. Sentence-level Splitting
3. Word-level Splitting

### 3. Evaluation Framework

The project includes an evaluation framework using:

- A dataset of 189 harmful questions across 7 categories
- Multiple LLM targets (e.g., GPT-4, Llama-3.1-70B)
- Automated evaluation using Llama-guard-3

## Implementation Details

### Stage 1: Query Rewriting

```python
def rewrite_query(query):
    # Implement logic to rewrite the query into a consistent structure
    # This may involve using NLP techniques or rule-based transformations
    pass
```

### Stage 2: Sentence-level Splitting

```python
def split_sentences(rewritten_query):
    # Implement sentence tokenization
    # Identify and isolate potentially harmful words or phrases
    pass
```

### Stage 3: Word-level Splitting

```python
def split_words(harmful_words):
    # Implement word-level splitting for harmful words
    # Break down harmful words into benign fractions
    pass
```

### Main JSP Function

```python
def jigsaw_puzzles_attack(original_query):
    rewritten_query = rewrite_query(original_query)
    split_sentences = split_sentences(rewritten_query)
    final_prompts = []
    
    for sentence in split_sentences:
        if is_harmful(sentence):
            split_words = split_words(sentence)
            final_prompts.extend(split_words)
        else:
            final_prompts.append(sentence)
    
    return final_prompts
```

### Evaluation

```python
def evaluate_jsp(model, dataset):
    results = {
        'ASR-a': 0,  # Attack Success Rate by Attempt
        'ASR-q': 0   # Attack Success Rate by Question
    }
    
    for query in dataset:
        jsp_prompts = jigsaw_puzzles_attack(query)
        success = execute_attack(model, jsp_prompts)
        
        # Update results based on success
        
    return results
```

## Relation to Research Paper

The implementation directly reflects the three-stage JSP strategy described in the paper. It aims to bypass content-based defenses by splitting harmful content and exploiting LLMs' contextual memory in multi-turn interactions.

# Potential Enhancements

1. **Dynamic Splitting Strategies**
   - Implement machine learning models to dynamically determine optimal splitting points for different types of queries and target LLMs.
   - This could improve the adaptability and success rate of the JSP method across various scenarios.

2. **Cross-lingual JSP**
   - Extend the JSP technique to work across multiple languages, exploring how language-specific features can be leveraged for more effective jailbreaking.
   - This would broaden the applicability of the research and uncover potential vulnerabilities in multilingual LLMs.

3. **Defensive JSP Implementation**
   - Develop a defensive version of JSP that can be integrated into LLMs to detect and prevent jailbreak attempts using similar splitting techniques.
   - This would contribute to improving LLM safety and robustness against multi-turn attacks.

4. **JSP with Semantic Preservation**
   - Enhance the word-level splitting stage to ensure that the semantic meaning of the original query is preserved as much as possible.
   - This could lead to more natural and less detectable jailbreak attempts, potentially increasing success rates.

5. **Integration with Other Jailbreak Techniques**
   - Combine JSP with other jailbreak strategies, such as prompt injection or adversarial examples, to create hybrid attacks.
   - This integration could result in even more powerful jailbreak methods and reveal compounded vulnerabilities in LLMs.