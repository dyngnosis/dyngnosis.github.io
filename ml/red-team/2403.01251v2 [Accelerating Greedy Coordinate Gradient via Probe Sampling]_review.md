#Tags
[[Research/Research Papers/2403.01251v2.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0040/MLModelInferenceAPIAccess
#AMLT0042/VerifyAttack

**Title:** Accelerating Greedy Coordinate Gradient and General Prompt Optimization via Probe Sampling
**Authors:** Yiran Zhao, Wenyue Zheng, Tianle Cai, Xuan Long Do, Kenji Kawaguchi, Anirudh Goyal, Michael Shieh
**Affiliations:** National University of Singapore, Princeton University, Google DeepMind
**Publication Date:** March 2, 2024 (preprint)

Key Contributions:
- Introduces Probe sampling, a new algorithm to accelerate Greedy Coordinate Gradient (GCG) for constructing adversarial prompts against LLMs
- Achieves up to 5.6x speedup on Llama2-7b-chat while maintaining or improving attack success rate (ASR)
- Demonstrates applicability to other prompt optimization techniques and adversarial methods

Problem Statement:
The paper addresses the time-consuming nature of the GCG algorithm for constructing adversarial prompts to break aligned LLMs, aiming to reduce computational costs while maintaining or improving attack effectiveness.

Methodology:
1. Probe sampling algorithm:
   - Uses a smaller draft model to filter out unpromising suffix candidates
   - Dynamically determines agreement between draft and target models using a probe set
   - Adjusts filtered set size based on agreement score
2. Evaluation on AdvBench dataset using Llama2-7b-Chat and Vicuna-v1.3 as target models, GPT-2 as draft model
3. Application to other methods: AutoPrompt, APE, and AutoDAN

Main Results:
1. Llama2-7b-Chat:
   - 3.5x speedup with improved ASR of 81.0% (vs. 69.0% for GCG)
   - 5.6x speedup with 74.0% ASR when combined with simulated annealing
2. Vicuna-7b-v1.3:
   - 3.2x speedup on harmful behaviors dataset
   - 3.6x speedup on harmful strings dataset
3. Acceleration of other methods:
   - AutoPrompt: 1.8x speedup
   - APE: 2.3x on GSM8K, 1.8x on MMLU, 3.0x on BBH
   - AutoDAN: 2.3x and 2.5x speedup on GA and HGA variants

Qualitative Analysis:
- Probe sampling introduces beneficial randomness to the GCG algorithm, potentially explaining improved ASR
- The adaptive agreement score between draft and target models is crucial for effective acceleration
- The method maintains similar memory usage to the original GCG algorithm, making it widely applicable

Limitations:
- Relatively slow performance on large test sets
- Limited to open-source models, excluding proprietary or closed-source LLMs

Conclusion and Future Work:
- Probe sampling significantly accelerates GCG and other prompt optimization techniques
- The method enables more comprehensive studies of LLM safety
- Future work could explore applications to multi-modality cases, fine-tuning scenarios, and running draft models on web-scale data to detect natural adversarial prompts

Relevant Figures:
- Figure 1: Illustration of the Greedy Coordinate Gradient (GCG) algorithm
- Figure 2: Overview of the Probe sampling algorithm
- Figure 4: Time allocation breakdown for different operations in the algorithm

New Tools:
- Probe sampling algorithm (implementation provided in Appendix A)