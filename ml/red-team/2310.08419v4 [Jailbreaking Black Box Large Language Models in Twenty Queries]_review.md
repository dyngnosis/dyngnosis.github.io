#Tags
[[Research/Research Papers/2310.08419v4.pdf]]

#AMLT0054/LLMJailbreak
#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0040/MLModelInferenceAPIAccess
#AMLT0042/VerifyAttack

**Title:** Jailbreaking Black Box Large Language Models in Twenty Queries

**Authors:** Patrick Chao, Alexander Robey, Edgar Dobriban, Hamed Hassani, George J. Pappas, Eric Wong

**Affiliation:** University of Pennsylvania

**Publication Date:** Originally submitted October 12, 2023, last updated July 18, 2024

Summary:
This paper introduces Prompt Automatic Iterative Refinement (PAIR), an algorithm for generating semantic jailbreaks on large language models (LLMs) using only black-box access. PAIR uses an attacker LLM to automatically generate jailbreaks for a target LLM without human intervention, often requiring fewer than 20 queries.

Key Contributions:
- Introduction of PAIR, an efficient black-box jailbreaking algorithm
- Demonstration of PAIR's effectiveness on various open and closed-source LLMs
- Analysis of PAIR's query efficiency compared to existing methods
- Evaluation of jailbreak transferability across different LLMs

Problem Statement:
The paper addresses the vulnerability of LLMs to adversarial jailbreaks that can override safety guardrails, highlighting the need for efficient methods to identify these vulnerabilities.

Methodology:
1. PAIR algorithm design:
   - Uses an attacker LLM to generate jailbreak prompts
   - Iteratively refines prompts based on target LLM responses
   - Employs a JUDGE function to evaluate jailbreak success
2. Experimental setup:
   - Tested on various LLMs: GPT-3.5/4, Vicuna, Llama-2, Claude-1/2, Gemini
   - Used Mixtral 8x7B Instruct as the primary attacker model
   - Evaluated using JailbreakBench dataset
3. Comparison with baselines:
   - GCG (gradient-based white-box attack)
   - Human-crafted jailbreaks from jailbreakchat.com

Main Results:
1. Efficiency: PAIR finds jailbreaks in several dozen queries, compared to 256,000 queries for GCG
2. Success rates:
   - 88% on Vicuna
   - 51% on GPT-3.5
   - 48% on GPT-4
   - 73% on Gemini
3. Transferability: PAIR-generated jailbreaks show good transfer across different LLMs
4. Query efficiency: Average of 10-56 queries per successful jailbreak

Qualitative Analysis:
- PAIR's semantic nature leads to more interpretable and transferable jailbreaks compared to token-level attacks
- The method's effectiveness varies across different LLMs, with strongly fine-tuned models like Llama-2 and Claude being more resistant
- PAIR's approach of using an attacker LLM mimics social engineering attacks, potentially revealing real-world vulnerabilities

Limitations:
- Less effective against strongly fine-tuned models (e.g., Llama-2, Claude)
- May require manual involvement or hyperparameter tuning for certain models
- As a search algorithm, PAIR may be less interpretable than optimization-based schemes

Conclusion and Future Work:
- PAIR demonstrates the ability to efficiently generate semantic jailbreaks for various LLMs
- The method's black-box nature and query efficiency make it accessible for red teaming
- Future work may include:
  1. Extending the framework to generate red teaming datasets for fine-tuning
  2. Adapting PAIR for multi-turn conversations
  3. Developing a specialized red teaming LLM

Tools Introduced:
- PAIR (Prompt Automatic Iterative Refinement) algorithm
- Github Repo: https://github.com/patrickrchao/JailbreakingLLMs
