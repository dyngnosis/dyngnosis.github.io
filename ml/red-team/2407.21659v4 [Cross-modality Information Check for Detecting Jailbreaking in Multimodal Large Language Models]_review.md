#Tags
[[Research/Research Papers/2407.21659v4.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0031/ErodeMLModelIntegrity
#AMLT0054/LLMJailbreak

**Title:** Cross-modality Information Check for Detecting Jailbreaking in Multimodal Large Language Models
**Authors:** Yue Xu, Xiuyuan Qi, Zhan Qin, Wenjie Wang
**Affiliations:** 
- School of Information Science and Technology, ShanghaiTech University
- The State Key Laboratory of Blockchain and Data Security, Zhejiang University
**Publication date:** 17 Oct 2024

Summary:
This paper introduces CIDER (Cross-modality Information DEtectoR), a plug-and-play jailbreaking detector for Multimodal Large Language Models (MLLMs). CIDER identifies maliciously perturbed image inputs by utilizing cross-modal similarity between harmful queries and adversarial images.

Key Contributions:
1. Proposal of CIDER, an effective and efficient pre-detection module for safeguarding MLLMs against jailbreak attacks
2. Investigation of the relationship between malicious queries and adversarially perturbed images in semantic space
3. Demonstration of CIDER's effectiveness, efficiency, and transferability across both white-box and black-box MLLMs

Problem Statement:
MLLMs are vulnerable to jailbreak attacks, which can break their safety alignment and generate harmful content. Existing defense methods either require modifications to the model's internal structure or demand significant computational resources during inference.

Methodology:
1. Utilize image and text encoders from LLaVA-v1.5-7B to capture semantic meanings
2. Employ cosine similarity to measure semantic similarity
3. Incorporate a diffusion-based denoiser to preprocess image modality
4. Compare semantic similarity between harmful queries and images before and after denoising
5. Set a threshold based on the change in similarity to detect adversarially perturbed images

Main Results:
1. CIDER achieves a Detection Success Rate (DSR) of approximately 80% across different MLLMs
2. Significant reduction in Attack Success Rate (ASR) for various MLLMs (e.g., LLaVA-v1.5-7B: 60% to 0%, MiniGPT4: 57% to 9%)
3. CIDER outperforms baseline method (Jailguard) in both effectiveness and efficiency
4. Strong transferability across both white-box and black-box MLLMs and attack methods

Qualitative Analysis:
- CIDER leverages the double-edged nature of multimodal information, using it to enhance safeguards against attacks
- The method is model-agnostic, making it applicable to various MLLMs without requiring access to internal model parameters
- CIDER's efficiency is crucial for real-time defense in practical applications

Limitations:
1. CIDER impacts MLLM performance on normal tasks, with an approximate 30% overall performance decline on the MM-Vet benchmark
2. The method is specifically designed for optimization-based adversarial jailbreak attacks and may not be effective against other types of attacks

Conclusion and Future Work:
- CIDER demonstrates effectiveness in safeguarding MLLMs against jailbreak attacks while maintaining efficiency
- Future work includes improving CIDER to reduce negative impact on MLLM utilities for normal tasks
- Exploring CIDER's effectiveness against non-optimization-based jailbreak attacks

Tools Introduced:
CIDER (Cross-modality Information DEtectoR)
GitHub repository: https://github.com/PandragonXIII/CIDER

## Repository Token Information
Total tokens in repository: 0

Tokens per file:


## Tutorial and Enhancement Suggestions

# CIDER: Cross-modality Information Detector for MLLM Jailbreak Detection

## Tutorial

### Project Overview

CIDER (Cross-modality Information DEtectoR) is a plug-and-play jailbreaking detector for Multimodal Large Language Models (MLLMs). The project aims to safeguard MLLMs against adversarial attacks by detecting maliciously perturbed image inputs.

Unfortunately, the GitHub repository content is not provided in the given information, so we cannot analyze the specific code structure. However, based on the research paper review, we can infer the key components and functionality of the project.

### Key Components and Functionality

1. **Image and Text Encoders**
   - Utilizes encoders from LLaVA-v1.5-7B to capture semantic meanings of images and text.
   - These encoders likely convert images and text into vector representations in a shared semantic space.

2. **Semantic Similarity Measurement**
   - Employs cosine similarity to measure the semantic similarity between image and text representations.
   - This component is crucial for detecting discrepancies between harmful queries and adversarial images.

3. **Diffusion-based Denoiser**
   - Preprocesses the image modality to remove potential adversarial perturbations.
   - Helps in comparing the semantic similarity before and after denoising.

4. **Threshold-based Detection**
   - Sets a threshold based on the change in similarity to detect adversarially perturbed images.
   - This mechanism allows CIDER to distinguish between normal and potentially harmful inputs.

### Relation to Research Concepts

The code implementation likely closely follows the methodology described in the research paper:

1. It uses pre-trained encoders to extract semantic features from both images and text.
2. It implements a similarity measurement function, probably using cosine similarity.
3. It incorporates a diffusion-based denoising step for image preprocessing.
4. It compares similarities before and after denoising to detect potential attacks.
5. It implements a threshold-based decision mechanism for final classification.

### Notable Algorithms and Techniques

1. **Cross-modal Similarity Analysis**: The core technique of CIDER, comparing semantic representations across different modalities (image and text).
2. **Diffusion-based Denoising**: A technique used to preprocess images and potentially remove adversarial perturbations.
3. **Threshold-based Detection**: A simple yet effective method for binary classification based on similarity changes.

## Potential Enhancements

1. **Adaptive Thresholding**
   - Implement an adaptive thresholding mechanism that adjusts based on the specific MLLM and input characteristics.
   - This could improve detection accuracy across different models and reduce false positives/negatives.

2. **Multi-modal Fusion Techniques**
   - Explore advanced multi-modal fusion techniques to better capture the relationship between image and text modalities.
   - This could potentially improve the detection of more sophisticated attacks that exploit cross-modal interactions.

3. **Adversarial Training Integration**
   - Incorporate adversarial training techniques to make CIDER more robust against evolving attack methods.
   - This could help address the limitation of CIDER being specifically designed for optimization-based attacks.

4. **Performance Optimization for Normal Tasks**
   - Develop techniques to reduce the negative impact on MLLM performance for normal tasks.
   - This could involve selective application of CIDER or more efficient preprocessing methods.

5. **Expansion to Other Attack Types**
   - Extend CIDER's capabilities to detect non-optimization-based jailbreak attacks.
   - This could involve developing new similarity metrics or incorporating additional preprocessing steps tailored to different attack vectors.