#Tags
[[Research/Research Papers/2406.08754v2.pdf]]

#AMLT0054/LLMJailbreak
#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0051/LLMPromptInjection

**Title:** Exploiting Uncommon Text-Encoded Structures for Automated Jailbreaks in LLMs
**Authors:** Bangxin Li, Hengrui Xing, Chao Huang, Jin Qian, Huangqing Xiao, Linfeng Feng, Cong Tian
**Publication Date:** June 13, 2024

Key Contributions:
- Introduction of Uncommon Text-Encoded Structure (UTES) for jailbreak attacks
- Development of StructuralSleight, an automated jailbreak framework
- Three escalating attack strategies: Structural Attack (SA), Structural and Character/Context Obfuscation Attack (SCA), and Fully Obfuscated Structural Attack (FSA)
- Extensive evaluation on multiple LLMs, including GPT-4o, Llama3-70B, and Claude3-Opus

Problem Statement:
The paper addresses the vulnerability of Large Language Models (LLMs) to jailbreak attacks, particularly focusing on the unexplored area of prompt structure manipulation.

Methodology:
1. Identification and classification of 12 UTES templates
2. Implementation of 5 character-level and 1 context-level obfuscation methods
3. Development of StructuralSleight framework with three attack stages
4. Evaluation on multiple LLMs using the Harmful Behaviors dataset
5. Comparison with baseline methods: PAIR, MasterKey, and CodeAttack

Main Results:
- StructuralSleight achieved high attack success rates (ASR):
  - 94.62% on GPT-4o
  - 92% on Llama3-70B
  - 82.31% on Claude3-Opus
- SCA stage showed the best performance among the three attack strategies
- Different LLMs exhibited varying vulnerabilities to specific UTES and obfuscation methods

Qualitative Analysis:
- The effectiveness of UTES-based attacks highlights a significant gap in LLM safety alignment regarding structured inputs
- The synergistic effect of combining structure-level with character/context-level obfuscation demonstrates the complexity of securing LLMs against multi-faceted attacks
- The varying vulnerabilities across different LLMs suggest that security measures are not uniformly implemented or effective across models

Limitations:
- The study focuses on a specific set of UTES templates and obfuscation methods, which may not be exhaustive
- The effectiveness of the attacks may vary with future updates to LLM security measures
- Ethical considerations in developing and testing jailbreak methods

Conclusion and Future Work:
- StructuralSleight demonstrates the importance of considering text structure in LLM security
- The authors suggest that future work should focus on developing more robust safety alignment techniques that account for structured inputs and complex obfuscation methods

New Tool Introduced:
StructuralSleight: An automated jailbreak framework that implements UTES-based attacks and combines them with character and context-level obfuscation methods. No GitHub repository was mentioned in the paper.