#Tags
[[Research/Research Papers/2401.10862v2.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0018/BackdoorMLModel
#AMLT0031/ErodeMLModelIntegrity
#AMLT0043/CraftAdversarialData
#AMLT0054/LLMJailbreak

**Title:** Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning
**Authors:** Adib Hasan, Ileana Rugina, Alex Wang
**Publication Date:** January 19, 2024 (updated April 29, 2024)

Key Contributions:
- Demonstrated that moderate WANDA pruning (10-20%) enhances LLM resistance to jailbreaking attacks without fine-tuning
- Introduced a dataset of 225 harmful tasks across five categories for evaluating LLM safety
- Proposed a regularization perspective to understand safety improvements in pruned models
- Analyzed attention patterns and perplexity shifts in pruned models to explain increased jailbreak resistance

Problem Statement:
How to increase the resistance of Large Language Models (LLMs) to jailbreaking attacks without compromising performance on standard tasks?

Methodology:
1. Dataset:
   - Created 225 malicious tasks across 5 categories
   - Integrated tasks into 10 distinct jailbreaking prompts
   - Total dataset: 2250 samples

2. Models:
   - LLaMA-2 Chat (7B parameters)
   - Vicuna-1.3 (7B parameters)
   - Mistral Instruct v0.2 (7B parameters)

3. Pruning:
   - Applied WANDA pruning to attention layers
   - Tested 10%, 20%, and 30% sparsity levels

4. Evaluation:
   - Measured refusal rates for malicious prompts
   - Benchmarked on standard tasks (MMLU, ARC, HellaSwag, etc.)
   - Analyzed attention patterns and perplexity shifts

Main Results:
1. Moderate pruning (10-20%) increased jailbreak resistance:
   - LLaMA-2 Chat: 8.5% average increase in refusal rates
   - Vicuna 1.3: Moderate improvement
   - Mistral Instruct v0.2: Minimal improvement

2. Safety improvement correlated with initial model safety:
   - LLaMA-2 Chat (most safety-aligned) showed highest improvement
   - Mistral Instruct v0.2 (least safety-aligned) showed minimal improvement

3. Pruning beyond 20% decreased safety and performance

4. Pruned models maintained performance on standard benchmarks

Qualitative Analysis:
1. Regularization effect:
   - Pruning helps models focus on task-relevant tokens in jailbreaking prompts
   - Pruned models show sharper attention patterns
   - Increased perplexity for jailbreak templates suggests better detection of artificial constructs

2. Attention analysis:
   - Introduced "IgnoreJailbreak" metric to quantify attention distribution
   - Pruned models showed increased focus on malicious tokens, ignoring jailbreak pretext

3. Perplexity analysis:
   - Pruned models assigned higher perplexity to jailbreak constructs
   - Suggests improved ability to detect out-of-distribution prompts

Limitations:
- Study limited to 7B parameter models
- Focus on WANDA pruning; other compression techniques not explored
- Long-term effects of pruning on model safety not investigated

Conclusion and Future Work:
- Moderate WANDA pruning (10-20%) enhances LLM jailbreak resistance without fine-tuning
- Pruning acts as a regularizer, improving generalization to jailbreaking prompts
- Future work should explore larger models, different compression techniques, and long-term safety effects

Tools Introduced:
- Dataset and implementation available at: https://github.com/CrystalEye42/eval-safety

Relevant Figures:
1. Figure 1: Jailbreaking resistance improvement for different models and pruning levels
2. Figure 2: Example of unpruned vs. pruned model responses to a jailbreaking prompt
3. Figure 4: Attention pattern entropy differences between base and pruned models
4. Figure 5: IgnoreJailbreak metric variation with pruning percentage
5. Figure 6: Perplexity shifts for jailbreak templates in base vs. pruned models