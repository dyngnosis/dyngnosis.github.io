#Tags
[[Research/Research Papers/2408.04811v1.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0054/LLMJailbreak
#AMLT0051/LLMPromptInjection
#AMLT0042/VerifyAttack

**Title:** h4rm3l: A Dynamic Benchmark of Composable Jailbreak Attacks for LLM Safety Assessment

**Authors:** Moussa Koulako Bala Doumbouya, Ananjan Nandi, Gabriel Poesia, Davide Ghilardi, Anna Goldie, Federico Bianchi, Dan Jurafsky, Christopher D. Manning

**Affiliation:** Department of Computer Science, Stanford University

**Publication Date:** August 9, 2024 (preprint)

Summary: The paper introduces h4rm3l, a novel dynamic benchmark for evaluating LLM safety against composable jailbreak attacks. It addresses the limitations of static benchmarks by providing a domain-specific language for expressing attacks, bandit-based few-shot program synthesis algorithms for generating novel attacks, and open-source automated red-teaming software.

Key Contributions:
- A domain-specific language (DSL) for formally expressing jailbreak attacks as compositions of parameterized prompt transformation primitives
- Bandit-based few-shot program synthesis algorithms for generating novel jailbreak attacks
- A dataset of 2,656 successful novel jailbreak attacks targeting 6 state-of-the-art LLMs
- Open-source automated red-teaming software for measuring LLM robustness and synthesizing targeted jailbreak attacks

Problem Statement:
The lack of comprehensive benchmarks for systematically evaluating LLMs' robustness to a large and diverse set of jailbreak attacks hinders the development of effective safety measures.

Methodology:
1. Development of h4rm3l DSL for representing jailbreak attacks
2. Implementation of bandit-based few-shot program synthesis algorithms
3. Creation of a zero-shot harmful LLM behavior classifier
4. Generation and evaluation of novel jailbreak attacks on 6 SOTA LLMs
5. Qualitative analysis of synthesized attacks

Main Results:
- Generated 2,656 successful novel jailbreak attacks with high Attack Success Rates (ASRs)
- Achieved ASRs exceeding 90% on SOTA closed language models like claude-3-haiku and GPT4-o
- Synthesized attacks outperformed state-of-the-art jailbreak attacks by significant margins
- Demonstrated limited transfer of attacks across models, highlighting the need for targeted attack synthesis

Qualitative Analysis:
- Composition of individual attacks resulted in higher ASRs
- High diversity among synthesized attacks with the same method
- Different LLMs showed vulnerabilities to attacks with particular characteristics
- Human-designed abstractions in the DSL improved attack synthesis performance

Limitations:
- Potential for misuse of the synthesized attacks
- Need for human discernment in accurate harm classification
- Additional safety filters applied by some LLM providers during the study

Conclusion and Future Work:
The h4rm3l framework provides a comprehensive benchmark for assessing LLM vulnerabilities and generates resources for safety guardrail development. Future work may focus on developing more robust defense strategies and expanding the framework to cover a wider range of LLMs and attack types.

New Tool:
h4rm3l: A dynamic benchmark of composable jailbreak attacks for LLM safety assessment. The tool includes a DSL for expressing attacks, program synthesis algorithms, and automated red-teaming software. (GitHub repository not provided in the paper)