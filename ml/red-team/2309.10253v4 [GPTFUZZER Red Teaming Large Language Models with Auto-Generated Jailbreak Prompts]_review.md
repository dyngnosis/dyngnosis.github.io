#Tags
[[Research/Research Papers/2309.10253v4.pdf]]

#AMLT0054/LLMJailbreak
#AMLT0043/CraftAdversarialData
#AMLT0015/EvadeMLModel
#AMLT0017/DevelopCapabilities
#AMLT0042/VerifyAttack

**Title:** GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts
**Authors:** Jiahao Yu, Xingwei Lin, Zheng Yu, Xinyu Xing
**Publication Date:** September 19, 2023

Summary:
GPTFUZZER is a novel black-box jailbreak fuzzing framework for automatically generating jailbreak templates to test the robustness of large language models (LLMs). It uses human-written templates as initial seeds and mutates them to produce new templates, achieving high success rates in compromising various LLMs.

Key Contributions:
- Introduction of GPTFUZZER, an automated jailbreak fuzzing framework for LLMs
- Design of three key components: seed selection strategy, mutate operators, and judgment model
- Extensive evaluation across commercial and open-source LLMs
- Demonstration of high attack success rates, even with suboptimal initial seeds

Problem Statement:
Existing jailbreak attacks on LLMs rely on manually crafted prompts, which are not scalable, labor-intensive, and may miss certain vulnerabilities. There is a need for an automated framework to efficiently generate jailbreak prompts for comprehensive LLM robustness evaluations.

Methodology:
1. Seed Selection: Strategies include Random, Round Robin, UCB, and MCTS-Explore
2. Mutation: Five operators (Generate, Crossover, Expand, Shorten, Rephrase) using ChatGPT
3. Judgment Model: Fine-tuned RoBERTa model to assess jailbreak success
4. Evaluation: Tested on ChatGPT, LLaMa-2, Vicuna, and other commercial LLMs
5. Comparison with baselines: No Attack, GCG, Human-Written, Masterkey, and "Here Is" methods

Main Results:
1. Single-question attack: Achieved 100% success rate on previously resistant questions for Llama-2-7B-Chat
2. Multi-question attack: Attained 60% top-1 ASR and 87% top-5 ASR for Llama-2-7B-Chat
3. Transfer attack: Consistently outperformed baselines across various LLMs
   - 100% top-5 ASR for ChatGPT
   - Over 90% top-5 ASR for Claude2 and PaLM2
   - Over 60% top-5 ASR for Bard and GPT-4

Qualitative Analysis:
- GPTFUZZER demonstrates the ability to generate effective jailbreak templates even with suboptimal initial seeds
- The framework's success highlights potential vulnerabilities in current LLMs, including well-aligned commercial models
- The evolving nature of LLM defenses necessitates automated tools like GPTFUZZER for ongoing robustness evaluation

Limitations:
- Reliance on human-written templates as initial seeds may limit innovation in generated templates
- Does not encompass transformations of the questions, potentially allowing keyword matching to reject prompts
- Requires many queries to the target model, risking being blocked if queries are too frequent

Conclusion and Future Work:
GPTFUZZER proves to be a powerful tool for red teaming LLMs, consistently outperforming human-crafted templates. Future work includes:
1. Leveraging LLMs to generate initial jailbreak templates without human knowledge
2. Transforming questions to make them more natural and less suspicious
3. Developing a more comprehensive jailbreak definition and robust judgment model
4. Exploring techniques to reduce the number of queries to target models

New Tool:
GPTFUZZER - A black-box jailbreak fuzzing framework for automated generation of jailbreak prompts targeting LLMs.
GitHub repository: https://github.com/sherdencooper/GPTFuzz

## Repository Token Information
Total tokens in repository: 17008

Tokens per file:
- gptfuzz.py: 921 tokens
- README.md: 1460 tokens
- gptfuzzer/__init__.py: 0 tokens
- gptfuzzer/fuzzer/mutator.py: 2335 tokens
- gptfuzzer/fuzzer/core.py: 1477 tokens
- gptfuzzer/fuzzer/__init__.py: 12 tokens
- gptfuzzer/fuzzer/selection.py: 1479 tokens
- gptfuzzer/llm/llm.py: 2690 tokens
- gptfuzzer/llm/__init__.py: 31 tokens
- gptfuzzer/utils/predict.py: 219 tokens
- gptfuzzer/utils/template.py: 42 tokens
- gptfuzzer/utils/__init__.py: 0 tokens
- gptfuzzer/utils/openai.py: 151 tokens
- example/finetune_roberta.py: 6105 tokens
- datasets/prompts/README.md: 86 tokens


## Tutorial and Enhancement Suggestions

# GPTFUZZER Tutorial

## Project Overview

GPTFUZZER is an automated framework for generating jailbreak prompts to test the robustness of large language models (LLMs). The project implements the key concepts described in the research paper, including seed selection strategies, mutation operators, and a judgment model for evaluating jailbreak success.

### Project Structure

The repository is organized as follows:

- `gptfuzz.py`: Main script to run the fuzzing experiments
- `gptfuzzer/`: Core package containing the main components
  - `fuzzer/`: Implements the fuzzing logic
    - `core.py`: Defines the `GPTFuzzer` and `PromptNode` classes
    - `mutator.py`: Implements various mutation operators
    - `selection.py`: Implements seed selection strategies
  - `llm/`: Interfaces for different language models
    - `llm.py`: Defines base `LLM` class and specific implementations
  - `utils/`: Utility functions and classes
    - `predict.py`: Implements the judgment model
    - `template.py`: Handles prompt template synthesis
- `example/`: Contains example scripts
  - `finetune_roberta.py`: Script for fine-tuning the RoBERTa judgment model
- `datasets/`: Stores datasets used for training and initial seeds

## Key Components

### 1. GPTFuzzer (gptfuzzer/fuzzer/core.py)

The `GPTFuzzer` class is the main orchestrator of the fuzzing process. It manages the following key aspects:

- Initialization of the target model, predictor (judgment model), and initial seed prompts
- Execution of the fuzzing loop
- Evaluation of generated prompts
- Logging and result tracking

Key methods:
- `run()`: Main fuzzing loop
- `evaluate()`: Evaluates generated prompts using the target model and predictor
- `update()`: Updates the fuzzer state with new results

### 2. Mutation Operators (gptfuzzer/fuzzer/mutator.py)

The `Mutator` classes implement various strategies for modifying prompt templates:

- `OpenAIMutatorGenerateSimilar`: Generates similar templates
- `OpenAIMutatorCrossOver`: Combines two templates
- `OpenAIMutatorExpand`: Adds sentences to the beginning of a template
- `OpenAIMutatorShorten`: Condenses sentences in a template
- `OpenAIMutatorRephrase`: Rephrases sentences in a template

These operators use OpenAI's API to perform the mutations, as described in the paper.

### 3. Seed Selection Strategies (gptfuzzer/fuzzer/selection.py)

Various selection policies are implemented to choose which prompts to mutate:

- `RoundRobinSelectPolicy`: Selects prompts in a circular order
- `RandomSelectPolicy`: Randomly selects prompts
- `UCBSelectPolicy`: Uses Upper Confidence Bound algorithm
- `MCTSExploreSelectPolicy`: Implements Monte Carlo Tree Search for exploration
- `EXP3SelectPolicy`: Implements the Exponential-weight algorithm for Exploration and Exploitation

These strategies aim to balance exploration and exploitation during the fuzzing process.

### 4. Language Model Interfaces (gptfuzzer/llm/llm.py)

The `LLM` class and its subclasses provide interfaces to different language models:

- `LocalLLM`: For locally hosted models
- `LocalVLLM`: Uses vLLM for optimized inference
- `OpenAILLM`: Interface for OpenAI's API
- `PaLM2LLM`: Interface for Google's PaLM 2 model
- `ClaudeLLM`: Interface for Anthropic's Claude model

These classes handle prompt generation and batched inference for efficiency.

### 5. Judgment Model (gptfuzzer/utils/predict.py)

The `RoBERTaPredictor` class implements the judgment model using a fine-tuned RoBERTa model to classify whether a response indicates a successful jailbreak.

## Running the Fuzzer

The `gptfuzz.py` script demonstrates how to set up and run the fuzzer:

1. Initialize the target model, mutator model, and predictor
2. Create a `GPTFuzzer` instance with the desired configuration
3. Run the fuzzer using the `run()` method

The script allows customization of various parameters such as the number of queries, jailbreak threshold, and selection strategy.

## Relation to Research Paper

The implementation closely follows the methodology described in the paper:

- The seed selection strategies correspond to Section 3.2
- The mutation operators implement the techniques from Section 3.3
- The judgment model aligns with the approach in Section 3.4
- The overall fuzzing process reflects the algorithm outlined in Section 3.5

# Potential Enhancements

1. **Automated Initial Seed Generation**
   - Implement a method to generate diverse initial seeds using LLMs without relying on human-written templates
   - This could involve fine-tuning a model specifically for generating jailbreak-like prompts

2. **Question Transformation**
   - Develop techniques to transform the target questions, making them less detectable by keyword matching
   - Implement semantic preservation checks to ensure transformed questions maintain their original intent

3. **Adaptive Mutation Strategies**
   - Create a feedback loop that analyzes successful jailbreaks to inform future mutations
   - Implement a meta-learning approach that optimizes mutation strategies based on their effectiveness across different LLMs

4. **Improved Judgment Model**
   - Develop a more nuanced classification system for jailbreak attempts, beyond binary success/failure
   - Incorporate multi-task learning to simultaneously assess safety, relevance, and jailbreak success

5. **Efficient Querying and Transfer Learning**
   - Implement techniques to reduce the number of queries required, such as active learning or meta-learning
   - Develop transfer learning methods to apply knowledge gained from fuzzing one LLM to more efficiently fuzz others