#Tags
[[Research/Research Papers/2402.13517v1.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0054/LLMJailbreak

**Title:** Round Trip Translation Defence against Large Language Model Jailbreaking Attacks
**Authors:** Canaan Yung, Hadi Mohaghegh Dolatabadi, Sarah Erfani, Christopher Leckie
**Affiliation:** School of Computing and Information Systems, The University of Melbourne, Parkville, VIC, 3010, Australia
**Publication Date:** 21 Feb 2024

Summary:
This paper introduces the Round Trip Translation (RTT) method to defend against social-engineered attacks on Large Language Models (LLMs). RTT paraphrases and generalizes adversarial prompts, making it easier for LLMs to detect harmful behavior. The method shows high effectiveness in mitigating various attacks, including PAIR and MathAttack.

Key Contributions:
- Proposal of RTT as a defense mechanism against social-engineered attacks on LLMs
- Achieved over 70% mitigation on PAIR attacks, outperforming existing defenses
- First attempt to mitigate MathAttack with almost 40% attack mitigation
- Demonstrated transferability of RTT across different LLMs

Problem Statement:
LLMs are vulnerable to social-engineered attacks that are human-interpretable but challenging for LLMs to counteract. Existing defensive measures can only mitigate less than half of these attacks at most.

Methodology:
1. Round Trip Translation (RTT):
   - Consecutively translate the original adversarial prompt into multiple non-Indo-European languages before back-translating to English
   - Used Google Translate API for translations
   - Tested various configurations (RTTx, where x is the number of languages)

2. Experiments:
   - Evaluated RTT's text generalization capabilities
   - Compared RTT with other paraphrasing techniques
   - Tested RTT against PAIR attacks on multiple LLMs (Vicuna, GPT4, Llama2, Palm2)
   - Evaluated RTT against MathAttack and Greedy Coordinate Gradient attack
   - Assessed impact on benign input using GSM8K dataset

Main Results:
1. RTT3d (3 languages from different families) achieved the best performance:
   - 72% attack mitigation rate on PAIR attacks
   - Consistent performance across different LLMs (70% average mitigation)
   - Reduced ASR in Llama2 to under 5%
   - Mitigated almost 80% of attacks in Palm2

2. Outperformed SmoothLLM (current strongest defense) by almost doubling its performance

3. First defense against MathAttack with 40% mitigation rate

4. Over 70% mitigation rate against Greedy Coordinate Gradient attack

5. Preserved more than 80% of GPT-4's original performance on benign input (GSM8K dataset)

Qualitative Analysis:
- RTT generalizes adversarial prompts, making them shorter and using more common terminology
- This generalization helps reveal underlying harmful behavior, making it easier for LLMs to detect and reject
- RTT shows strong transferability across different LLMs and attack types, indicating its versatility as a defense mechanism

Limitations:
- Results may vary with different translation algorithms
- Impact on benign input tested only on grade school-level math problems
- Further testing needed on diverse datasets to increase reliability

Conclusion and Future Work:
- RTT is a promising new defense strategy against social-engineered attacks on LLMs
- Future work includes:
  1. Testing other translation algorithms
  2. Verifying RTT's performance on non-English adversarial prompts
  3. Exploring ensemble methods with multiple RTT prompts

New Tools:
- Round Trip Translation (RTT) defense
- GitHub repository: https://github.com/Cancanxxx/Round_Trip_Translation_Defence

## Repository Token Information
Total tokens in repository: 3506

Tokens per file:
- RTT.py: 668 tokens
- Experimental Details for paper.md: 1628 tokens
- README.md: 1210 tokens


## Tutorial and Enhancement Suggestions

# Tutorial: Round Trip Translation Defence against LLM Jailbreaking Attacks

## Project Overview

This repository contains the implementation of the Round Trip Translation (RTT) defense mechanism against jailbreaking attacks on Large Language Models (LLMs). The main components of the project are:

1. `RTT.py`: The core implementation of the RTT defense
2. `Experimental Details for paper.md`: Detailed information about the experimental setup
3. `README.md`: Project overview and examples

## Key Components and Functionality

### RTT.py

This file contains the main implementation of the Round Trip Translation defense. Let's break down its key components:

1. **Google Translate API Setup**:
   ```python
   os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r"YOUR JSON FILE PATH"
   translate_client = translate_v2.Client()
   ```
   This sets up the Google Translate API client for performing translations.

2. **Language Selection**:
   ```python
   sepFam = ['am', 'ar', 'ay', ...]
   ```
   This list contains language codes for non-Indo-European languages used in the RTT process.

3. **RTT Implementation**:
   ```python
   for prompt in prompts:
       trans_lang = random.choice(tmpSepFam)
       # ... (language selection)
       translated_pt = translate_client.translate(prompt, target_language=trans_lang)['translatedText']
       # ... (back-translations)
       bk3_translated_pt = translate_client.translate(bk2_translated_pt, target_language='en')['translatedText']
   ```
   This loop performs the Round Trip Translation for each prompt, using three randomly selected non-Indo-European languages before translating back to English.

4. **Output Generation**:
   ```python
   with open(r'testing.txt', 'w') as fp:
       for item in para_prompts:
           fp.write("%s\n" % item)
   ```
   This writes the RTT-processed prompts to a file for further use or analysis.

## Relation to Research Concepts

The `RTT.py` script directly implements the core idea presented in the research paper:

1. **Multiple Language Translations**: The code uses three consecutive translations to non-Indo-European languages, which aligns with the RTT3d method described in the paper as the most effective variant.

2. **Generalization and Paraphrasing**: By translating through multiple languages, the code aims to generalize and paraphrase the original prompts, making it harder for adversarial content to survive the process while preserving the general meaning.

3. **Non-Indo-European Language Focus**: The `sepFam` list contains languages from families different from English, which is crucial for the effectiveness of the RTT defense as described in the paper.

## Notable Techniques

1. **Random Language Selection**: The code randomly selects languages for each translation step, which adds variability to the defense mechanism.

2. **HTML Unescaping**: 
   ```python
   bk3_translated_pt = html.unescape(bk3_translated_pt)
   ```
   This step ensures that any HTML entities introduced during translation are properly converted back to their original characters.

# Potential Enhancements

1. **Dynamic Language Selection**:
   Implement a more sophisticated language selection algorithm that considers factors like linguistic distance from the source language or performance metrics from previous runs. This could potentially improve the generalization capabilities of the RTT defense.

2. **Parallel Processing**:
   Implement parallel processing for translating multiple prompts simultaneously, which could significantly speed up the RTT process for large datasets. This could be achieved using Python's `multiprocessing` or `concurrent.futures` modules.

3. **Integration with Multiple Translation Services**:
   Extend the code to support multiple translation services (e.g., Microsoft Translator, DeepL) and implement a fallback mechanism. This could improve reliability and potentially the quality of translations.

4. **Adaptive RTT**:
   Develop an adaptive version of RTT that adjusts the number of translation steps based on the complexity or sensitivity of the input prompt. This could optimize the trade-off between defense strength and computational cost.

5. **Prompt Analysis and Filtering**:
   Implement pre- and post-processing steps to analyze prompts for specific patterns or keywords associated with jailbreaking attempts. This could include:
   - Sentiment analysis to detect potentially harmful content
   - Named entity recognition to identify and handle sensitive information
   - Custom filters based on known attack patterns

These enhancements could push the research forward by improving the efficiency, effectiveness, and adaptability of the RTT defense mechanism against evolving jailbreaking techniques.