#Tags
[[Research/Research Papers/2310.02446v2.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0051/LLMPromptInjection
#AMLT0054/LLMJailbreak

**Title:** Low-Resource Languages Jailbreak GPT-4
**Authors:** Zheng-Xin Yong, Cristina Menghini, Stephen H. Bach
**Affiliations:** Department of Computer Science, Brown University; Data Science Institute, Brown University
**Publication Date:** October 3, 2023

Summary:
This paper exposes a cross-lingual vulnerability in GPT-4's safety mechanisms by successfully circumventing its safeguards through translating unsafe English inputs into low-resource languages. The study demonstrates that this method achieves a 79% success rate in eliciting harmful responses from GPT-4, comparable to or surpassing state-of-the-art jailbreaking attacks.

Key Contributions:
- Reveals the cross-lingual vulnerability of GPT-4's safety mechanisms
- Demonstrates the effectiveness of using low-resource languages to bypass content filters
- Highlights the potential risks associated with linguistic inequality in AI safety training
- Calls for more inclusive and comprehensive red-teaming efforts in AI safety

Problem Statement:
The research addresses the inherent weakness in current AI safety training and red-teaming efforts, which predominantly focus on high-resource languages, particularly English. This linguistic bias creates a vulnerability that can be exploited using low-resource languages to bypass safety mechanisms in large language models like GPT-4.

Methodology:
1. Translation-based jailbreaking attack:
   - Translate unsafe English inputs into various languages
   - Feed translated inputs into GPT-4
   - Translate GPT-4's responses back to English
2. Evaluation protocol:
   - Used AdvBench Harmful Behaviors dataset (520 unsafe instruction strings)
   - Tested 12 languages across low-, mid-, and high-resource categories
   - Compared results with other jailbreaking methods (AIM, base64, prefix injection, refusal suppression)
3. Human annotation for attack success classification:
   - BYPASS: Model engages with the request on-topic
   - REJECT: Model detects harmfulness and refuses to engage
   - UNCLEAR: Nonsensical or ambiguous response

Main Results:
1. Low-resource languages achieved a 79.04% attack success rate (combined)
2. High-resource languages had a 10.96% attack success rate (combined)
3. Mid-resource languages had a 21.92% attack success rate (combined)
4. Original English inputs had less than 1% success rate
5. Low-resource language attacks were most successful in topics like terrorism, financial manipulation, and misinformation

Qualitative Analysis:
- The study reveals a significant disparity in the effectiveness of safety measures between high- and low-resource languages
- This vulnerability stems from the linguistic inequality in safety training data and practices
- The ease of exploiting this vulnerability using publicly available translation APIs poses a risk to all LLM users, not just speakers of low-resource languages
- The research highlights the need for a more holistic approach to AI safety that considers linguistic diversity

Limitations:
- The study focuses solely on GPT-4 and may not generalize to other large language models
- The research does not explore the underlying reasons for GPT-4's ability to process and generate harmful content in low-resource languages
- The study relies on machine translation, which may introduce errors or inconsistencies in the input and output

Conclusion and Future Work:
- The paper calls for more comprehensive red-teaming efforts that include low-resource languages
- Emphasizes the need to develop robust multilingual safeguards with wider language coverage
- Suggests that future research should investigate the generalizability of these findings to other LLMs and explore methods to mitigate cross-lingual vulnerabilities

Relevant Figures:
Figure 1: Illustration of the translation-based jailbreaking method
Table 1: Attack success rates for different languages and jailbreaking methods
Figure 2: Breakdown of attack success rates by topic for different language resource levels