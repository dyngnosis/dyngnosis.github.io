#Tags
[[Research/Research Papers/2403.00292v2.pdf]]

#AMLT0054/LLMJailbreak
#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0044/FullMLModelAccess

**Title:** Enhancing Jailbreak Attacks with Diversity Guidance
**Authors:** Xu Zhang, Dinghao Jing, Xiaojun Wan
**Affiliation:** Wangxuan Institute of Computer Technology, Peking University
**Publication Date:** September 19, 2024 (updated)

Key Contributions:
- Proposed DPP-based Stochastic Trigger Searching (DSTS), a new optimization algorithm for jailbreak attacks
- Introduced diversity guidance through stochastic gradient search and DPP selection
- Demonstrated improved performance in jailbreak attacks compared to existing methods
- Developed a method to compute risk boundaries for different LLMs

Problem Statement:
Existing jailbreak attack methods suffer from redundant computations, limiting their performance. The paper aims to improve the effectiveness of jailbreak attacks on large language models (LLMs) while providing a new perspective on LLM safety evaluation.

Methodology:
1. Developed DSTS algorithm incorporating:
   - Beam search
   - Stochastic gradient search
   - Determinantal Point Process (DPP) selection
2. Evaluated on harmful string elicitation and harmful behavior tasks
3. Used CivilComments and AdvBench datasets for experiments
4. Tested on LLaMA-2-7B-Chat and Vicuna-7B models
5. Compared with baseline methods: GBDA, PGDC, AutoPrompt, and GCG

Main Results:
1. DSTS achieved highest attack success rates on both harmful string elicitation and harmful behavior tasks
2. Demonstrated improved performance over existing methods like AutoPrompt and GCG
3. Showed effective transfer of jailbreak attacks to larger LLMs
4. Computed risk boundaries for different LLMs using the HEx-PHI dataset

Qualitative Analysis:
- The introduction of diversity guidance in DSTS helps reduce redundant searches, leading to more effective jailbreak attacks
- The ability to transfer attacks to larger models indicates a potential scalability issue in LLM safety
- Risk boundaries provide a new perspective on LLM safety evaluation, highlighting vulnerabilities in different domains

Limitations:
- Experiments limited to LLMs with approximately 10 billion parameters
- Potential negative impact of the method being used by malicious attackers

Conclusion and Future Work:
- DSTS demonstrates improved performance in jailbreak attacks through diversity guidance
- The method provides a new approach to evaluating LLM safety through risk boundaries
- Future work could focus on extending the analysis to larger LLMs and developing more robust defense mechanisms

Figures and Tables:
- Figure 1: Illustration of prompt searching for jailbreak attacks
- Figure 2: Overview of the DSTS algorithm
- Figure 3: Performance comparison of different jailbreak attack algorithms
- Figure 4: Risk boundaries of different LLMs evaluated on HEx-PHI
- Table 1: Experimental results of different jailbreak attack algorithms
- Table 6: Detailed results of risk boundaries for each category in HEx-PHI dataset

New Tools:
- DPP-based Stochastic Trigger Searching (DSTS) algorithm for enhanced jailbreak attacks
- No specific GitHub repository mentioned in the paper