#Tags
[[Research/Research Papers/2405.19103v1.pdf]]

#AMLT0054/LLMJailbreak
#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0040/MLModelInferenceAPIAccess
#AMLT0042/VerifyAttack

**Title:** Voice Jailbreak Attacks Against GPT-4o
**Authors:** Xinyue Shen, Yixin Wu, Michael Backes, Yang Zhang
**Affiliation:** CISPA Helmholtz Center for Information Security
**Publication Date:** May 29, 2024

Key Contributions:
- First systematic measurement of jailbreak attacks against the voice mode of GPT-4o
- Proposal of VoiceJailbreak, a novel voice jailbreak attack using fictional storytelling
- Extensive experiments on interaction steps, key elements, and languages for VoiceJailbreak
- Enhancement of attack performance using advanced fictional writing techniques

Problem Statement:
The paper addresses the security risks associated with the voice mode of GPT-4o, specifically focusing on jailbreak attacks that aim to bypass safeguards and manipulate the model into generating harmful content.

Methodology:
1. Preliminary study:
   - Tested forbidden questions and text jailbreak prompts in voice mode
   - Used text-to-speech model to convert text to audio
   - Evaluated across six forbidden scenarios
2. VoiceJailbreak attack:
   - Leveraged fictional storytelling principles (setting, character, plot)
   - Conducted two-step interactions with GPT-4o
   - Tested advanced techniques: Point of View (POV), Red Herring, Foreshadowing
3. Evaluation metrics:
   - Attack Success Rate (ASR)
   - Utility metrics: duration, word count, readability

Main Results:
1. GPT-4o shows good resistance to forbidden questions and text jailbreak prompts in voice mode
   - Baseline ASR: 0.233
   - Text jailbreak prompts (audio form) ASR: 0.033
2. VoiceJailbreak significantly increases attack effectiveness
   - Average ASR increased from 0.033 to 0.778
3. Advanced techniques further enhance attack performance
   - Foreshadowing increased ASR in pornography scenario from 0.400 to 0.600
4. VoiceJailbreak performs well in multilingual contexts (e.g., Chinese)

Qualitative Analysis:
- The effectiveness of VoiceJailbreak highlights potential vulnerabilities in the voice mode of GPT-4o
- The success of fictional storytelling in bypassing safeguards suggests that current security measures may not be sufficient against creative attack vectors
- The study raises concerns about the safety of voice interactions with MLLMs and the need for improved security measures

Limitations:
- Limited to three prompts due to manual testing constraints
- Focus on audible methods only, not considering inaudible attacks
- Potential for model updates affecting results over time

Conclusion and Future Work:
- The study reveals a new attack surface in the voice mode of GPT-4o
- Highlights the need for more robust and adaptive safeguards against voice jailbreak attacks
- Suggests further research into securing MLLMs across all modalities

Tools Introduced:
VoiceJailbreak: A voice jailbreak attack method using fictional storytelling principles (No GitHub repository mentioned)