#Tags
[[Research/Research Papers/2404.08793v1.pdf]]

#AMLT0054/LLMJailbreak
#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0042/VerifyAttack
#AMLT0040/MLModelInferenceAPIAccess

**Title:** JailbreakLens: Visual Analysis of Jailbreak Attacks Against Large Language Models
**Authors:** Yingchaojie Feng, Zhizhang Chen, Zhining Kang, Sijia Wang, Minfeng Zhu, Wei Zhang, Wei Chen
**Publication Date:** April 12, 2024

Key Contributions:
- Developed an LLM-assisted framework for analyzing jailbreak prompts
- Created JailbreakLens, a visual analysis system for multi-level exploration of jailbreak prompts
- Proposed a component-based approach for analyzing jailbreak prompt characteristics
- Introduced perturbation strategies for component-level analysis
- Designed a keyword analysis method to identify important terms in jailbreak prompts

Problem Statement:
The paper addresses the challenge of comprehensively analyzing jailbreak prompts to evaluate LLMs' defensive capabilities and identify potential weaknesses. The complexity of evaluating jailbreak performance and understanding prompt characteristics makes this analysis laborious.

Methodology:
1. Collaborated with domain experts to characterize problems and design requirements
2. Developed an LLM-assisted framework for jailbreak prompt analysis:
   - Automatic jailbreak result assessment using GPT-4
   - Component classification and perturbation strategies
   - Keyword importance and performance analysis
3. Designed JailbreakLens, a visual analysis system with multiple views:
   - Configuration View
   - Summary View
   - Response View
   - Keyword View
   - Instance View
4. Conducted a case study, technical evaluations, and expert interviews

Main Results:
1. The LLM-assisted framework achieved 80.25% accuracy in jailbreak result assessment with default criteria and 90.25% with refined question-specific criteria.
2. Component classification method achieved 80.26% accuracy on the prompt component classification task.
3. The system effectively supported multi-level exploration of jailbreak prompts, enabling users to identify important components and keywords.
4. Experts found the system helpful in evaluating model security and identifying weaknesses.

Qualitative Analysis:
- The component-based analysis approach provided new insights into jailbreak prompt patterns and guided users towards critical parts of the prompts.
- The keyword analysis helped identify effective terms for jailbreak attacks, which can be used to strengthen defense mechanisms.
- The visual system's design facilitated intuitive exploration and comparison of jailbreak performance across different questions and templates.

Limitations:
- The current perturbation strategies for component analysis are limited to deletion, rephrasing, and switching.
- The system focuses primarily on textual jailbreak attacks and does not address multi-modal scenarios.
- The effectiveness of the keyword analysis may be limited when analyzing only a few prompts.

Conclusion and Future Work:
- JailbreakLens demonstrates effectiveness in supporting the security analysis of LLMs against jailbreak attacks.
- Future work includes:
  1. Incorporating more perturbation strategies for component analysis
  2. Extending the analysis to more large language models
  3. Exploring multi-modal jailbreak attacks
  4. Supporting jailbreak performance comparisons across multiple models
  5. Fine-tuning jailbreak questions to bypass safety measurements

Tools Introduced:
JailbreakLens: A visual analysis system for exploring jailbreak attacks against large language models. No GitHub repository was mentioned in the paper.