#Tags
[[Research/Research Papers/2404.02928v2.pdf]]

#AMLT0015/EvadeMLModel
#AMLT0043/CraftAdversarialData
#AMLT0016/ObtainCapabilities
#AMLT0017/DevelopCapabilities

**Title:** Jailbreaking Prompt Attack: A Controllable Adversarial Attack against Diffusion Models
**Authors:** Jiachen Ma, Anda Cao, Zhiqing Xiao, Jie Zhang, Chao Ye, Junbo Zhao
**Affiliations:** Zhejiang University, ETH Zurich
**Publication Date:** June 2, 2024

Summary:
The paper introduces the Jailbreak Prompt Attack (JPA), an automated framework for bypassing safety checkers in Text-to-Image (T2I) models to generate Not Safe for Work (NSFW) images while preserving the semantics of original prompts.

Key Contributions:
- Automated attack framework (JPA) for bypassing safety checkers in T2I models
- Method to maintain prompt semantics while evading detection
- Demonstration of JPA's effectiveness against both online services and offline defense-employed models

Problem Statement:
How to bypass various types of safety checkers in T2I models to generate NSFW images while preserving the semantics of the original prompts?

Methodology:
1. Render process:
   - Add concept embeddings to target prompt embeddings
   - Project rendered embeddings back to token space
2. Similarity learning objective:
   - Use cosine similarity to keep concatenated prompts semantically similar to rendered embedding
3. Sensitive word masking:
   - Apply masking during optimization to filter sensitive words

Main Results:
1. JPA successfully bypasses both online services and offline defense-employed models
2. Achieves high Attack Success Rate (ASR) and low Frechet Inception Distance (FID) scores
3. Outperforms existing white-box and black-box attack methods

Qualitative Analysis:
- JPA exposes vulnerabilities in the text space of T2I models
- The method reveals hidden connections within the textual space of concepts
- Findings suggest that current safety checkers are insufficient for preventing NSFW image generation

Limitations:
- Effectiveness decreases when using completely safe data instead of the I2P dataset
- The attack may not be generalizable to all types of safety checkers

Conclusion and Future Work:
- JPA demonstrates the vulnerability of T2I models to text-based attacks
- The authors suggest developing more effective safety checkers as an urgent task for future research

Relevant Figures:
- Figure 1: Illustration of safety checker types and JPA bypass process
- Figure 2: Pipeline of JPA and insight into generating NSFW images
- Figure 5: Visualization of the rendering process for the "nudity" concept

New Tools:
- Jailbreak Prompt Attack (JPA) framework (no GitHub repository mentioned)