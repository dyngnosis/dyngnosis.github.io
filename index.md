# AI Security Research Hub

Welcome to the AI Security Research Hub. Here you'll find links to our latest research papers.

## Research Papers

| Title | Tags | Last Updated |
|-------|------|---------------|
| [Leveraging the Context through Multi-Round Interactions for Jailbreaking Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.09177v2%20%5BLeveraging%20the%20Context%20through%20Multi-Round%20Interactions%20for%20Jailbreaking%20Attacks%5D_review.md) |  | 2024-10-15 |
| [Enhancing Jailbreak Attacks with Diversity Guidance review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2403.00292v2%20%5BEnhancing%20Jailbreak%20Attacks%20with%20Diversity%20Guidance%5D_review.md) |  | 2024-10-15 |
| [Distract Large Language Models for Automatic Jailbreak Attack review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2403.08424v2%20%5BDistract%20Large%20Language%20Models%20for%20Automatic%20Jailbreak%20Attack%5D_review.md) |  | 2024-10-15 |
| [Don't Listen To Me Understanding and Exploring Jailbreak Prompts of Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2403.17336v2%20%5BDon%27t%20Listen%20To%20Me%20Understanding%20and%20Exploring%20Jailbreak%20Prompts%20of%20Large%20Language%20Models%5D_review.md) |  | 2024-10-15 |
| [Great, Now Write an Article About That The Crescendo Multi-Turn LLM Jailbreak Attack review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.01833v2%20%5BGreat,%20Now%20Write%20an%20Article%20About%20That%20The%20Crescendo%20Multi-Turn%20LLM%20Jailbreak%20Attack%5D_review.md) |  | 2024-10-15 |
| [Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.02151v3%20%5BJailbreaking%20Leading%20Safety-Aligned%20LLMs%20with%20Simple%20Adaptive%20Attacks%5D_review.md) |  | 2024-10-15 |
| [Don't Say No Jailbreaking LLM by Suppressing Refusal review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.16369v2%20%5BDon%27t%20Say%20No%20Jailbreaking%20LLM%20by%20Suppressing%20Refusal%5D_review.md) |  | 2024-10-15 |
| [White-box Multimodal Jailbreaks Against Large Vision-Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.17894v2%20%5BWhite-box%20Multimodal%20Jailbreaks%20Against%20Large%20Vision-Language%20Models%5D_review.md) |  | 2024-10-15 |
| [Understanding Jailbreak Success A Study of Latent Space Dynamics in Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.09289v2%20%5BUnderstanding%20Jailbreak%20Success%20A%20Study%20of%20Latent%20Space%20Dynamics%20in%20Large%20Language%20Models%5D_review.md) |  | 2024-10-15 |
| [Bag of Tricks Benchmarking of Jailbreak Attacks on LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.09324v2%20%5BBag%20of%20Tricks%20Benchmarking%20of%20Jailbreak%20Attacks%20on%20LLMs%5D_review.md) |  | 2024-10-15 |
| [Jailbreaking as a Reward Misspecification Problem review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.14393v3%20%5BJailbreaking%20as%20a%20Reward%20Misspecification%20Problem%5D_review.md) |  | 2024-10-15 |
| [Jailbreaking LLMs with Arabic Transliteration and Arabizi review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.18725v2%20%5BJailbreaking%20LLMs%20with%20Arabic%20Transliteration%20and%20Arabizi%5D_review.md) |  | 2024-10-15 |
| [Large Language Models Are Involuntary Truth-Tellers Exploiting Fallacy Failure for Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.00869v2%20%5BLarge%20Language%20Models%20Are%20Involuntary%20Truth-Tellers%20Exploiting%20Fallacy%20Failure%20for%20Jailbreak%20Attacks%5D_review.md) |  | 2024-10-15 |
| [Cross-modality Information Check for Detecting Jailbreaking in Multimodal Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.21659v3%20%5BCross-modality%20Information%20Check%20for%20Detecting%20Jailbreaking%20in%20Multimodal%20Large%20Language%20Models%5D_review.md) |  | 2024-10-15 |
| [PathSeeker Exploring LLM Security Vulnerabilities with a Reinforcement Learning-Based Jailbreak Approach review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2409.14177v2%20%5BPathSeeker%20Exploring%20LLM%20Security%20Vulnerabilities%20with%20a%20Reinforcement%20Learning-Based%20Jailbreak%20Approach%5D_review.md) |  | 2024-10-15 |
| [Effective and Evasive Fuzz Testing-Driven Jailbreaking Attacks against LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2409.14866v2%20%5BEffective%20and%20Evasive%20Fuzz%20Testing-Driven%20Jailbreaking%20Attacks%20against%20LLMs%5D_review.md) |  | 2024-10-15 |
| [RoleBreak Character Hallucination as a Jailbreak Attack in Role-Playing Systems review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2409.16727v1%20%5BRoleBreak%20Character%20Hallucination%20as%20a%20Jailbreak%20Attack%20in%20Role-Playing%20Systems%5D_review.md) |  | 2024-10-15 |
| [RED QUEEN Safeguarding Large Language Models against Concealed Multi-Turn Jailbreaking review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2409.17458v1%20%5BRED%20QUEEN%20Safeguarding%20Large%20Language%20Models%20against%20Concealed%20Multi-Turn%20Jailbreaking%5D_review.md) |  | 2024-10-15 |
| [MoJE Mixture of Jailbreak Experts, Naive Tabular Classifiers as Guard for Prompt Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2409.17699v3%20%5BMoJE%20Mixture%20of%20Jailbreak%20Experts,%20Naive%20Tabular%20Classifiers%20as%20Guard%20for%20Prompt%20Attacks%5D_review.md) |  | 2024-10-15 |
| [Multimodal Pragmatic Jailbreak on Text-to-image Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2409.19149v1%20%5BMultimodal%20Pragmatic%20Jailbreak%20on%20Text-to-image%20Models%5D_review.md) |  | 2024-10-15 |
| [Endless Jailbreaks with Bijection Learning review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2410.01294v1%20%5BEndless%20Jailbreaks%20with%20Bijection%20Learning%5D_review.md) |  | 2024-10-15 |
| [FlipAttack Jailbreak LLMs via Flipping review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2410.02832v1%20%5BFlipAttack%20Jailbreak%20LLMs%20via%20Flipping%5D_review.md) |  | 2024-10-15 |
| [Information-Theoretical Principled Trade-off between Jailbreakability and Stealthiness on Vision Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2410.01438v1%20%5BInformation-Theoretical%20Principled%20Trade-off%20between%20Jailbreakability%20and%20Stealthiness%20on%20Vision%20Language%20Models%5D_review.md) |  | 2024-10-15 |
| [Jailbreak Antidote Runtime Safety-Utility Balance via Sparse Representation Adjustment in Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2410.02298v2%20%5BJailbreak%20Antidote%20Runtime%20Safety-Utility%20Balance%20via%20Sparse%20Representation%20Adjustment%20in%20Large%20Language%20Models%5D_review.md) |  | 2024-10-15 |
| [AutoDAN-Turbo A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2410.05295v2%20%5BAutoDAN-Turbo%20A%20Lifelong%20Agent%20for%20Strategy%20Self-Exploration%20to%20Jailbreak%20LLMs%5D_review.md) |  | 2024-10-15 |
| [Gradient-based Jailbreak Images for Multimodal Fusion Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2410.03489v1%20%5BGradient-based%20Jailbreak%20Images%20for%20Multimodal%20Fusion%20Models%5D_review.md) |  | 2024-10-15 |
| [You Know What I'm Saying Jailbreak Attack via Implicit Reference review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2410.03857v2%20%5BYou%20Know%20What%20I%27m%20Saying%20Jailbreak%20Attack%20via%20Implicit%20Reference%5D_review.md) |  | 2024-10-15 |
| [Chain-of-Jailbreak Attack for Image Generation Models via Editing Step by Step review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2410.03869v1%20%5BChain-of-Jailbreak%20Attack%20for%20Image%20Generation%20Models%20via%20Editing%20Step%20by%20Step%5D_review.md) |  | 2024-10-15 |
| [Functional Homotopy Smoothing Discrete Optimization via Continuous Parameters for LLM Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2410.04234v1%20%5BFunctional%20Homotopy%20Smoothing%20Discrete%20Optimization%20via%20Continuous%20Parameters%20for%20LLM%20Jailbreak%20Attacks%5D_review.md) |  | 2024-10-15 |
| [RePD Defending Jailbreak Attack through a Retrieval-based Prompt Decomposition Process review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2410.08660v1%20%5BRePD%20Defending%20Jailbreak%20Attack%20through%20a%20Retrieval-based%20Prompt%20Decomposition%20Process%5D_review.md) |  | 2024-10-15 |
| [AttnGCG Enhancing Jailbreaking Attacks on LLMs with Attention Manipulation review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2410.09040v1%20%5BAttnGCG%20Enhancing%20Jailbreaking%20Attacks%20on%20LLMs%20with%20Attention%20Manipulation%5D_review.md) |  | 2024-10-15 |
| [BlackDAN A Black-Box Multi-Objective Approach for Effective and Contextual Jailbreaking of Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2410.09804v1%20%5BBlackDAN%20A%20Black-Box%20Multi-Objective%20Approach%20for%20Effective%20and%20Contextual%20Jailbreaking%20of%20Large%20Language%20Models%5D_review.md) |  | 2024-10-15 |
| [Jailbreak Instruction-Tuned LLMs via end-of-sentence MLP Re-weighting review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2410.10150v1%20%5BJailbreak%20Instruction-Tuned%20LLMs%20via%20end-of-sentence%20MLP%20Re-weighting%5D_review.md) |  | 2024-10-15 |
| [h4rm3l A Dynamic Benchmark of Composable Jailbreak Attacks for LLM Safety Assessment review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.04811v2%20%5Bh4rm3l%20A%20Dynamic%20Benchmark%20of%20Composable%20Jailbreak%20Attacks%20for%20LLM%20Safety%20Assessment%5D_review.md) |  | 2024-09-22 |
| [AdaPPA Adaptive Position Pre-Fill Jailbreak Attack Approach Targeting LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2409.07503v1%20%5BAdaPPA%20Adaptive%20Position%20Pre-Fill%20Jailbreak%20Attack%20Approach%20Targeting%20LLMs%5D_review.md) |  | 2024-09-22 |
| [Unleashing Worms and Extracting Data Escalating the Outcome of Attacks against RAG-based Inference in Scale and Severity Using Jailbreaking review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2409.08045v1%20%5BUnleashing%20Worms%20and%20Extracting%20Data%20Escalating%20the%20Outcome%20of%20Attacks%20against%20RAG-based%20Inference%20in%20Scale%20and%20Severity%20Using%20Jailbreaking%5D_review.md) |  | 2024-09-22 |
| [Jailbreaking Large Language Models with Symbolic Mathematics review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2409.11445v1%20%5BJailbreaking%20Large%20Language%20Models%20with%20Symbolic%20Mathematics%5D_review.md) |  | 2024-09-22 |
| [Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2409.07353v1%20%5BSecuring%20Vision-Language%20Models%20with%20a%20Robust%20Encoder%20Against%20Jailbreak%20and%20Adversarial%20Attacks%5D_review.md) |  | 2024-09-11 |
| [Jailbreaking Text-to-Image Models with LLM-Based Agents review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.00523v2%20%5BJailbreaking%20Text-to-Image%20Models%20with%20LLM-Based%20Agents%5D_review.md) |  | 2024-09-09 |
| [SelfDefend LLMs Can Defend Themselves against Jailbreaking in a Practical Manner review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.05498v2%20%5BSelfDefend%20LLMs%20Can%20Defend%20Themselves%20against%20Jailbreaking%20in%20a%20Practical%20Manner%5D_review.md) |  | 2024-09-05 |
| [Emerging Vulnerabilities in Frontier Models Multi-Turn Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2409.00137v1%20%5BEmerging%20Vulnerabilities%20in%20Frontier%20Models%20Multi-Turn%20Jailbreak%20Attacks%5D_review.md) |  | 2024-09-04 |
| [$textit{MMJ-Bench}$ A Comprehensive Study on Jailbreak Attacks and Defenses for Vision Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.08464v2%20%5B%24textit%7BMMJ-Bench%7D%24%20A%20Comprehensive%20Study%20on%20Jailbreak%20Attacks%20and%20Defenses%20for%20Vision%20Language%20Models%5D_review.md) |  | 2024-09-04 |
| [Jailbreaking Prompt Attack A Controllable Adversarial Attack against Diffusion Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.02928v3%20%5BJailbreaking%20Prompt%20Attack%20A%20Controllable%20Adversarial%20Attack%20against%20Diffusion%20Models%5D_review.md) |  | 2024-09-04 |
| [LLM Defenses Are Not Robust to Multi-Turn Human Jailbreaks Yet review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.15221v2%20%5BLLM%20Defenses%20Are%20Not%20Robust%20to%20Multi-Turn%20Human%20Jailbreaks%20Yet%5D_review.md) |  | 2024-09-04 |
| [Jailbreak Attacks and Defenses Against Large Language Models A Survey review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.04295v2%20%5BJailbreak%20Attacks%20and%20Defenses%20Against%20Large%20Language%20Models%20A%20Survey%5D_review.md) |  | 2024-09-01 |
| [A StrongREJECT for Empty Jailbreaks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.10260v2%20%5BA%20StrongREJECT%20for%20Empty%20Jailbreaks%5D_review.md) |  | 2024-08-30 |
| [Image-to-Text Logic Jailbreak Your Imagination can Help You Do Anything review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.02534v2%20%5BImage-to-Text%20Logic%20Jailbreak%20Your%20Imagination%20can%20Help%20You%20Do%20Anything%5D_review.md) |  | 2024-08-30 |
| [Can Large Language Models Automatically Jailbreak GPT-4V review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.16686v2%20%5BCan%20Large%20Language%20Models%20Automatically%20Jailbreak%20GPT-4V%5D_review.md) |  | 2024-08-30 |
| [The Dark Side of Function Calling Pathways to Jailbreaking Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.17915v3%20%5BThe%20Dark%20Side%20of%20Function%20Calling%20Pathways%20to%20Jailbreaking%20Large%20Language%20Models%5D_review.md) |  | 2024-08-30 |
| [Perception-guided Jailbreak against Text-to-Image Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.10848v2%20%5BPerception-guided%20Jailbreak%20against%20Text-to-Image%20Models%5D_review.md) |  | 2024-08-30 |
| [RT-Attack Jailbreaking Text-to-Image Models via Random Token review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.13896v2%20%5BRT-Attack%20Jailbreaking%20Text-to-Image%20Models%20via%20Random%20Token%5D_review.md) |  | 2024-08-30 |
| [Investigating Coverage Criteria in Large Language Models An In-Depth Study Through Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.15207v1%20%5BInvestigating%20Coverage%20Criteria%20in%20Large%20Language%20Models%20An%20In-Depth%20Study%20Through%20Jailbreak%20Attacks%5D_review.md) |  | 2024-08-30 |
| [LLM Defenses Are Not Robust to Multi-Turn Human Jailbreaks Yet review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.15221v1%20%5BLLM%20Defenses%20Are%20Not%20Robust%20to%20Multi-Turn%20Human%20Jailbreaks%20Yet%5D_review.md) |  | 2024-08-30 |
| [Unlocking Adversarial Suffix Optimization Without Affirmative Phrases Efficient Black-box Jailbreaking via LLM as Optimizer review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.11313v1%20%5BUnlocking%20Adversarial%20Suffix%20Optimization%20Without%20Affirmative%20Phrases%20Efficient%20Black-box%20Jailbreaking%20via%20LLM%20as%20Optimizer%5D_review.md) |  | 2024-08-23 |
| [Jailbreaking Black Box Large Language Models in Twenty Queries review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2310.08419v4%20%5BJailbreaking%20Black%20Box%20Large%20Language%20Models%20in%20Twenty%20Queries%5D_review.md) |  | 2024-08-23 |
| [Fight Back Against Jailbreaking via Prompt Adversarial Tuning review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.06255v3%20%5BFight%20Back%20Against%20Jailbreaking%20via%20Prompt%20Adversarial%20Tuning%5D_review.md) |  | 2024-08-22 |
| [Medical MLLM is Vulnerable Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.20775v2%20%5BMedical%20MLLM%20is%20Vulnerable%20Cross-Modality%20Jailbreak%20and%20Mismatched%20Attacks%20on%20Medical%20Multimodal%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [The Dark Side of Function Calling Pathways to Jailbreaking Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.17915v2%20%5BThe%20Dark%20Side%20of%20Function%20Calling%20Pathways%20to%20Jailbreaking%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Prefix Guidance A Steering Wheel for Large Language Models to Defend Against Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.08924v2%20%5BPrefix%20Guidance%20A%20Steering%20Wheel%20for%20Large%20Language%20Models%20to%20Defend%20Against%20Jailbreak%20Attacks%5D_review.md) |  | 2024-08-22 |
| [Large Language Models Are Involuntary Truth-Tellers Exploiting Fallacy Failure for Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.00869v1%20%5BLarge%20Language%20Models%20Are%20Involuntary%20Truth-Tellers%20Exploiting%20Fallacy%20Failure%20for%20Jailbreak%20Attacks%5D_review.md) |  | 2024-08-22 |
| [AutoJailbreak Exploring Jailbreak Attacks and Defenses through a Dependency Lens review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.03805v1%20%5BAutoJailbreak%20Exploring%20Jailbreak%20Attacks%20and%20Defenses%20through%20a%20Dependency%20Lens%5D_review.md) |  | 2024-08-22 |
| [JailbreakEval An Integrated Toolkit for Evaluating Jailbreak Attempts Against Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.09321v1%20%5BJailbreakEval%20An%20Integrated%20Toolkit%20for%20Evaluating%20Jailbreak%20Attempts%20Against%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Foot In The Door Understanding Large Language Model Jailbreaking via Cognitive Psychology review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.15690v1%20%5BFoot%20In%20The%20Door%20Understanding%20Large%20Language%20Model%20Jailbreaking%20via%20Cognitive%20Psychology%5D_review.md) |  | 2024-08-22 |
| [Universal and Transferable Adversarial Attacks on Aligned Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2307.15043v2%20%5BUniversal%20and%20Transferable%20Adversarial%20Attacks%20on%20Aligned%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Enhancing Jailbreak Attack Against Large Language Models through Silent Tokens review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.20653v2%20%5BEnhancing%20Jailbreak%20Attack%20Against%20Large%20Language%20Models%20through%20Silent%20Tokens%5D_review.md) |  | 2024-08-22 |
| [Perception-guided Jailbreak against Text-to-Image Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.10848v1%20%5BPerception-guided%20Jailbreak%20against%20Text-to-Image%20Models%5D_review.md) |  | 2024-08-22 |
| [Exploiting Uncommon Text-Encoded Structures for Automated Jailbreaks in LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.08754v2%20%5BExploiting%20Uncommon%20Text-Encoded%20Structures%20for%20Automated%20Jailbreaks%20in%20LLMs%5D_review.md) |  | 2024-08-22 |
| [SneakyPrompt Jailbreaking Text-to-image Generative Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2305.12082v3%20%5BSneakyPrompt%20Jailbreaking%20Text-to-image%20Generative%20Models%5D_review.md) |  | 2024-08-22 |
| [COLD-Attack Jailbreaking LLMs with Stealthiness and Controllability review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.08679v2%20%5BCOLD-Attack%20Jailbreaking%20LLMs%20with%20Stealthiness%20and%20Controllability%5D_review.md) |  | 2024-08-22 |
| [Defensive Prompt Patch A Robust and Interpretable Defense of LLMs against Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.20099v1%20%5BDefensive%20Prompt%20Patch%20A%20Robust%20and%20Interpretable%20Defense%20of%20LLMs%20against%20Jailbreak%20Attacks%5D_review.md) |  | 2024-08-22 |
| [Visual Adversarial Examples Jailbreak Aligned Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2306.13213v2%20%5BVisual%20Adversarial%20Examples%20Jailbreak%20Aligned%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [SoP Unlock the Power of Social Facilitation for Automatic Jailbreak Attack review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.01902v1%20%5BSoP%20Unlock%20the%20Power%20of%20Social%20Facilitation%20for%20Automatic%20Jailbreak%20Attack%5D_review.md) |  | 2024-08-22 |
| [A Wolf in Sheep's Clothing Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2311.08268v4%20%5BA%20Wolf%20in%20Sheep%27s%20Clothing%20Generalized%20Nested%20Jailbreak%20Prompts%20can%20Fool%20Large%20Language%20Models%20Easily%5D_review.md) |  | 2024-08-22 |
| [Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2401.17263v4%20%5BRobust%20Prompt%20Optimization%20for%20Defending%20Language%20Models%20Against%20Jailbreaking%20Attacks%5D_review.md) |  | 2024-08-22 |
| [Jailbreaking LLMs with Arabic Transliteration and Arabizi review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.18725v1%20%5BJailbreaking%20LLMs%20with%20Arabic%20Transliteration%20and%20Arabizi%5D_review.md) |  | 2024-08-22 |
| [Jailbreak Vision Language Models via Bi-Modal Adversarial Prompt review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.04031v2%20%5BJailbreak%20Vision%20Language%20Models%20via%20Bi-Modal%20Adversarial%20Prompt%5D_review.md) |  | 2024-08-22 |
| [Not Aligned is Not Malicious Being Careful about Hallucinations of Large Language Models' Jailbreak review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.11668v1%20%5BNot%20Aligned%20is%20Not%20Malicious%20Being%20Careful%20about%20Hallucinations%20of%20Large%20Language%20Models%27%20Jailbreak%5D_review.md) |  | 2024-08-22 |
| [Jailbreaking Text-to-Image Models with LLM-Based Agents review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.00523v1%20%5BJailbreaking%20Text-to-Image%20Models%20with%20LLM-Based%20Agents%5D_review.md) |  | 2024-08-22 |
| [Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2310.06987v1%20%5BCatastrophic%20Jailbreak%20of%20Open-source%20LLMs%20via%20Exploiting%20Generation%5D_review.md) |  | 2024-08-22 |
| [Testing the Limits of Jailbreaking Defenses with the Purple Problem review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2403.14725v2%20%5BTesting%20the%20Limits%20of%20Jailbreaking%20Defenses%20with%20the%20Purple%20Problem%5D_review.md) |  | 2024-08-22 |
| [EasyJailbreak A Unified Framework for Jailbreaking Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2403.12171v1%20%5BEasyJailbreak%20A%20Unified%20Framework%20for%20Jailbreaking%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [STAR SocioTechnical Approach to Red Teaming Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.11757v3%20%5BSTAR%20SocioTechnical%20Approach%20to%20Red%20Teaming%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Jailbreaking Attack against Multimodal Large Language Model review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.02309v1%20%5BJailbreaking%20Attack%20against%20Multimodal%20Large%20Language%20Model%5D_review.md) |  | 2024-08-22 |
| [WildTeaming at Scale From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.18510v1%20%5BWildTeaming%20at%20Scale%20From%20In-the-Wild%20Jailbreaks%20to%20%28Adversarially%29%20Safer%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [GUARD Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.03299v4%20%5BGUARD%20Role-playing%20to%20Generate%20Natural-language%20Jailbreakings%20to%20Test%20Guideline%20Adherence%20of%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Latent Jailbreak A Benchmark for Evaluating Text Safety and Output Robustness of Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2307.08487v3%20%5BLatent%20Jailbreak%20A%20Benchmark%20for%20Evaluating%20Text%20Safety%20and%20Output%20Robustness%20of%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Can Large Language Models Automatically Jailbreak GPT-4V review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.16686v1%20%5BCan%20Large%20Language%20Models%20Automatically%20Jailbreak%20GPT-4V%5D_review.md) |  | 2024-08-22 |
| [Towards Understanding Jailbreak Attacks in LLMs A Representation Space Analysis review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.10794v2%20%5BTowards%20Understanding%20Jailbreak%20Attacks%20in%20LLMs%20A%20Representation%20Space%20Analysis%5D_review.md) |  | 2024-08-22 |
| [Voice Jailbreak Attacks Against GPT-4o review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.19103v1%20%5BVoice%20Jailbreak%20Attacks%20Against%20GPT-4o%5D_review.md) |  | 2024-08-22 |
| [Multilingual Jailbreak Challenges in Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2310.06474v3%20%5BMultilingual%20Jailbreak%20Challenges%20in%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [When LLM Meets DRL Advancing Jailbreaking Efficiency via DRL-guided Search review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.08705v1%20%5BWhen%20LLM%20Meets%20DRL%20Advancing%20Jailbreaking%20Efficiency%20via%20DRL-guided%20Search%5D_review.md) |  | 2024-08-22 |
| [FuzzLLM A Novel and Universal Fuzzing Framework for Proactively Discovering Jailbreak Vulnerabilities in Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2309.05274v2%20%5BFuzzLLM%20A%20Novel%20and%20Universal%20Fuzzing%20Framework%20for%20Proactively%20Discovering%20Jailbreak%20Vulnerabilities%20in%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Leveraging the Context through Multi-Round Interactions for Jailbreaking Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.09177v1%20%5BLeveraging%20the%20Context%20through%20Multi-Round%20Interactions%20for%20Jailbreaking%20Attacks%5D_review.md) |  | 2024-08-22 |
| [Are Large Language Models Really Bias-Free Jailbreak Prompts for Assessing Adversarial Robustness to Bias Elicitation review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.08441v1%20%5BAre%20Large%20Language%20Models%20Really%20Bias-Free%20Jailbreak%20Prompts%20for%20Assessing%20Adversarial%20Robustness%20to%20Bias%20Elicitation%5D_review.md) |  | 2024-08-22 |
| [FigStep Jailbreaking Large Vision-language Models via Typographic Visual Prompts review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2311.05608v2%20%5BFigStep%20Jailbreaking%20Large%20Vision-language%20Models%20via%20Typographic%20Visual%20Prompts%5D_review.md) |  | 2024-08-22 |
| [Pandora Jailbreak GPTs by Retrieval Augmented Generation Poisoning review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.08416v1%20%5BPandora%20Jailbreak%20GPTs%20by%20Retrieval%20Augmented%20Generation%20Poisoning%5D_review.md) |  | 2024-08-22 |
| [EEG-Defender Defending against Jailbreak through Early Exit Generation of Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.11308v1%20%5BEEG-Defender%20Defending%20against%20Jailbreak%20through%20Early%20Exit%20Generation%20of%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Comprehensive Assessment of Jailbreak Attacks Against LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.05668v1%20%5BComprehensive%20Assessment%20of%20Jailbreak%20Attacks%20Against%20LLMs%5D_review.md) |  | 2024-08-22 |
| [Why Are My Prompts Leaked Unraveling Prompt Extraction Threats in Customized Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.02416v1%20%5BWhy%20Are%20My%20Prompts%20Leaked%20Unraveling%20Prompt%20Extraction%20Threats%20in%20Customized%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [DeCE Deceptive Cross-Entropy Loss Designed for Defending Backdoor Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.08956v2%20%5BDeCE%20Deceptive%20Cross-Entropy%20Loss%20Designed%20for%20Defending%20Backdoor%20Attacks%5D_review.md) |  | 2024-08-22 |
| [Play Guessing Game with LLM Indirect Jailbreak Attack with Implicit Clues review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.09091v2%20%5BPlay%20Guessing%20Game%20with%20LLM%20Indirect%20Jailbreak%20Attack%20with%20Implicit%20Clues%5D_review.md) |  | 2024-08-22 |
| [JailBreakV-28K A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.03027v3%20%5BJailBreakV-28K%20A%20Benchmark%20for%20Assessing%20the%20Robustness%20of%20MultiModal%20Large%20Language%20Models%20against%20Jailbreak%20Attacks%5D_review.md) |  | 2024-08-22 |
| [EnJa Ensemble Jailbreak on Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.03603v1%20%5BEnJa%20Ensemble%20Jailbreak%20on%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Human-Interpretable Adversarial Prompt Attack on Large Language Models with Situational Context review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.14644v2%20%5BHuman-Interpretable%20Adversarial%20Prompt%20Attack%20on%20Large%20Language%20Models%20with%20Situational%20Context%5D_review.md) |  | 2024-08-22 |
| [Fight Back Against Jailbreaking via Prompt Adversarial Tuning review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.06255v2%20%5BFight%20Back%20Against%20Jailbreaking%20via%20Prompt%20Adversarial%20Tuning%5D_review.md) |  | 2024-08-22 |
| [Automatic Jailbreaking of the Text-to-Image Generative AI Systems review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.16567v2%20%5BAutomatic%20Jailbreaking%20of%20the%20Text-to-Image%20Generative%20AI%20Systems%5D_review.md) |  | 2024-08-22 |
| [ASETF A Novel Method for Jailbreak Attack on LLMs through Translate Suffix Embeddings review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.16006v2%20%5BASETF%20A%20Novel%20Method%20for%20Jailbreak%20Attack%20on%20LLMs%20through%20Translate%20Suffix%20Embeddings%5D_review.md) |  | 2024-08-22 |
| [Multi-step Jailbreaking Privacy Attacks on ChatGPT review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2304.05197v3%20%5BMulti-step%20Jailbreaking%20Privacy%20Attacks%20on%20ChatGPT%5D_review.md) |  | 2024-08-22 |
| [textit{MMJ-Bench} A Comprehensive Study on Jailbreak Attacks and Defenses for Vision Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.08464v1%20%5Btextit%7BMMJ-Bench%7D%20A%20Comprehensive%20Study%20on%20Jailbreak%20Attacks%20and%20Defenses%20for%20Vision%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Tree of Attacks Jailbreaking Black-Box LLMs Automatically review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2312.02119v2%20%5BTree%20of%20Attacks%20Jailbreaking%20Black-Box%20LLMs%20Automatically%5D_review.md) |  | 2024-08-22 |
| [Merging Improves Self-Critique Against Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.07188v2%20%5BMerging%20Improves%20Self-Critique%20Against%20Jailbreak%20Attacks%5D_review.md) |  | 2024-08-22 |
| [Open Sesame! Universal Black Box Jailbreaking of Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2309.01446v4%20%5BOpen%20Sesame%21%20Universal%20Black%20Box%20Jailbreaking%20of%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Red teaming ChatGPT via Jailbreaking Bias, Robustness, Reliability and Toxicity review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2301.12867v4%20%5BRed%20teaming%20ChatGPT%20via%20Jailbreaking%20Bias,%20Robustness,%20Reliability%20and%20Toxicity%5D_review.md) |  | 2024-08-22 |
| [Jailbreaking Quantum Computers review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.05941v1%20%5BJailbreaking%20Quantum%20Computers%5D_review.md) |  | 2024-08-22 |
| [Compromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.04522v1%20%5BCompromesso%21%20Italian%20Many-Shot%20Jailbreaks%20Undermine%20the%20Safety%20of%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Defending Jailbreak Prompts via In-Context Adversarial Game review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.13148v2%20%5BDefending%20Jailbreak%20Prompts%20via%20In-Context%20Adversarial%20Game%5D_review.md) |  | 2024-08-22 |
| [DeepInception Hypnotize Large Language Model to Be Jailbreaker review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2311.03191v4%20%5BDeepInception%20Hypnotize%20Large%20Language%20Model%20to%20Be%20Jailbreaker%5D_review.md) |  | 2024-08-22 |
| [Gemma Scope Open Sparse Autoencoders Everywhere All At Once on Gemma 2 review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.05147v2%20%5BGemma%20Scope%20Open%20Sparse%20Autoencoders%20Everywhere%20All%20At%20Once%20on%20Gemma%202%5D_review.md) |  | 2024-08-22 |
| [Rapid Optimization for Jailbreaking LLMs via Subconscious Exploitation and Echopraxia review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.05467v1%20%5BRapid%20Optimization%20for%20Jailbreaking%20LLMs%20via%20Subconscious%20Exploitation%20and%20Echopraxia%5D_review.md) |  | 2024-08-22 |
| [Jailbreaking Prompt Attack A Controllable Adversarial Attack against Diffusion Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.02928v2%20%5BJailbreaking%20Prompt%20Attack%20A%20Controllable%20Adversarial%20Attack%20against%20Diffusion%20Models%5D_review.md) |  | 2024-08-22 |
| [Adversarial Tuning Defending Against Jailbreak Attacks for LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.06622v1%20%5BAdversarial%20Tuning%20Defending%20Against%20Jailbreak%20Attacks%20for%20LLMs%5D_review.md) |  | 2024-08-22 |
| [Jailbreaking as a Reward Misspecification Problem review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.14393v2%20%5BJailbreaking%20as%20a%20Reward%20Misspecification%20Problem%5D_review.md) |  | 2024-08-22 |
| [Virtual Context Enhancing Jailbreak Attacks with Special Token Injection review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.19845v2%20%5BVirtual%20Context%20Enhancing%20Jailbreak%20Attacks%20with%20Special%20Token%20Injection%5D_review.md) |  | 2024-08-22 |
| [Jailbreaking Large Language Models Against Moderation Guardrails via Cipher Characters review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.20413v1%20%5BJailbreaking%20Large%20Language%20Models%20Against%20Moderation%20Guardrails%20via%20Cipher%20Characters%5D_review.md) |  | 2024-08-22 |
| [Jailbreaking ChatGPT via Prompt Engineering An Empirical Study review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2305.13860v2%20%5BJailbreaking%20ChatGPT%20via%20Prompt%20Engineering%20An%20Empirical%20Study%5D_review.md) |  | 2024-08-22 |
| [Hide Your Malicious Goal Into Benign Narratives Jailbreak Large Language Models through Neural Carrier Articles review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.11182v1%20%5BHide%20Your%20Malicious%20Goal%20Into%20Benign%20Narratives%20Jailbreak%20Large%20Language%20Models%20through%20Neural%20Carrier%20Articles%5D_review.md) |  | 2024-08-22 |
| [Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2310.06387v3%20%5BJailbreak%20and%20Guard%20Aligned%20Language%20Models%20with%20Only%20Few%20In-Context%20Demonstrations%5D_review.md) |  | 2024-08-22 |
| [How Alignment and Jailbreak Work Explain LLM Safety through Intermediate Hidden States review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.05644v2%20%5BHow%20Alignment%20and%20Jailbreak%20Work%20Explain%20LLM%20Safety%20through%20Intermediate%20Hidden%20States%5D_review.md) |  | 2024-08-22 |
| [Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.02151v2%20%5BJailbreaking%20Leading%20Safety-Aligned%20LLMs%20with%20Simple%20Adaptive%20Attacks%5D_review.md) |  | 2024-08-22 |
| [AVIBench Towards Evaluating the Robustness of Large Vision-Language Model on Adversarial Visual-Instructions review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2403.09346v1%20%5BAVIBench%20Towards%20Evaluating%20the%20Robustness%20of%20Large%20Vision-Language%20Model%20on%20Adversarial%20Visual-Instructions%5D_review.md) |  | 2024-08-22 |
| [Prefix Guidance A Steering Wheel for Large Language Models to Defend Against Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.08924v1%20%5BPrefix%20Guidance%20A%20Steering%20Wheel%20for%20Large%20Language%20Models%20to%20Defend%20Against%20Jailbreak%20Attacks%5D_review.md) |  | 2024-08-22 |
| [Universal Jailbreak Backdoors from Poisoned Human Feedback review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2311.14455v4%20%5BUniversal%20Jailbreak%20Backdoors%20from%20Poisoned%20Human%20Feedback%5D_review.md) |  | 2024-08-22 |
| [The Threats of Embodied Multimodal LLMs Jailbreaking Robotic Manipulation in the Physical World review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.20242v2%20%5BThe%20Threats%20of%20Embodied%20Multimodal%20LLMs%20Jailbreaking%20Robotic%20Manipulation%20in%20the%20Physical%20World%5D_review.md) |  | 2024-08-22 |
| [Round Trip Translation Defence against Large Language Model Jailbreaking Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.13517v1%20%5BRound%20Trip%20Translation%20Defence%20against%20Large%20Language%20Model%20Jailbreaking%20Attacks%5D_review.md) |  | 2024-08-22 |
| [Breaking Agents Compromising Autonomous LLM Agents Through Malfunction Amplification review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.20859v1%20%5BBreaking%20Agents%20Compromising%20Autonomous%20LLM%20Agents%20Through%20Malfunction%20Amplification%5D_review.md) |  | 2024-08-22 |
| [Tricking LLMs into Disobedience Formalizing, Analyzing, and Detecting Jailbreaks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2305.14965v4%20%5BTricking%20LLMs%20into%20Disobedience%20Formalizing,%20Analyzing,%20and%20Detecting%20Jailbreaks%5D_review.md) |  | 2024-08-22 |
| [Continuous Embedding Attacks via Clipped Inputs in Jailbreaking Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.13796v1%20%5BContinuous%20Embedding%20Attacks%20via%20Clipped%20Inputs%20in%20Jailbreaking%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Learning To See But Forgetting To Follow Visual Instruction Tuning Makes LLMs More Prone To Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.04403v1%20%5BLearning%20To%20See%20But%20Forgetting%20To%20Follow%20Visual%20Instruction%20Tuning%20Makes%20LLMs%20More%20Prone%20To%20Jailbreak%20Attacks%5D_review.md) |  | 2024-08-22 |
| [Subtoxic Questions Dive Into Attitude Change of LLM's Response in Jailbreak Attempts review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.08309v1%20%5BSubtoxic%20Questions%20Dive%20Into%20Attitude%20Change%20of%20LLM%27s%20Response%20in%20Jailbreak%20Attempts%5D_review.md) |  | 2024-08-22 |
| [The Dark Side of Function Calling Pathways to Jailbreaking Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.17915v1%20%5BThe%20Dark%20Side%20of%20Function%20Calling%20Pathways%20to%20Jailbreaking%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Tastle Distract Large Language Models for Automatic Jailbreak Attack review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2403.08424v1%20%5BTastle%20Distract%20Large%20Language%20Models%20for%20Automatic%20Jailbreak%20Attack%5D_review.md) |  | 2024-08-22 |
| [Safe Unlearning A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.02855v1%20%5BSafe%20Unlearning%20A%20Surprisingly%20Effective%20and%20Generalizable%20Solution%20to%20Defend%20Against%20Jailbreak%20Attacks%5D_review.md) |  | 2024-08-22 |
| [PARDEN, Can You Repeat That Defending against Jailbreaks via Repetition review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.07932v2%20%5BPARDEN,%20Can%20You%20Repeat%20That%20Defending%20against%20Jailbreaks%20via%20Repetition%5D_review.md) |  | 2024-08-22 |
| [Improved Techniques for Optimization-Based Jailbreaking on Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.21018v2%20%5BImproved%20Techniques%20for%20Optimization-Based%20Jailbreaking%20on%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Jailbreak Attacks and Defenses Against Large Language Models A Survey review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.04295v1%20%5BJailbreak%20Attacks%20and%20Defenses%20Against%20Large%20Language%20Models%20A%20Survey%5D_review.md) |  | 2024-08-22 |
| [States as Strings as Strategies Steering Language Models with Game-Theoretic Solvers review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.01704v2%20%5BStates%20as%20Strings%20as%20Strategies%20Steering%20Language%20Models%20with%20Game-Theoretic%20Solvers%5D_review.md) |  | 2024-08-22 |
| [Making Them Ask and Answer Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.18104v2%20%5BMaking%20Them%20Ask%20and%20Answer%20Jailbreaking%20Large%20Language%20Models%20in%20Few%20Queries%20via%20Disguise%20and%20Reconstruction%5D_review.md) |  | 2024-08-22 |
| [Image-to-Text Logic Jailbreak Your Imagination can Help You Do Anything review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.02534v1%20%5BImage-to-Text%20Logic%20Jailbreak%20Your%20Imagination%20can%20Help%20You%20Do%20Anything%5D_review.md) |  | 2024-08-22 |
| [GPT-4 Jailbreaks Itself with Near-Perfect Success Using Self-Explanation review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.13077v1%20%5BGPT-4%20Jailbreaks%20Itself%20with%20Near-Perfect%20Success%20Using%20Self-Explanation%5D_review.md) |  | 2024-08-22 |
| [Semantic Mirror Jailbreak Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.14872v2%20%5BSemantic%20Mirror%20Jailbreak%20Genetic%20Algorithm%20Based%20Jailbreak%20Prompts%20Against%20Open-source%20LLMs%5D_review.md) |  | 2024-08-22 |
| [InjecAgent Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2403.02691v3%20%5BInjecAgent%20Benchmarking%20Indirect%20Prompt%20Injections%20in%20Tool-Integrated%20Large%20Language%20Model%20Agents%5D_review.md) |  | 2024-08-22 |
| [Do Anything Now Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2308.03825v2%20%5BDo%20Anything%20Now%20Characterizing%20and%20Evaluating%20In-The-Wild%20Jailbreak%20Prompts%20on%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [SmoothLLM Defending Large Language Models Against Jailbreaking Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2310.03684v4%20%5BSmoothLLM%20Defending%20Large%20Language%20Models%20Against%20Jailbreaking%20Attacks%5D_review.md) |  | 2024-08-22 |
| [Fast Adversarial Attacks on Language Models In One GPU Minute review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.15570v1%20%5BFast%20Adversarial%20Attacks%20on%20Language%20Models%20In%20One%20GPU%20Minute%5D_review.md) |  | 2024-08-22 |
| [Competition Report Finding Universal Jailbreak Backdoors in Aligned LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.14461v2%20%5BCompetition%20Report%20Finding%20Universal%20Jailbreak%20Backdoors%20in%20Aligned%20LLMs%5D_review.md) |  | 2024-08-22 |
| [Figure it Out Analyzing-based Jailbreak Attack on Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.16205v3%20%5BFigure%20it%20Out%20Analyzing-based%20Jailbreak%20Attack%20on%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Accelerating Greedy Coordinate Gradient via Probe Sampling review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2403.01251v2%20%5BAccelerating%20Greedy%20Coordinate%20Gradient%20via%20Probe%20Sampling%5D_review.md) |  | 2024-08-22 |
| [GradSafe Detecting Jailbreak Prompts for LLMs via Safety-Critical Gradient Analysis review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.13494v2%20%5BGradSafe%20Detecting%20Jailbreak%20Prompts%20for%20LLMs%20via%20Safety-Critical%20Gradient%20Analysis%5D_review.md) |  | 2024-08-22 |
| [ObscurePrompt Jailbreaking Large Language Models via Obscure Input review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.13662v1%20%5BObscurePrompt%20Jailbreaking%20Large%20Language%20Models%20via%20Obscure%20Input%5D_review.md) |  | 2024-08-22 |
| [JailbreakHunter A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.03045v1%20%5BJailbreakHunter%20A%20Visual%20Analytics%20Approach%20for%20Jailbreak%20Prompts%20Discovery%20from%20Large-Scale%20Human-LLM%20Conversational%20Datasets%5D_review.md) |  | 2024-08-22 |
| [When Do Universal Image Jailbreaks Transfer Between Vision-Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.15211v1%20%5BWhen%20Do%20Universal%20Image%20Jailbreaks%20Transfer%20Between%20Vision-Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Scalable and Transferable Black-Box Jailbreaks for Language Models via Persona Modulation review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2311.03348v2%20%5BScalable%20and%20Transferable%20Black-Box%20Jailbreaks%20for%20Language%20Models%20via%20Persona%20Modulation%5D_review.md) |  | 2024-08-22 |
| [A StrongREJECT for Empty Jailbreaks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.10260v1%20%5BA%20StrongREJECT%20for%20Empty%20Jailbreaks%5D_review.md) |  | 2024-08-22 |
| [Jailbreaking Proprietary Large Language Models using Word Substitution Cipher review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.10601v1%20%5BJailbreaking%20Proprietary%20Large%20Language%20Models%20using%20Word%20Substitution%20Cipher%5D_review.md) |  | 2024-08-22 |
| [Aurora-M The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.00399v2%20%5BAurora-M%20The%20First%20Open%20Source%20Multilingual%20Language%20Model%20Red-teamed%20according%20to%20the%20U.S.%20Executive%20Order%5D_review.md) |  | 2024-08-22 |
| [ALERT A Comprehensive Benchmark for Assessing Large Language Models' Safety through Red Teaming review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.08676v3%20%5BALERT%20A%20Comprehensive%20Benchmark%20for%20Assessing%20Large%20Language%20Models%27%20Safety%20through%20Red%20Teaming%5D_review.md) |  | 2024-08-22 |
| [Hidden You Malicious Goal Into Benign Narratives Jailbreak Large Language Models through Logic Chain Injection review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.04849v2%20%5BHidden%20You%20Malicious%20Goal%20Into%20Benign%20Narratives%20Jailbreak%20Large%20Language%20Models%20through%20Logic%20Chain%20Injection%5D_review.md) |  | 2024-08-22 |
| [Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2311.09096v2%20%5BDefending%20Large%20Language%20Models%20Against%20Jailbreaking%20Attacks%20Through%20Goal%20Prioritization%5D_review.md) |  | 2024-08-22 |
| [A Comprehensive Study of Jailbreak Attack versus Defense for Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.13457v2%20%5BA%20Comprehensive%20Study%20of%20Jailbreak%20Attack%20versus%20Defense%20for%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [ArtPrompt ASCII Art-based Jailbreak Attacks against Aligned LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.11753v4%20%5BArtPrompt%20ASCII%20Art-based%20Jailbreak%20Attacks%20against%20Aligned%20LLMs%5D_review.md) |  | 2024-08-22 |
| [AutoBreach Universal and Adaptive Jailbreaking with Efficient Wordplay-Guided Optimization review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.19668v1%20%5BAutoBreach%20Universal%20and%20Adaptive%20Jailbreaking%20with%20Efficient%20Wordplay-Guided%20Optimization%5D_review.md) |  | 2024-08-22 |
| [Unveiling the Safety of GPT-4o An Empirical Study using Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.06302v2%20%5BUnveiling%20the%20Safety%20of%20GPT-4o%20An%20Empirical%20Study%20using%20Jailbreak%20Attacks%5D_review.md) |  | 2024-08-22 |
| [DrAttack Prompt Decomposition and Reconstruction Makes Powerful LLM Jailbreakers review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.16914v2%20%5BDrAttack%20Prompt%20Decomposition%20and%20Reconstruction%20Makes%20Powerful%20LLM%20Jailbreakers%5D_review.md) |  | 2024-08-22 |
| [ImgTrojan Jailbreaking Vision-Language Models with ONE Image review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2403.02910v2%20%5BImgTrojan%20Jailbreaking%20Vision-Language%20Models%20with%20ONE%20Image%5D_review.md) |  | 2024-08-22 |
| [RL-JACK Reinforcement Learning-powered Black-box Jailbreaking Attack against LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.08725v1%20%5BRL-JACK%20Reinforcement%20Learning-powered%20Black-box%20Jailbreaking%20Attack%20against%20LLMs%5D_review.md) |  | 2024-08-22 |
| [A Cross-Language Investigation into Jailbreak Attacks in Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2401.16765v1%20%5BA%20Cross-Language%20Investigation%20into%20Jailbreak%20Attacks%20in%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [LLMs Can Defend Themselves Against Jailbreaking in a Practical Manner A Vision Paper review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.15727v2%20%5BLLMs%20Can%20Defend%20Themselves%20Against%20Jailbreaking%20in%20a%20Practical%20Manner%20A%20Vision%20Paper%5D_review.md) |  | 2024-08-22 |
| [Hacc-Man An Arcade Game for Jailbreaking LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.15902v1%20%5BHacc-Man%20An%20Arcade%20Game%20for%20Jailbreaking%20LLMs%5D_review.md) |  | 2024-08-22 |
| [Rethinking How to Evaluate Language Model Jailbreak review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.06407v3%20%5BRethinking%20How%20to%20Evaluate%20Language%20Model%20Jailbreak%5D_review.md) |  | 2024-08-22 |
| [Break the Breakout Reinventing LM Defense Against Jailbreak Attacks with Self-Refinement review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.15180v2%20%5BBreak%20the%20Breakout%20Reinventing%20LM%20Defense%20Against%20Jailbreak%20Attacks%20with%20Self-Refinement%5D_review.md) |  | 2024-08-22 |
| [All in How You Ask for It Simple Black-Box Method for Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2401.09798v3%20%5BAll%20in%20How%20You%20Ask%20for%20It%20Simple%20Black-Box%20Method%20for%20Jailbreak%20Attacks%5D_review.md) |  | 2024-08-22 |
| [Jailbreaker in Jail Moving Target Defense for Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2310.02417v1%20%5BJailbreaker%20in%20Jail%20Moving%20Target%20Defense%20for%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.18166v2%20%5BDefending%20Large%20Language%20Models%20Against%20Jailbreak%20Attacks%20via%20Layer-specific%20Editing%5D_review.md) |  | 2024-08-22 |
| [JailbreakLens Visual Analysis of Jailbreak Attacks Against Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.08793v1%20%5BJailbreakLens%20Visual%20Analysis%20of%20Jailbreak%20Attacks%20Against%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Defending LLMs against Jailbreaking Attacks via Backtranslation review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.16459v3%20%5BDefending%20LLMs%20against%20Jailbreaking%20Attacks%20via%20Backtranslation%5D_review.md) |  | 2024-08-22 |
| [Badllama 3 removing safety finetuning from Llama 3 in minutes review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.01376v1%20%5BBadllama%203%20removing%20safety%20finetuning%20from%20Llama%203%20in%20minutes%5D_review.md) |  | 2024-08-22 |
| [Images are Achilles' Heel of Alignment Exploiting Visual Vulnerabilities for Jailbreaking Multimodal Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2403.09792v2%20%5BImages%20are%20Achilles%27%20Heel%20of%20Alignment%20Exploiting%20Visual%20Vulnerabilities%20for%20Jailbreaking%20Multimodal%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Agent Smith A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.08567v2%20%5BAgent%20Smith%20A%20Single%20Image%20Can%20Jailbreak%20One%20Million%20Multimodal%20LLM%20Agents%20Exponentially%20Fast%5D_review.md) |  | 2024-08-22 |
| [SafeDecoding Defending against Jailbreak Attacks via Safety-Aware Decoding review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.08983v4%20%5BSafeDecoding%20Defending%20against%20Jailbreak%20Attacks%20via%20Safety-Aware%20Decoding%5D_review.md) |  | 2024-08-22 |
| [Efficient LLM-Jailbreaking by Introducing Visual Modality review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.20015v1%20%5BEfficient%20LLM-Jailbreaking%20by%20Introducing%20Visual%20Modality%5D_review.md) |  | 2024-08-22 |
| [Gradient Cuff Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2403.00867v2%20%5BGradient%20Cuff%20Detecting%20Jailbreak%20Attacks%20on%20Large%20Language%20Models%20by%20Exploring%20Refusal%20Loss%20Landscapes%5D_review.md) |  | 2024-08-22 |
| [GPTFUZZER Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2309.10253v4%20%5BGPTFUZZER%20Red%20Teaming%20Large%20Language%20Models%20with%20Auto-Generated%20Jailbreak%20Prompts%5D_review.md) |  | 2024-08-22 |
| [Lockpicking LLMs A Logit-Based Jailbreak Using Token-level Manipulation review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.13068v2%20%5BLockpicking%20LLMs%20A%20Logit-Based%20Jailbreak%20Using%20Token-level%20Manipulation%5D_review.md) |  | 2024-08-22 |
| [h4rm3l A Dynamic Benchmark of Composable Jailbreak Attacks for LLM Safety Assessment review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.04811v1%20%5Bh4rm3l%20A%20Dynamic%20Benchmark%20of%20Composable%20Jailbreak%20Attacks%20for%20LLM%20Safety%20Assessment%5D_review.md) |  | 2024-08-22 |
| [Intention Analysis Makes LLMs A Good Jailbreak Defender review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2401.06561v3%20%5BIntention%20Analysis%20Makes%20LLMs%20A%20Good%20Jailbreak%20Defender%5D_review.md) |  | 2024-08-22 |
| [Jailbreak in pieces Compositional Adversarial Attacks on Multi-Modal Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2307.14539v2%20%5BJailbreak%20in%20pieces%20Compositional%20Adversarial%20Attacks%20on%20Multi-Modal%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Don't Listen To Me Understanding and Exploring Jailbreak Prompts of Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2403.17336v1%20%5BDon%27t%20Listen%20To%20Me%20Understanding%20and%20Exploring%20Jailbreak%20Prompts%20of%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Can LLMs Deeply Detect Complex Malicious Queries A Framework for Jailbreaking via Obfuscating Intent review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.03654v2%20%5BCan%20LLMs%20Deeply%20Detect%20Complex%20Malicious%20Queries%20A%20Framework%20for%20Jailbreaking%20via%20Obfuscating%20Intent%5D_review.md) |  | 2024-08-22 |
| [Understanding Jailbreak Success A Study of Latent Space Dynamics in Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.09289v1%20%5BUnderstanding%20Jailbreak%20Success%20A%20Study%20of%20Latent%20Space%20Dynamics%20in%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Characterizing and Evaluating the Reliability of LLMs against Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.09326v1%20%5BCharacterizing%20and%20Evaluating%20the%20Reliability%20of%20LLMs%20against%20Jailbreak%20Attacks%5D_review.md) |  | 2024-08-22 |
| [Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.20775v1%20%5BCross-Modality%20Jailbreak%20and%20Mismatched%20Attacks%20on%20Medical%20Multimodal%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Low-Resource Languages Jailbreak GPT-4 review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2310.02446v2%20%5BLow-Resource%20Languages%20Jailbreak%20GPT-4%5D_review.md) |  | 2024-08-22 |
| [BaThe Defense against the Jailbreak Attack in Multimodal Large Language Models by Treating Harmful Instruction as Backdoor Trigger review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.09093v1%20%5BBaThe%20Defense%20against%20the%20Jailbreak%20Attack%20in%20Multimodal%20Large%20Language%20Models%20by%20Treating%20Harmful%20Instruction%20as%20Backdoor%20Trigger%5D_review.md) |  | 2024-08-22 |
| [Refusal in Language Models Is Mediated by a Single Direction review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.11717v2%20%5BRefusal%20in%20Language%20Models%20Is%20Mediated%20by%20a%20Single%20Direction%5D_review.md) |  | 2024-08-22 |
| [Eraser Jailbreaking Defense in Large Language Models via Unlearning Harmful Knowledge review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.05880v2%20%5BEraser%20Jailbreaking%20Defense%20in%20Large%20Language%20Models%20via%20Unlearning%20Harmful%20Knowledge%5D_review.md) |  | 2024-08-22 |
| [WordGame Efficient & Effective LLM Jailbreak via Simultaneous Obfuscation in Query and Response review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.14023v1%20%5BWordGame%20Efficient%20%26%20Effective%20LLM%20Jailbreak%20via%20Simultaneous%20Obfuscation%20in%20Query%20and%20Response%5D_review.md) |  | 2024-08-22 |
| [Mitigating Fine-tuning based Jailbreak Attack with Backdoor Enhanced Safety Alignment review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.14968v3%20%5BMitigating%20Fine-tuning%20based%20Jailbreak%20Attack%20with%20Backdoor%20Enhanced%20Safety%20Alignment%5D_review.md) |  | 2024-08-22 |
| [Poisoned LangChain Jailbreak LLMs by LangChain review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.18122v1%20%5BPoisoned%20LangChain%20Jailbreak%20LLMs%20by%20LangChain%5D_review.md) |  | 2024-08-22 |
| [Rethinking Jailbreaking through the Lens of Representation Engineering review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2401.06824v3%20%5BRethinking%20Jailbreaking%20through%20the%20Lens%20of%20Representation%20Engineering%5D_review.md) |  | 2024-08-22 |
| [AutoDAN Generating Stealthy Jailbreak Prompts on Aligned Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2310.04451v2%20%5BAutoDAN%20Generating%20Stealthy%20Jailbreak%20Prompts%20on%20Aligned%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Fluent Student-Teacher Redteaming review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.17447v1%20%5BFluent%20Student-Teacher%20Redteaming%5D_review.md) |  | 2024-08-22 |
| [Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2311.09127v2%20%5BJailbreaking%20GPT-4V%20via%20Self-Adversarial%20Attacks%20with%20System%20Prompts%5D_review.md) |  | 2024-08-22 |
| [WIP Jailbreak Paradox The Achilles' Heel of LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.12702v2%20%5B%5BWIP%5D%20Jailbreak%20Paradox%20The%20Achilles%27%20Heel%20of%20LLMs%5D_review.md) |  | 2024-08-22 |
| [Red Teaming GPT-4V Are GPT-4V Safe Against UniMulti-Modal Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.03411v1%20%5BRed%20Teaming%20GPT-4V%20Are%20GPT-4V%20Safe%20Against%20UniMulti-Modal%20Jailbreak%20Attacks%5D_review.md) |  | 2024-08-22 |
| [Boosting Jailbreak Attack with Momentum review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.01229v1%20%5BBoosting%20Jailbreak%20Attack%20with%20Momentum%5D_review.md) |  | 2024-08-22 |
| [SelfDefend LLMs Can Defend Themselves against Jailbreaking in a Practical Manner review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.05498v1%20%5BSelfDefend%20LLMs%20Can%20Defend%20Themselves%20against%20Jailbreaking%20in%20a%20Practical%20Manner%5D_review.md) |  | 2024-08-22 |
| [Arondight Red Teaming Large Vision Language Models with Auto-generated Multi-modal Jailbreak Prompts review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.15050v1%20%5BArondight%20Red%20Teaming%20Large%20Vision%20Language%20Models%20with%20Auto-generated%20Multi-modal%20Jailbreak%20Prompts%5D_review.md) |  | 2024-08-22 |
| [Defending Jailbreak Attack in VLMs via Cross-modality Information Detector review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.21659v2%20%5BDefending%20Jailbreak%20Attack%20in%20VLMs%20via%20Cross-modality%20Information%20Detector%5D_review.md) |  | 2024-08-22 |
| [AutoDefense Multi-Agent LLM Defense against Jailbreak Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2403.04783v1%20%5BAutoDefense%20Multi-Agent%20LLM%20Defense%20against%20Jailbreak%20Attacks%5D_review.md) |  | 2024-08-22 |
| [Improved Few-Shot Jailbreaking Can Circumvent Aligned Language Models and Their Defenses review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.01288v1%20%5BImproved%20Few-Shot%20Jailbreaking%20Can%20Circumvent%20Aligned%20Language%20Models%20and%20Their%20Defenses%5D_review.md) |  | 2024-08-22 |
| [Weak-to-Strong Jailbreaking on Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2401.17256v2%20%5BWeak-to-Strong%20Jailbreaking%20on%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Defending Large Language Models against Jailbreak Attacks via Semantic Smoothing review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.16192v2%20%5BDefending%20Large%20Language%20Models%20against%20Jailbreak%20Attacks%20via%20Semantic%20Smoothing%5D_review.md) |  | 2024-08-22 |
| [How Johnny Can Persuade LLMs to Jailbreak Them Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2401.06373v2%20%5BHow%20Johnny%20Can%20Persuade%20LLMs%20to%20Jailbreak%20Them%20Rethinking%20Persuasion%20to%20Challenge%20AI%20Safety%20by%20Humanizing%20LLMs%5D_review.md) |  | 2024-08-22 |
| [Multi-Turn Context Jailbreak Attack on Large Language Models From First Principles review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.04686v1%20%5BMulti-Turn%20Context%20Jailbreak%20Attack%20on%20Large%20Language%20Models%20From%20First%20Principles%5D_review.md) |  | 2024-08-22 |
| [DeCE Deceptive Cross-Entropy Loss Designed for Defending Backdoor Attacks review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.08956v1%20%5BDeCE%20Deceptive%20Cross-Entropy%20Loss%20Designed%20for%20Defending%20Backdoor%20Attacks%5D_review.md) |  | 2024-08-22 |
| [WildGuard Open One-Stop Moderation Tools for Safety Risks, Jailbreaks, and Refusals of LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.18495v2%20%5BWildGuard%20Open%20One-Stop%20Moderation%20Tools%20for%20Safety%20Risks,%20Jailbreaks,%20and%20Refusals%20of%20LLMs%5D_review.md) |  | 2024-08-22 |
| [White-box Multimodal Jailbreaks Against Large Vision-Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.17894v1%20%5BWhite-box%20Multimodal%20Jailbreaks%20Against%20Large%20Vision-Language%20Models%5D_review.md) |  | 2024-08-22 |
| [JailbreakZoo Survey, Landscapes, and Horizons in Jailbreaking Large Language and Vision-Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.01599v2%20%5BJailbreakZoo%20Survey,%20Landscapes,%20and%20Horizons%20in%20Jailbreaking%20Large%20Language%20and%20Vision-Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Don't Say No Jailbreaking LLM by Suppressing Refusal review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.16369v1%20%5BDon%27t%20Say%20No%20Jailbreaking%20LLM%20by%20Suppressing%20Refusal%5D_review.md) |  | 2024-08-22 |
| [From LLMs to MLLMs Exploring the Landscape of Multimodal Jailbreaking review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.14859v1%20%5BFrom%20LLMs%20to%20MLLMs%20Exploring%20the%20Landscape%20of%20Multimodal%20Jailbreaking%5D_review.md) |  | 2024-08-22 |
| [CodeChameleon Personalized Encryption Framework for Jailbreaking Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.16717v1%20%5BCodeChameleon%20Personalized%20Encryption%20Framework%20for%20Jailbreaking%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Soft Begging Modular and Efficient Shielding of LLMs against Prompt Injection and Jailbreaking based on Prompt Tuning review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2407.03391v1%20%5BSoft%20Begging%20Modular%20and%20Efficient%20Shielding%20of%20LLMs%20against%20Prompt%20Injection%20and%20Jailbreaking%20based%20on%20Prompt%20Tuning%5D_review.md) |  | 2024-08-22 |
| [The Butterfly Effect of Altering Prompts How Small Changes and Jailbreaks Affect Large Language Model Performance review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2401.03729v3%20%5BThe%20Butterfly%20Effect%20of%20Altering%20Prompts%20How%20Small%20Changes%20and%20Jailbreaks%20Affect%20Large%20Language%20Model%20Performance%5D_review.md) |  | 2024-08-22 |
| [JailbreakBench An Open Robustness Benchmark for Jailbreaking Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.01318v4%20%5BJailbreakBench%20An%20Open%20Robustness%20Benchmark%20for%20Jailbreaking%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [SafeAligner Safety Alignment against Jailbreak Attacks via Response Disparity Guidance review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.18118v2%20%5BSafeAligner%20Safety%20Alignment%20against%20Jailbreak%20Attacks%20via%20Response%20Disparity%20Guidance%5D_review.md) |  | 2024-08-22 |
| [Efficient LLM Jailbreak via Adaptive Dense-to-sparse Constrained Optimization review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2405.09113v1%20%5BEfficient%20LLM%20Jailbreak%20via%20Adaptive%20Dense-to-sparse%20Constrained%20Optimization%5D_review.md) |  | 2024-08-22 |
| [Pruning for Protection Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2401.10862v2%20%5BPruning%20for%20Protection%20Increasing%20Jailbreak%20Resistance%20in%20Aligned%20LLMs%20Without%20Fine-Tuning%5D_review.md) |  | 2024-08-22 |
| [AttackEval How to Evaluate the Effectiveness of Jailbreak Attacking on Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2401.09002v5%20%5BAttackEval%20How%20to%20Evaluate%20the%20Effectiveness%20of%20Jailbreak%20Attacking%20on%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [MasterKey Automated Jailbreak Across Multiple Large Language Model Chatbots review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2307.08715v2%20%5BMasterKey%20Automated%20Jailbreak%20Across%20Multiple%20Large%20Language%20Model%20Chatbots%5D_review.md) |  | 2024-08-22 |
| [Cognitive Overload Jailbreaking Large Language Models with Overloaded Logical Thinking review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2311.09827v2%20%5BCognitive%20Overload%20Jailbreaking%20Large%20Language%20Models%20with%20Overloaded%20Logical%20Thinking%5D_review.md) |  | 2024-08-22 |
| [MM-SafetyBench A Benchmark for Safety Evaluation of Multimodal Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2311.17600v5%20%5BMM-SafetyBench%20A%20Benchmark%20for%20Safety%20Evaluation%20of%20Multimodal%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Bag of Tricks Benchmarking of Jailbreak Attacks on LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.09324v1%20%5BBag%20of%20Tricks%20Benchmarking%20of%20Jailbreak%20Attacks%20on%20LLMs%5D_review.md) |  | 2024-08-22 |
| [Is the System Message Really Important to Jailbreaks in Large Language Models review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2402.14857v2%20%5BIs%20the%20System%20Message%20Really%20Important%20to%20Jailbreaks%20in%20Large%20Language%20Models%5D_review.md) |  | 2024-08-22 |
| [Mission Impossible A Statistical Perspective on Jailbreaking LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2408.01420v1%20%5BMission%20Impossible%20A%20Statistical%20Perspective%20on%20Jailbreaking%20LLMs%5D_review.md) |  | 2024-08-22 |
| [AmpleGCG Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2404.07921v2%20%5BAmpleGCG%20Learning%20a%20Universal%20and%20Transferable%20Generative%20Model%20of%20Adversarial%20Suffixes%20for%20Jailbreaking%20Both%20Open%20and%20Closed%20LLMs%5D_review.md) |  | 2024-08-22 |
| [AgentDojo A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents review](https://github.com/dyngnosis/dyngnosis.github.io/blob/main/ml/red-team/2406.13352v2%20%5BAgentDojo%20A%20Dynamic%20Environment%20to%20Evaluate%20Attacks%20and%20Defenses%20for%20LLM%20Agents%5D_review.md) |  | 2024-08-22 |
